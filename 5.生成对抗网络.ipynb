{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成对抗是一种非监督学习，通过生成器和判别器进行对抗博弈学习过程，最终提高双方生成能力和判别能力\n",
    "# 源于Lan Goodfellow 在2014年提出了GAN\n",
    "\n",
    "# 博弈论中极大极小思想： max_g min_d d(g(z))\n",
    "# 交替训练\n",
    "\n",
    "# 数据归一化，保证训练数据分布稳定\n",
    "# torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d\n",
    "# torch.nn.InstanceNorm1d, torch.nn.InstanceNorm2d, torch.nn.InstanceNorm3d\n",
    "# torch.nn.LayerNorm\n",
    "\n",
    "# 初始化\n",
    "# torch.nn.init.uniform_(), torch.nn.init.normal_(), torch.nn.init.constant_()\n",
    "# torch.nn.init.xavier_uniform_(), torch.nn.init.xavier_normal_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45c2f8e0fc34473af0e1ef9bff7141d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# 数据\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "dataset = CIFAR10(root='./data', download=True, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnet Sequential(\n",
      "  (0): ConvTranspose2d(64, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU()\n",
      "  (9): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (10): Sigmoid()\n",
      ")\n",
      "dnet: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): LeakyReLU(negative_slope=0.2)\n",
      "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): LeakyReLU(negative_slope=0.2)\n",
      "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.2)\n",
      "  (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2)\n",
       "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): LeakyReLU(negative_slope=0.2)\n",
       "  (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 生成器\n",
    "gnet = torch.nn.Sequential(\n",
    "    # (64,1,1)\n",
    "    torch.nn.ConvTranspose2d(64, 4 * 64, kernel_size=4, bias=False),\n",
    "    torch.nn.BatchNorm2d(4 * 64),\n",
    "    torch.nn.ReLU(),\n",
    "    # (256, 4, 4)\n",
    "    torch.nn.ConvTranspose2d(4 * 64, 2*64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(2*64),\n",
    "    torch.nn.ReLU(),\n",
    "    # (128,8,8)\n",
    "    torch.nn.ConvTranspose2d(2*64, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    # (64,16,16)\n",
    "    torch.nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2,padding=1),\n",
    "    torch.nn.Sigmoid()\n",
    "    # (3, 32, 32)\n",
    "    )\n",
    "\n",
    "print('gnet', gnet)\n",
    "\n",
    "# 判别器\n",
    "dnet = torch.nn.Sequential(\n",
    "    # (3,32,32)\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # (64, 16, 16)\n",
    "    torch.nn.Conv2d(64, 2*64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(2*64),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # (128, 8, 8)\n",
    "    torch.nn.Conv2d(2*64, 4*64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(4*64),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # (256,4,4)\n",
    "    torch.nn.Conv2d(4*64, 1, kernel_size=4)\n",
    "    )\n",
    "\n",
    "print('dnet:', dnet)\n",
    "\n",
    "\n",
    "# 采用特殊初始化网络实例\n",
    "\n",
    "def weight_init(para):\n",
    "    if type(para) in [torch.nn.ConvTranspose2d, torch.nn.Conv2d]:\n",
    "        torch.nn.init.xavier_normal_(para.weight)\n",
    "    elif type(para) == torch.nn.BatchNorm2d:\n",
    "        torch.nn.init.normal_(para.weight, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(para.bias, 0)\n",
    "\n",
    "gnet.apply(weight_init)\n",
    "dnet.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0迭代下第0批次: 判别损失=0.08434556424617767，生成损失=6.563366889953613, real_dmean=0.9645393490791321, fake_dmean=0.04231749102473259\n",
      "第0迭代下第10批次: 判别损失=0.22085706889629364，生成损失=3.5826005935668945, real_dmean=0.8684533834457397, fake_dmean=0.06666837632656097\n",
      "第0迭代下第20批次: 判别损失=0.10985997319221497，生成损失=4.784465312957764, real_dmean=0.9070792198181152, fake_dmean=0.0060376557521522045\n",
      "第0迭代下第30批次: 判别损失=0.23157250881195068，生成损失=3.708918809890747, real_dmean=0.8714855313301086, fake_dmean=0.07131540775299072\n",
      "第0迭代下第40批次: 判别损失=0.2764389216899872，生成损失=5.2186994552612305, real_dmean=0.8834843635559082, fake_dmean=0.12246251851320267\n",
      "第0迭代下第50批次: 判别损失=0.35679957270622253，生成损失=3.856228828430176, real_dmean=0.7877732515335083, fake_dmean=0.07124626636505127\n",
      "第0迭代下第60批次: 判别损失=0.6028554439544678，生成损失=4.091498851776123, real_dmean=0.8671908378601074, fake_dmean=0.30802032351493835\n",
      "第0迭代下第70批次: 判别损失=0.628990888595581，生成损失=3.0334861278533936, real_dmean=0.7279706597328186, fake_dmean=0.1671130657196045\n",
      "第0迭代下第80批次: 判别损失=0.5682861804962158，生成损失=2.089372396469116, real_dmean=0.6315136551856995, fake_dmean=0.057016145437955856\n",
      "第0迭代下第90批次: 判别损失=0.60065096616745，生成损失=4.0687408447265625, real_dmean=0.9193233847618103, fake_dmean=0.37551233172416687\n",
      "第0迭代下第100批次: 判别损失=0.31398093700408936，生成损失=3.6755564212799072, real_dmean=0.8033263683319092, fake_dmean=0.05993986502289772\n",
      "第0迭代下第110批次: 判别损失=0.6671640276908875，生成损失=4.647889137268066, real_dmean=0.8015543818473816, fake_dmean=0.32049474120140076\n",
      "第0迭代下第120批次: 判别损失=0.519120454788208，生成损失=4.114487171173096, real_dmean=0.8701746463775635, fake_dmean=0.28878816962242126\n",
      "第0迭代下第130批次: 判别损失=0.5678814053535461，生成损失=3.730186939239502, real_dmean=0.8362383842468262, fake_dmean=0.28174102306365967\n",
      "第0迭代下第140批次: 判别损失=0.6855877637863159，生成损失=1.8116494417190552, real_dmean=0.6296678781509399, fake_dmean=0.12754352390766144\n",
      "第0迭代下第150批次: 判别损失=0.44782426953315735，生成损失=3.956143379211426, real_dmean=0.970977783203125, fake_dmean=0.32543957233428955\n",
      "第0迭代下第160批次: 判别损失=0.6293838620185852，生成损失=2.4715888500213623, real_dmean=0.6143122911453247, fake_dmean=0.06820210069417953\n",
      "第0迭代下第170批次: 判别损失=0.558192253112793，生成损失=3.684586524963379, real_dmean=0.8560671210289001, fake_dmean=0.306966096162796\n",
      "第0迭代下第180批次: 判别损失=0.4438873827457428，生成损失=3.050156354904175, real_dmean=0.742659866809845, fake_dmean=0.10890853404998779\n",
      "第0迭代下第190批次: 判别损失=0.793854832649231，生成损失=2.0046494007110596, real_dmean=0.5368376970291138, fake_dmean=0.05083214119076729\n",
      "第0迭代下第200批次: 判别损失=0.7746294736862183，生成损失=2.349959373474121, real_dmean=0.6595812439918518, fake_dmean=0.2324746698141098\n",
      "第0迭代下第210批次: 判别损失=0.6824798583984375，生成损失=2.025651454925537, real_dmean=0.6331186294555664, fake_dmean=0.13577905297279358\n",
      "第0迭代下第220批次: 判别损失=0.688727855682373，生成损失=4.36379337310791, real_dmean=0.8383738398551941, fake_dmean=0.3497227728366852\n",
      "第0迭代下第230批次: 判别损失=1.2356460094451904，生成损失=1.8252413272857666, real_dmean=0.4148373603820801, fake_dmean=0.07197055965662003\n",
      "第0迭代下第240批次: 判别损失=1.1517958641052246，生成损失=2.1578562259674072, real_dmean=0.6285067200660706, fake_dmean=0.38836029171943665\n",
      "第0迭代下第250批次: 判别损失=0.8153454065322876，生成损失=2.718127489089966, real_dmean=0.6740452647209167, fake_dmean=0.2737400531768799\n",
      "第0迭代下第260批次: 判别损失=1.2323811054229736，生成损失=4.224257946014404, real_dmean=0.834898829460144, fake_dmean=0.59816575050354\n",
      "第0迭代下第270批次: 判别损失=0.6348540782928467，生成损失=3.2267773151397705, real_dmean=0.8198142051696777, fake_dmean=0.3085646629333496\n",
      "第0迭代下第280批次: 判别损失=0.6592521667480469，生成损失=2.2306411266326904, real_dmean=0.6660593748092651, fake_dmean=0.1720452904701233\n",
      "第0迭代下第290批次: 判别损失=0.6887792944908142，生成损失=3.9480531215667725, real_dmean=0.8571608066558838, fake_dmean=0.38242799043655396\n",
      "第0迭代下第300批次: 判别损失=0.846002995967865，生成损失=3.175313711166382, real_dmean=0.839281439781189, fake_dmean=0.45425334572792053\n",
      "第0迭代下第310批次: 判别损失=0.597288191318512，生成损失=2.9782204627990723, real_dmean=0.7839243412017822, fake_dmean=0.2730364501476288\n",
      "第0迭代下第320批次: 判别损失=0.4302416443824768，生成损失=3.6048431396484375, real_dmean=0.8413560390472412, fake_dmean=0.20701567828655243\n",
      "第0迭代下第330批次: 判别损失=0.9316105246543884，生成损失=2.2438786029815674, real_dmean=0.5079714059829712, fake_dmean=0.10534149408340454\n",
      "第0迭代下第340批次: 判别损失=0.6321992874145508，生成损失=2.6437299251556396, real_dmean=0.6973575353622437, fake_dmean=0.1808164417743683\n",
      "第0迭代下第350批次: 判别损失=0.8505022525787354，生成损失=2.710521697998047, real_dmean=0.6089369058609009, fake_dmean=0.19813820719718933\n",
      "第0迭代下第360批次: 判别损失=0.5510322451591492，生成损失=3.004575729370117, real_dmean=0.7185011506080627, fake_dmean=0.14072555303573608\n",
      "第0迭代下第370批次: 判别损失=0.7173130512237549，生成损失=3.986502170562744, real_dmean=0.8144012689590454, fake_dmean=0.3627612888813019\n",
      "第0迭代下第380批次: 判别损失=0.690619945526123，生成损失=3.5808207988739014, real_dmean=0.8523507714271545, fake_dmean=0.3828135132789612\n",
      "第0迭代下第390批次: 判别损失=0.5801165103912354，生成损失=3.35329008102417, real_dmean=0.8620384931564331, fake_dmean=0.318326473236084\n",
      "第0迭代下第400批次: 判别损失=0.5748342275619507，生成损失=2.65733003616333, real_dmean=0.8068655133247375, fake_dmean=0.2634446322917938\n",
      "第0迭代下第410批次: 判别损失=0.563643217086792，生成损失=3.2691967487335205, real_dmean=0.7831895351409912, fake_dmean=0.24766454100608826\n",
      "第0迭代下第420批次: 判别损失=1.0793861150741577，生成损失=1.653627872467041, real_dmean=0.4398491382598877, fake_dmean=0.06324217468500137\n",
      "第0迭代下第430批次: 判别损失=0.7384930849075317，生成损失=3.2316336631774902, real_dmean=0.7915686368942261, fake_dmean=0.3529343605041504\n",
      "第0迭代下第440批次: 判别损失=0.5741957426071167，生成损失=2.446206569671631, real_dmean=0.6754639148712158, fake_dmean=0.12261605262756348\n",
      "第0迭代下第450批次: 判别损失=0.9348818063735962，生成损失=5.331695556640625, real_dmean=0.8876177072525024, fake_dmean=0.515893816947937\n",
      "第0迭代下第460批次: 判别损失=0.7230750322341919，生成损失=2.39481782913208, real_dmean=0.7277171611785889, fake_dmean=0.25238311290740967\n",
      "第0迭代下第470批次: 判别损失=0.7622846364974976，生成损失=2.3010151386260986, real_dmean=0.5991124510765076, fake_dmean=0.14220622181892395\n",
      "第0迭代下第480批次: 判别损失=1.0453813076019287，生成损失=1.908557653427124, real_dmean=0.4484129846096039, fake_dmean=0.06848748028278351\n",
      "第0迭代下第490批次: 判别损失=0.6428502798080444，生成损失=2.660930633544922, real_dmean=0.7061780691146851, fake_dmean=0.18574345111846924\n",
      "第0迭代下第500批次: 判别损失=0.7505744099617004，生成损失=3.0668647289276123, real_dmean=0.7895796895027161, fake_dmean=0.3525596261024475\n",
      "第0迭代下第510批次: 判别损失=1.3283416032791138，生成损失=1.4504497051239014, real_dmean=0.39923807978630066, fake_dmean=0.1737598329782486\n",
      "第0迭代下第520批次: 判别损失=0.599719226360321，生成损失=2.7928714752197266, real_dmean=0.8061627745628357, fake_dmean=0.2948610484600067\n",
      "第0迭代下第530批次: 判别损失=1.0282491445541382，生成损失=3.05507493019104, real_dmean=0.800584077835083, fake_dmean=0.5193760395050049\n",
      "第0迭代下第540批次: 判别损失=0.7275885343551636，生成损失=2.5068159103393555, real_dmean=0.6690893173217773, fake_dmean=0.23412549495697021\n",
      "第0迭代下第550批次: 判别损失=1.2468291521072388，生成损失=3.513455867767334, real_dmean=0.8246092796325684, fake_dmean=0.616654098033905\n",
      "第0迭代下第560批次: 判别损失=0.9359930753707886，生成损失=1.6194638013839722, real_dmean=0.6236189603805542, fake_dmean=0.3105422854423523\n",
      "第0迭代下第570批次: 判别损失=0.6469972133636475，生成损失=2.702881097793579, real_dmean=0.7703153491020203, fake_dmean=0.29581865668296814\n",
      "第0迭代下第580批次: 判别损失=1.2124621868133545，生成损失=1.1013466119766235, real_dmean=0.40894731879234314, fake_dmean=0.12119916826486588\n",
      "第0迭代下第590批次: 判别损失=0.8987844586372375，生成损失=2.2493085861206055, real_dmean=0.7232306003570557, fake_dmean=0.38976895809173584\n",
      "第0迭代下第600批次: 判别损失=1.0742007493972778，生成损失=2.153289318084717, real_dmean=0.6679386496543884, fake_dmean=0.40758615732192993\n",
      "第0迭代下第610批次: 判别损失=1.108054518699646，生成损失=1.212592601776123, real_dmean=0.45661693811416626, fake_dmean=0.14873501658439636\n",
      "第0迭代下第620批次: 判别损失=1.330899953842163，生成损失=3.4136054515838623, real_dmean=0.8769099116325378, fake_dmean=0.6514772772789001\n",
      "第0迭代下第630批次: 判别损失=0.7608201503753662，生成损失=1.91768479347229, real_dmean=0.6525471210479736, fake_dmean=0.2498863935470581\n",
      "第0迭代下第640批次: 判别损失=1.065355658531189，生成损失=1.2913148403167725, real_dmean=0.5028668642044067, fake_dmean=0.22596953809261322\n",
      "第0迭代下第650批次: 判别损失=1.0555200576782227，生成损失=1.6923892498016357, real_dmean=0.4717977046966553, fake_dmean=0.1509319692850113\n",
      "第0迭代下第660批次: 判别损失=0.8836925625801086，生成损失=1.6309412717819214, real_dmean=0.5680484771728516, fake_dmean=0.2095261514186859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0迭代下第670批次: 判别损失=0.9728689193725586，生成损失=2.024376392364502, real_dmean=0.6656652092933655, fake_dmean=0.36594343185424805\n",
      "第0迭代下第680批次: 判别损失=0.8210138082504272，生成损失=2.2558977603912354, real_dmean=0.8307033181190491, fake_dmean=0.4422130584716797\n",
      "第0迭代下第690批次: 判别损失=1.0184245109558105，生成损失=2.7046375274658203, real_dmean=0.7788686156272888, fake_dmean=0.488380491733551\n",
      "第0迭代下第700批次: 判别损失=0.7535871267318726，生成损失=2.042137622833252, real_dmean=0.6455379128456116, fake_dmean=0.22206932306289673\n",
      "第0迭代下第710批次: 判别损失=0.9356599450111389，生成损失=1.5789915323257446, real_dmean=0.6154754161834717, fake_dmean=0.2887496054172516\n",
      "第0迭代下第720批次: 判别损失=0.9302873611450195，生成损失=1.9376522302627563, real_dmean=0.6238278150558472, fake_dmean=0.3105897307395935\n",
      "第0迭代下第730批次: 判别损失=1.1668555736541748，生成损失=1.2689638137817383, real_dmean=0.4140392541885376, fake_dmean=0.1266816407442093\n",
      "第0迭代下第740批次: 判别损失=1.0153424739837646，生成损失=2.475417375564575, real_dmean=0.8201665282249451, fake_dmean=0.5270996689796448\n",
      "第0迭代下第750批次: 判别损失=1.1501715183258057，生成损失=1.1129497289657593, real_dmean=0.488813579082489, fake_dmean=0.26684311032295227\n",
      "第0迭代下第760批次: 判别损失=0.7684375047683716，生成损失=1.9145711660385132, real_dmean=0.6773084998130798, fake_dmean=0.2801257073879242\n",
      "第0迭代下第770批次: 判别损失=1.0428407192230225，生成损失=2.558398485183716, real_dmean=0.8268933892250061, fake_dmean=0.5313521027565002\n",
      "第0迭代下第780批次: 判别损失=0.7500176429748535，生成损失=2.334148406982422, real_dmean=0.6783227324485779, fake_dmean=0.26147252321243286\n",
      "第1迭代下第0批次: 判别损失=1.2007628679275513，生成损失=3.8215277194976807, real_dmean=0.856570839881897, fake_dmean=0.5984832644462585\n",
      "第1迭代下第10批次: 判别损失=0.8805784583091736，生成损失=2.9826602935791016, real_dmean=0.8617606163024902, fake_dmean=0.4890534579753876\n",
      "第1迭代下第20批次: 判别损失=0.7525101900100708，生成损失=2.0413596630096436, real_dmean=0.7128356099128723, fake_dmean=0.3010069727897644\n",
      "第1迭代下第30批次: 判别损失=1.054000735282898，生成损失=1.9330648183822632, real_dmean=0.71467125415802, fake_dmean=0.47087961435317993\n",
      "第1迭代下第40批次: 判别损失=0.9876171946525574，生成损失=2.249422311782837, real_dmean=0.6501990556716919, fake_dmean=0.3744894564151764\n",
      "第1迭代下第50批次: 判别损失=0.9887205362319946，生成损失=1.8809400796890259, real_dmean=0.6424038410186768, fake_dmean=0.3629779517650604\n",
      "第1迭代下第60批次: 判别损失=1.1903467178344727，生成损失=1.195319652557373, real_dmean=0.49059543013572693, fake_dmean=0.30272376537323\n",
      "第1迭代下第70批次: 判别损失=0.8362820744514465，生成损失=2.594754934310913, real_dmean=0.7951010465621948, fake_dmean=0.414917916059494\n",
      "第1迭代下第80批次: 判别损失=1.1812201738357544，生成损失=0.8706395626068115, real_dmean=0.4232025146484375, fake_dmean=0.1897929310798645\n",
      "第1迭代下第90批次: 判别损失=1.0576575994491577，生成损失=1.1964424848556519, real_dmean=0.4757690131664276, fake_dmean=0.16905373334884644\n",
      "第1迭代下第100批次: 判别损失=0.6756446361541748，生成损失=3.035407304763794, real_dmean=0.8278127908706665, fake_dmean=0.35887205600738525\n",
      "第1迭代下第110批次: 判别损失=1.1774624586105347，生成损失=1.4896119832992554, real_dmean=0.43631675839424133, fake_dmean=0.1798936426639557\n",
      "第1迭代下第120批次: 判别损失=0.8464657068252563，生成损失=2.5023937225341797, real_dmean=0.7888168096542358, fake_dmean=0.4137811064720154\n",
      "第1迭代下第130批次: 判别损失=1.1915537118911743，生成损失=1.5139282941818237, real_dmean=0.40610525012016296, fake_dmean=0.15982525050640106\n",
      "第1迭代下第140批次: 判别损失=1.1645116806030273，生成损失=2.2932562828063965, real_dmean=0.7265375852584839, fake_dmean=0.5286874175071716\n",
      "第1迭代下第150批次: 判别损失=1.1281708478927612，生成损失=1.6398224830627441, real_dmean=0.5808054208755493, fake_dmean=0.3738219141960144\n",
      "第1迭代下第160批次: 判别损失=0.8037204742431641，生成损失=2.1491715908050537, real_dmean=0.7321494817733765, fake_dmean=0.3602892756462097\n",
      "第1迭代下第170批次: 判别损失=0.8196904063224792，生成损失=2.4537596702575684, real_dmean=0.7426817417144775, fake_dmean=0.37445390224456787\n",
      "第1迭代下第180批次: 判别损失=1.042813777923584，生成损失=1.2595689296722412, real_dmean=0.4754825830459595, fake_dmean=0.19303511083126068\n",
      "第1迭代下第190批次: 判别损失=0.7959850430488586，生成损失=2.8450136184692383, real_dmean=0.8442953824996948, fake_dmean=0.44098955392837524\n",
      "第1迭代下第200批次: 判别损失=0.990703284740448，生成损失=2.2782602310180664, real_dmean=0.6880674958229065, fake_dmean=0.4085390269756317\n",
      "第1迭代下第210批次: 判别损失=1.0254019498825073，生成损失=1.2540901899337769, real_dmean=0.5148046016693115, fake_dmean=0.2317943572998047\n",
      "第1迭代下第220批次: 判别损失=0.8745865225791931，生成损失=1.3526118993759155, real_dmean=0.5548563003540039, fake_dmean=0.19954898953437805\n",
      "第1迭代下第230批次: 判别损失=1.3604142665863037，生成损失=1.2755705118179321, real_dmean=0.37839463353157043, fake_dmean=0.20294512808322906\n",
      "第1迭代下第240批次: 判别损失=0.7759032249450684，生成损失=1.9197880029678345, real_dmean=0.6724227070808411, fake_dmean=0.27344146370887756\n",
      "第1迭代下第250批次: 判别损失=1.1284244060516357，生成损失=1.9687707424163818, real_dmean=0.6048464179039001, fake_dmean=0.4138159453868866\n",
      "第1迭代下第260批次: 判别损失=0.7824221849441528，生成损失=1.440288782119751, real_dmean=0.6233532428741455, fake_dmean=0.227183535695076\n",
      "第1迭代下第270批次: 判别损失=0.9181971549987793，生成损失=1.415051817893982, real_dmean=0.5594044923782349, fake_dmean=0.23010803759098053\n",
      "第1迭代下第280批次: 判别损失=0.9254752397537231，生成损失=1.680322527885437, real_dmean=0.7096158862113953, fake_dmean=0.40021753311157227\n",
      "第1迭代下第290批次: 判别损失=1.011484980583191，生成损失=2.456055164337158, real_dmean=0.7603200674057007, fake_dmean=0.4862091541290283\n",
      "第1迭代下第300批次: 判别损失=0.9759758710861206，生成损失=2.1231348514556885, real_dmean=0.6765850186347961, fake_dmean=0.38686615228652954\n",
      "第1迭代下第310批次: 判别损失=0.8508344888687134，生成损失=2.5789835453033447, real_dmean=0.7356279492378235, fake_dmean=0.3819116950035095\n",
      "第1迭代下第320批次: 判别损失=0.7196903228759766，生成损失=1.8406084775924683, real_dmean=0.6838213205337524, fake_dmean=0.24803827702999115\n",
      "第1迭代下第330批次: 判别损失=0.7449407577514648，生成损失=2.5568253993988037, real_dmean=0.7223530411720276, fake_dmean=0.3072190582752228\n",
      "第1迭代下第340批次: 判别损失=0.9582481384277344，生成损失=1.2742935419082642, real_dmean=0.5687536597251892, fake_dmean=0.28162461519241333\n",
      "第1迭代下第350批次: 判别损失=1.1313328742980957，生成损失=1.3446028232574463, real_dmean=0.4407315254211426, fake_dmean=0.18261322379112244\n",
      "第1迭代下第360批次: 判别损失=1.0750293731689453，生成损失=1.8780382871627808, real_dmean=0.7037696242332458, fake_dmean=0.4583481252193451\n",
      "第1迭代下第370批次: 判别损失=0.7051364183425903，生成损失=2.1894097328186035, real_dmean=0.7287123203277588, fake_dmean=0.2988591194152832\n",
      "第1迭代下第380批次: 判别损失=1.1319046020507812，生成损失=1.9813175201416016, real_dmean=0.6664797067642212, fake_dmean=0.4685085713863373\n",
      "第1迭代下第390批次: 判别损失=1.0227137804031372，生成损失=1.4465274810791016, real_dmean=0.5136246681213379, fake_dmean=0.22881074249744415\n",
      "第1迭代下第400批次: 判别损失=1.1820610761642456，生成损失=1.9504262208938599, real_dmean=0.6043366193771362, fake_dmean=0.44721072912216187\n",
      "第1迭代下第410批次: 判别损失=1.0592267513275146，生成损失=2.329514265060425, real_dmean=0.8421230912208557, fake_dmean=0.5474184155464172\n",
      "第1迭代下第420批次: 判别损失=0.9806879162788391，生成损失=1.5337235927581787, real_dmean=0.6605978012084961, fake_dmean=0.3918623924255371\n",
      "第1迭代下第430批次: 判别损失=0.9011197090148926，生成损失=1.7975703477859497, real_dmean=0.6179764270782471, fake_dmean=0.2966125011444092\n",
      "第1迭代下第440批次: 判别损失=0.6255599856376648，生成损失=1.9589085578918457, real_dmean=0.7329493165016174, fake_dmean=0.24588599801063538\n",
      "第1迭代下第450批次: 判别损失=0.9831255674362183，生成损失=1.585009217262268, real_dmean=0.614628791809082, fake_dmean=0.3531801104545593\n",
      "第1迭代下第460批次: 判别损失=0.8672886490821838，生成损失=2.049363851547241, real_dmean=0.7799856066703796, fake_dmean=0.4239045977592468\n",
      "第1迭代下第470批次: 判别损失=0.7696640491485596，生成损失=1.7151973247528076, real_dmean=0.6660538911819458, fake_dmean=0.25916561484336853\n",
      "第1迭代下第480批次: 判别损失=0.7569748163223267，生成损失=1.8828823566436768, real_dmean=0.7124822735786438, fake_dmean=0.30107659101486206\n",
      "第1迭代下第490批次: 判别损失=1.0469186305999756，生成损失=1.4762852191925049, real_dmean=0.6410294771194458, fake_dmean=0.398131787776947\n",
      "第1迭代下第500批次: 判别损失=1.1762943267822266，生成损失=1.3020002841949463, real_dmean=0.5457833409309387, fake_dmean=0.35183972120285034\n",
      "第1迭代下第510批次: 判别损失=0.971193790435791，生成损失=1.9085382223129272, real_dmean=0.7277563214302063, fake_dmean=0.4347265958786011\n",
      "第1迭代下第520批次: 判别损失=0.9259352684020996，生成损失=1.3661417961120605, real_dmean=0.545183002948761, fake_dmean=0.22255605459213257\n",
      "第1迭代下第530批次: 判别损失=0.6530354022979736，生成损失=2.0498085021972656, real_dmean=0.7553494572639465, fake_dmean=0.2719813585281372\n",
      "第1迭代下第540批次: 判别损失=1.1917539834976196，生成损失=2.676332712173462, real_dmean=0.8301973342895508, fake_dmean=0.606257438659668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1迭代下第550批次: 判别损失=0.7880003452301025，生成损失=2.1174356937408447, real_dmean=0.7219080924987793, fake_dmean=0.3406107425689697\n",
      "第1迭代下第560批次: 判别损失=0.832095205783844，生成损失=1.8132213354110718, real_dmean=0.6897485256195068, fake_dmean=0.3335244953632355\n",
      "第1迭代下第570批次: 判别损失=0.607383131980896，生成损失=1.9865448474884033, real_dmean=0.8406447172164917, fake_dmean=0.3265215754508972\n",
      "第1迭代下第580批次: 判别损失=0.6797335147857666，生成损失=2.1243655681610107, real_dmean=0.7751823663711548, fake_dmean=0.32263368368148804\n",
      "第1迭代下第590批次: 判别损失=1.0285497903823853，生成损失=1.0167251825332642, real_dmean=0.5288244485855103, fake_dmean=0.2532396614551544\n",
      "第1迭代下第600批次: 判别损失=0.7317360639572144，生成损失=1.726452112197876, real_dmean=0.614475667476654, fake_dmean=0.18280287086963654\n",
      "第1迭代下第610批次: 判别损失=0.765508770942688，生成损失=1.9510304927825928, real_dmean=0.7270298004150391, fake_dmean=0.3237536549568176\n",
      "第1迭代下第620批次: 判别损失=0.8204450607299805，生成损失=1.9755760431289673, real_dmean=0.7674299478530884, fake_dmean=0.39978668093681335\n",
      "第1迭代下第630批次: 判别损失=0.9791431427001953，生成损失=2.5437562465667725, real_dmean=0.75227952003479, fake_dmean=0.45287850499153137\n",
      "第1迭代下第640批次: 判别损失=0.773746132850647，生成损失=1.4340473413467407, real_dmean=0.6163556575775146, fake_dmean=0.20553788542747498\n",
      "第1迭代下第650批次: 判别损失=0.7999303340911865，生成损失=2.5097339153289795, real_dmean=0.802933931350708, fake_dmean=0.40234705805778503\n",
      "第1迭代下第660批次: 判别损失=1.1128596067428589，生成损失=3.0940802097320557, real_dmean=0.8827908039093018, fake_dmean=0.577968418598175\n",
      "第1迭代下第670批次: 判别损失=0.672440767288208，生成损失=1.6023794412612915, real_dmean=0.6978597044944763, fake_dmean=0.23240643739700317\n",
      "第1迭代下第680批次: 判别损失=0.7553704977035522，生成损失=1.7325373888015747, real_dmean=0.678509533405304, fake_dmean=0.2659149765968323\n",
      "第1迭代下第690批次: 判别损失=1.1198813915252686，生成损失=0.8927397727966309, real_dmean=0.4074832499027252, fake_dmean=0.11400529742240906\n",
      "第1迭代下第700批次: 判别损失=0.6386924982070923，生成损失=1.7549201250076294, real_dmean=0.6922605037689209, fake_dmean=0.20782095193862915\n",
      "第1迭代下第710批次: 判别损失=0.7540134191513062，生成损失=2.565810203552246, real_dmean=0.7541602849960327, fake_dmean=0.3406737744808197\n",
      "第1迭代下第720批次: 判别损失=0.7692633867263794，生成损失=2.529081344604492, real_dmean=0.7679744362831116, fake_dmean=0.3553016185760498\n",
      "第1迭代下第730批次: 判别损失=0.7585779428482056，生成损失=2.4903006553649902, real_dmean=0.7592899799346924, fake_dmean=0.3586665391921997\n",
      "第1迭代下第740批次: 判别损失=0.7556694746017456，生成损失=1.8228654861450195, real_dmean=0.5894790887832642, fake_dmean=0.15693777799606323\n",
      "第1迭代下第750批次: 判别损失=0.8325255513191223，生成损失=1.3735325336456299, real_dmean=0.5969624519348145, fake_dmean=0.21390490233898163\n",
      "第1迭代下第760批次: 判别损失=1.1805317401885986，生成损失=1.5100687742233276, real_dmean=0.46503743529319763, fake_dmean=0.22713112831115723\n",
      "第1迭代下第770批次: 判别损失=0.5978321433067322，生成损失=1.890906572341919, real_dmean=0.716992974281311, fake_dmean=0.18972451984882355\n",
      "第1迭代下第780批次: 判别损失=0.6096282005310059，生成损失=2.432180643081665, real_dmean=0.7422449588775635, fake_dmean=0.2257031351327896\n",
      "第2迭代下第0批次: 判别损失=0.7949713468551636，生成损失=2.671844482421875, real_dmean=0.7988428473472595, fake_dmean=0.37524843215942383\n",
      "第2迭代下第10批次: 判别损失=1.0089656114578247，生成损失=3.535072088241577, real_dmean=0.8505522608757019, fake_dmean=0.5341373085975647\n",
      "第2迭代下第20批次: 判别损失=0.9409951567649841，生成损失=2.7253880500793457, real_dmean=0.7890562415122986, fake_dmean=0.4739893078804016\n",
      "第2迭代下第30批次: 判别损失=0.6726139187812805，生成损失=1.8013547658920288, real_dmean=0.6819785833358765, fake_dmean=0.20995016396045685\n",
      "第2迭代下第40批次: 判别损失=0.6347962617874146，生成损失=1.949815034866333, real_dmean=0.6639869213104248, fake_dmean=0.16447493433952332\n",
      "第2迭代下第50批次: 判别损失=0.6519012451171875，生成损失=2.3714351654052734, real_dmean=0.6676581501960754, fake_dmean=0.17309479415416718\n",
      "第2迭代下第60批次: 判别损失=0.8565791249275208，生成损失=3.643514633178711, real_dmean=0.8389434218406677, fake_dmean=0.45600301027297974\n",
      "第2迭代下第70批次: 判别损失=0.7109994888305664，生成损失=2.774380683898926, real_dmean=0.7227727770805359, fake_dmean=0.2868430018424988\n",
      "第2迭代下第80批次: 判别损失=1.776161551475525，生成损失=2.5899462699890137, real_dmean=0.7269672155380249, fake_dmean=0.7108268737792969\n",
      "第2迭代下第90批次: 判别损失=0.8601311445236206，生成损失=2.830831289291382, real_dmean=0.8406373262405396, fake_dmean=0.45561665296554565\n",
      "第2迭代下第100批次: 判别损失=1.153181552886963，生成损失=1.5237749814987183, real_dmean=0.5762939453125, fake_dmean=0.38248538970947266\n",
      "第2迭代下第110批次: 判别损失=0.9379366636276245，生成损失=2.4631409645080566, real_dmean=0.7468429803848267, fake_dmean=0.4326149821281433\n",
      "第2迭代下第120批次: 判别损失=0.9780368804931641，生成损失=1.9786643981933594, real_dmean=0.826347827911377, fake_dmean=0.5048037767410278\n",
      "第2迭代下第130批次: 判别损失=0.9451591968536377，生成损失=1.4190397262573242, real_dmean=0.6282455921173096, fake_dmean=0.3259442448616028\n",
      "第2迭代下第140批次: 判别损失=0.9051080942153931，生成损失=1.630584478378296, real_dmean=0.6381263732910156, fake_dmean=0.3253415822982788\n",
      "第2迭代下第150批次: 判别损失=0.7813894152641296，生成损失=1.3444814682006836, real_dmean=0.5930960774421692, fake_dmean=0.18592429161071777\n",
      "第2迭代下第160批次: 判别损失=0.8208345174789429，生成损失=2.162846326828003, real_dmean=0.8159565925598145, fake_dmean=0.43041694164276123\n",
      "第2迭代下第170批次: 判别损失=0.8822441101074219，生成损失=1.2427022457122803, real_dmean=0.6081326007843018, fake_dmean=0.27425238490104675\n",
      "第2迭代下第180批次: 判别损失=1.1328907012939453，生成损失=2.408459424972534, real_dmean=0.8600207567214966, fake_dmean=0.5855836272239685\n",
      "第2迭代下第190批次: 判别损失=0.9751133322715759，生成损失=1.671931505203247, real_dmean=0.7132254242897034, fake_dmean=0.4282347857952118\n",
      "第2迭代下第200批次: 判别损失=0.7986117005348206，生成损失=1.471404790878296, real_dmean=0.625264585018158, fake_dmean=0.24168291687965393\n",
      "第2迭代下第210批次: 判别损失=0.8233085870742798，生成损失=2.357567071914673, real_dmean=0.8232249021530151, fake_dmean=0.4400826692581177\n",
      "第2迭代下第220批次: 判别损失=0.9416369795799255，生成损失=1.5882617235183716, real_dmean=0.7400779128074646, fake_dmean=0.4327663481235504\n",
      "第2迭代下第230批次: 判别损失=0.8688289523124695，生成损失=1.7732502222061157, real_dmean=0.6262984275817871, fake_dmean=0.2855806052684784\n",
      "第2迭代下第240批次: 判别损失=1.2415599822998047，生成损失=0.6520839333534241, real_dmean=0.3813909888267517, fake_dmean=0.1674090027809143\n",
      "第2迭代下第250批次: 判别损失=0.9573862552642822，生成损失=1.4795106649398804, real_dmean=0.6312918066978455, fake_dmean=0.3254198431968689\n",
      "第2迭代下第260批次: 判别损失=0.8012656569480896，生成损失=1.972606897354126, real_dmean=0.8196250796318054, fake_dmean=0.42509108781814575\n",
      "第2迭代下第270批次: 判别损失=0.744288444519043，生成损失=2.103274345397949, real_dmean=0.7398833632469177, fake_dmean=0.32583191990852356\n",
      "第2迭代下第280批次: 判别损失=1.005129337310791，生成损失=1.1921745538711548, real_dmean=0.5670177340507507, fake_dmean=0.2958534359931946\n",
      "第2迭代下第290批次: 判别损失=1.0556529760360718，生成损失=1.177343726158142, real_dmean=0.409222275018692, fake_dmean=0.07594601809978485\n",
      "第2迭代下第300批次: 判别损失=0.7485409379005432，生成损失=2.3056020736694336, real_dmean=0.7344298958778381, fake_dmean=0.3063529133796692\n",
      "第2迭代下第310批次: 判别损失=1.0478556156158447，生成损失=2.5314345359802246, real_dmean=0.7889716625213623, fake_dmean=0.5168293118476868\n",
      "第2迭代下第320批次: 判别损失=0.7638806104660034，生成损失=2.098243236541748, real_dmean=0.7064537405967712, fake_dmean=0.31279391050338745\n",
      "第2迭代下第330批次: 判别损失=1.0212280750274658，生成损失=1.1640881299972534, real_dmean=0.49746301770210266, fake_dmean=0.20061418414115906\n",
      "第2迭代下第340批次: 判别损失=0.8274637460708618，生成损失=1.791546106338501, real_dmean=0.7130142450332642, fake_dmean=0.3552665710449219\n",
      "第2迭代下第350批次: 判别损失=0.9335851073265076，生成损失=1.1924198865890503, real_dmean=0.5098956227302551, fake_dmean=0.1621483713388443\n",
      "第2迭代下第360批次: 判别损失=0.6155884861946106，生成损失=2.4900283813476562, real_dmean=0.8389366865158081, fake_dmean=0.3258606791496277\n",
      "第2迭代下第370批次: 判别损失=0.7757250070571899，生成损失=1.9782989025115967, real_dmean=0.6896849870681763, fake_dmean=0.2856100797653198\n",
      "第2迭代下第380批次: 判别损失=0.8529934883117676，生成损失=2.7563376426696777, real_dmean=0.8067713379859924, fake_dmean=0.4332452118396759\n",
      "第2迭代下第390批次: 判别损失=0.897335410118103，生成损失=1.7640061378479004, real_dmean=0.7090118527412415, fake_dmean=0.3855375051498413\n",
      "第2迭代下第400批次: 判别损失=1.1270906925201416，生成损失=2.204854965209961, real_dmean=0.6809272170066833, fake_dmean=0.4779624938964844\n",
      "第2迭代下第410批次: 判别损失=0.7768322229385376，生成损失=1.6505491733551025, real_dmean=0.7070513367652893, fake_dmean=0.30556291341781616\n",
      "第2迭代下第420批次: 判别损失=0.8068536520004272，生成损失=1.778110146522522, real_dmean=0.7865284085273743, fake_dmean=0.39409196376800537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2迭代下第430批次: 判别损失=0.9122008681297302，生成损失=1.560577154159546, real_dmean=0.6328079700469971, fake_dmean=0.3111151158809662\n",
      "第2迭代下第440批次: 判别损失=0.9204719662666321，生成损失=1.9627485275268555, real_dmean=0.6499660015106201, fake_dmean=0.34376439452171326\n",
      "第2迭代下第450批次: 判别损失=1.017236590385437，生成损失=2.671506881713867, real_dmean=0.8327963352203369, fake_dmean=0.5308167338371277\n",
      "第2迭代下第460批次: 判别损失=0.7198184728622437，生成损失=1.8169605731964111, real_dmean=0.6712724566459656, fake_dmean=0.23811718821525574\n",
      "第2迭代下第470批次: 判别损失=0.7290027737617493，生成损失=2.144355058670044, real_dmean=0.8034422397613525, fake_dmean=0.37245216965675354\n",
      "第2迭代下第480批次: 判别损失=0.812409520149231，生成损失=1.2901265621185303, real_dmean=0.5681913495063782, fake_dmean=0.1707356870174408\n",
      "第2迭代下第490批次: 判别损失=0.7098806500434875，生成损失=1.904081106185913, real_dmean=0.714042067527771, fake_dmean=0.27020251750946045\n",
      "第2迭代下第500批次: 判别损失=0.8998031616210938，生成损失=1.4970331192016602, real_dmean=0.6434884071350098, fake_dmean=0.3181506097316742\n",
      "第2迭代下第510批次: 判别损失=0.8815775513648987，生成损失=1.4985136985778809, real_dmean=0.6180912256240845, fake_dmean=0.2791823744773865\n",
      "第2迭代下第520批次: 判别损失=1.0314061641693115，生成损失=1.3215749263763428, real_dmean=0.5213561654090881, fake_dmean=0.24273818731307983\n",
      "第2迭代下第530批次: 判别损失=0.7684959769248962，生成损失=2.3243134021759033, real_dmean=0.797888994216919, fake_dmean=0.38664478063583374\n",
      "第2迭代下第540批次: 判别损失=0.9415321350097656，生成损失=2.7442445755004883, real_dmean=0.7946880459785461, fake_dmean=0.473494291305542\n",
      "第2迭代下第550批次: 判别损失=0.8783721923828125，生成损失=1.4483582973480225, real_dmean=0.6218076944351196, fake_dmean=0.2743355333805084\n",
      "第2迭代下第560批次: 判别损失=0.5643004179000854，生成损失=2.2011380195617676, real_dmean=0.7930079102516174, fake_dmean=0.26148247718811035\n",
      "第2迭代下第570批次: 判别损失=1.128904104232788，生成损失=1.1326905488967896, real_dmean=0.4036472737789154, fake_dmean=0.07908930629491806\n",
      "第2迭代下第580批次: 判别损失=1.1173009872436523，生成损失=0.9140997529029846, real_dmean=0.4162571430206299, fake_dmean=0.10859470069408417\n",
      "第2迭代下第590批次: 判别损失=0.9887169599533081，生成损失=1.486484408378601, real_dmean=0.4722958505153656, fake_dmean=0.13881909847259521\n",
      "第2迭代下第600批次: 判别损失=0.7209118604660034，生成损失=2.2686338424682617, real_dmean=0.8339181542396545, fake_dmean=0.3978550434112549\n",
      "第2迭代下第610批次: 判别损失=0.5976289510726929，生成损失=2.2369213104248047, real_dmean=0.7040309906005859, fake_dmean=0.185467928647995\n",
      "第2迭代下第620批次: 判别损失=1.19332754611969，生成损失=2.3752355575561523, real_dmean=0.7757099270820618, fake_dmean=0.5592203140258789\n",
      "第2迭代下第630批次: 判别损失=0.9166741371154785，生成损失=1.1776955127716064, real_dmean=0.5574206113815308, fake_dmean=0.21556977927684784\n",
      "第2迭代下第640批次: 判别损失=0.7841833233833313，生成损失=1.1814769506454468, real_dmean=0.604169487953186, fake_dmean=0.20452654361724854\n",
      "第2迭代下第650批次: 判别损失=0.7683080434799194，生成损失=2.158613681793213, real_dmean=0.7858681678771973, fake_dmean=0.3779364824295044\n",
      "第2迭代下第660批次: 判别损失=0.8672124743461609，生成损失=2.433204174041748, real_dmean=0.8604580760002136, fake_dmean=0.48127034306526184\n",
      "第2迭代下第670批次: 判别损失=0.8321831226348877，生成损失=1.5358949899673462, real_dmean=0.7980778217315674, fake_dmean=0.42120781540870667\n",
      "第2迭代下第680批次: 判别损失=1.2831755876541138，生成损失=0.8427595496177673, real_dmean=0.3654271066188812, fake_dmean=0.14488866925239563\n",
      "第2迭代下第690批次: 判别损失=0.8933433294296265，生成损失=1.8390045166015625, real_dmean=0.7094910144805908, fake_dmean=0.377707839012146\n",
      "第2迭代下第700批次: 判别损失=1.0949057340621948，生成损失=0.669901967048645, real_dmean=0.4630200266838074, fake_dmean=0.20680898427963257\n",
      "第2迭代下第710批次: 判别损失=0.9026535749435425，生成损失=1.7843315601348877, real_dmean=0.7485883831977844, fake_dmean=0.4098764955997467\n",
      "第2迭代下第720批次: 判别损失=0.7603191137313843，生成损失=1.5621073246002197, real_dmean=0.6284195184707642, fake_dmean=0.20256537199020386\n",
      "第2迭代下第730批次: 判别损失=0.9671574831008911，生成损失=1.460699439048767, real_dmean=0.617701530456543, fake_dmean=0.32129666209220886\n",
      "第2迭代下第740批次: 判别损失=0.6620163917541504，生成损失=2.2045681476593018, real_dmean=0.709972083568573, fake_dmean=0.23914963006973267\n",
      "第2迭代下第750批次: 判别损失=0.7681074738502502，生成损失=1.9552083015441895, real_dmean=0.7296040058135986, fake_dmean=0.3253370225429535\n",
      "第2迭代下第760批次: 判别损失=0.8230205774307251，生成损失=1.591690182685852, real_dmean=0.6585493087768555, fake_dmean=0.2931118607521057\n",
      "第2迭代下第770批次: 判别损失=0.9623204469680786，生成损失=1.5491125583648682, real_dmean=0.6701929569244385, fake_dmean=0.3786950409412384\n",
      "第2迭代下第780批次: 判别损失=0.9398669004440308，生成损失=1.3381150960922241, real_dmean=0.553321361541748, fake_dmean=0.21169498562812805\n",
      "第3迭代下第0批次: 判别损失=0.7931891083717346，生成损失=2.9200005531311035, real_dmean=0.8492002487182617, fake_dmean=0.4328244626522064\n",
      "第3迭代下第10批次: 判别损失=0.8032049536705017，生成损失=2.018028736114502, real_dmean=0.8341346979141235, fake_dmean=0.4237350821495056\n",
      "第3迭代下第20批次: 判别损失=1.1028895378112793，生成损失=1.693439245223999, real_dmean=0.6278614401817322, fake_dmean=0.41750481724739075\n",
      "第3迭代下第30批次: 判别损失=0.8537122011184692，生成损失=2.1325602531433105, real_dmean=0.670615017414093, fake_dmean=0.3246033787727356\n",
      "第3迭代下第40批次: 判别损失=0.9955211877822876，生成损失=1.0287094116210938, real_dmean=0.523895263671875, fake_dmean=0.232464000582695\n",
      "第3迭代下第50批次: 判别损失=0.6186498403549194，生成损失=1.9085923433303833, real_dmean=0.7346760034561157, fake_dmean=0.24440905451774597\n",
      "第3迭代下第60批次: 判别损失=0.9904651045799255，生成损失=2.1352906227111816, real_dmean=0.7212778329849243, fake_dmean=0.4389691948890686\n",
      "第3迭代下第70批次: 判别损失=0.9315340518951416，生成损失=1.525313138961792, real_dmean=0.6289339661598206, fake_dmean=0.3175332248210907\n",
      "第3迭代下第80批次: 判别损失=0.9426535367965698，生成损失=2.684490203857422, real_dmean=0.8351261615753174, fake_dmean=0.4953075051307678\n",
      "第3迭代下第90批次: 判别损失=1.033154845237732，生成损失=2.787209987640381, real_dmean=0.7994083762168884, fake_dmean=0.5032671689987183\n",
      "第3迭代下第100批次: 判别损失=0.8438365459442139，生成损失=1.4616177082061768, real_dmean=0.579018235206604, fake_dmean=0.2111389935016632\n",
      "第3迭代下第110批次: 判别损失=1.0539919137954712，生成损失=1.3666601181030273, real_dmean=0.4718581438064575, fake_dmean=0.1510845571756363\n",
      "第3迭代下第120批次: 判别损失=0.8864409923553467，生成损失=2.6750986576080322, real_dmean=0.8544740676879883, fake_dmean=0.4767540991306305\n",
      "第3迭代下第130批次: 判别损失=0.7562492489814758，生成损失=2.2034618854522705, real_dmean=0.8219344615936279, fake_dmean=0.3889562487602234\n",
      "第3迭代下第140批次: 判别损失=1.1094032526016235，生成损失=2.728239059448242, real_dmean=0.8816521763801575, fake_dmean=0.5847300887107849\n",
      "第3迭代下第150批次: 判别损失=0.8731848001480103，生成损失=2.209228992462158, real_dmean=0.7295643091201782, fake_dmean=0.37558043003082275\n",
      "第3迭代下第160批次: 判别损失=0.820950984954834，生成损失=1.1449795961380005, real_dmean=0.5942417979240417, fake_dmean=0.1924741566181183\n",
      "第3迭代下第170批次: 判别损失=1.0939922332763672，生成损失=2.4125051498413086, real_dmean=0.759792149066925, fake_dmean=0.5019221901893616\n",
      "第3迭代下第180批次: 判别损失=0.941398024559021，生成损失=1.5107120275497437, real_dmean=0.6258776783943176, fake_dmean=0.3320896327495575\n",
      "第3迭代下第190批次: 判别损失=0.8070990443229675，生成损失=1.9998183250427246, real_dmean=0.7667008638381958, fake_dmean=0.38117092847824097\n",
      "第3迭代下第200批次: 判别损失=0.9103643894195557，生成损失=2.041226625442505, real_dmean=0.77137291431427, fake_dmean=0.44120216369628906\n",
      "第3迭代下第210批次: 判别损失=0.6742979288101196，生成损失=1.5702464580535889, real_dmean=0.6473997235298157, fake_dmean=0.17280367016792297\n",
      "第3迭代下第220批次: 判别损失=0.744660496711731，生成损失=1.6934242248535156, real_dmean=0.7393445372581482, fake_dmean=0.32737404108047485\n",
      "第3迭代下第230批次: 判别损失=0.9773728251457214，生成损失=2.3833155632019043, real_dmean=0.7781452536582947, fake_dmean=0.4762287139892578\n",
      "第3迭代下第240批次: 判别损失=0.8060178756713867，生成损失=2.0735630989074707, real_dmean=0.7424676418304443, fake_dmean=0.3582940995693207\n",
      "第3迭代下第250批次: 判别损失=0.9607065916061401，生成损失=2.5576746463775635, real_dmean=0.8373910188674927, fake_dmean=0.5005420446395874\n",
      "第3迭代下第260批次: 判别损失=0.9537202715873718，生成损失=2.888103723526001, real_dmean=0.9135247468948364, fake_dmean=0.547295868396759\n",
      "第3迭代下第270批次: 判别损失=1.5782811641693115，生成损失=0.9583852291107178, real_dmean=0.2750200629234314, fake_dmean=0.08009251207113266\n",
      "第3迭代下第280批次: 判别损失=0.6444345712661743，生成损失=1.797499179840088, real_dmean=0.6796736121177673, fake_dmean=0.19117726385593414\n",
      "第3迭代下第290批次: 判别损失=0.8382120728492737，生成损失=1.701207160949707, real_dmean=0.6919121146202087, fake_dmean=0.3383675217628479\n",
      "第3迭代下第300批次: 判别损失=1.1143054962158203，生成损失=1.1234792470932007, real_dmean=0.4432861804962158, fake_dmean=0.17766274511814117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3迭代下第310批次: 判别损失=0.9825531244277954，生成损失=1.5313071012496948, real_dmean=0.5475177764892578, fake_dmean=0.24575954675674438\n",
      "第3迭代下第320批次: 判别损失=0.8213165998458862，生成损失=1.0514438152313232, real_dmean=0.5614204406738281, fake_dmean=0.17029064893722534\n",
      "第3迭代下第330批次: 判别损失=0.9646046161651611，生成损失=1.873784065246582, real_dmean=0.6733965277671814, fake_dmean=0.3873012363910675\n",
      "第3迭代下第340批次: 判别损失=1.0451691150665283，生成损失=1.1312097311019897, real_dmean=0.5070217847824097, fake_dmean=0.2261974811553955\n",
      "第3迭代下第350批次: 判别损失=1.158441185951233，生成损失=0.8278856873512268, real_dmean=0.3864557445049286, fake_dmean=0.10617391020059586\n",
      "第3迭代下第360批次: 判别损失=0.9144200086593628，生成损失=1.881060242652893, real_dmean=0.6872055530548096, fake_dmean=0.36352360248565674\n",
      "第3迭代下第370批次: 判别损失=0.904952883720398，生成损失=1.8632904291152954, real_dmean=0.6952926516532898, fake_dmean=0.38598236441612244\n",
      "第3迭代下第380批次: 判别损失=0.9134103059768677，生成损失=1.4466370344161987, real_dmean=0.5784772634506226, fake_dmean=0.2633182108402252\n",
      "第3迭代下第390批次: 判别损失=0.8921165466308594，生成损失=1.0535204410552979, real_dmean=0.5734865069389343, fake_dmean=0.24065017700195312\n",
      "第3迭代下第400批次: 判别损失=0.8640540838241577，生成损失=2.3765692710876465, real_dmean=0.7764182090759277, fake_dmean=0.4219358265399933\n",
      "第3迭代下第410批次: 判别损失=0.7348095774650574，生成损失=1.861952781677246, real_dmean=0.7382230162620544, fake_dmean=0.3206580877304077\n",
      "第3迭代下第420批次: 判别损失=1.060932993888855，生成损失=1.7267178297042847, real_dmean=0.8076327443122864, fake_dmean=0.5377310514450073\n",
      "第3迭代下第430批次: 判别损失=0.8305865526199341，生成损失=1.4405086040496826, real_dmean=0.6786309480667114, fake_dmean=0.3091035783290863\n",
      "第3迭代下第440批次: 判别损失=1.0008881092071533，生成损失=1.0245959758758545, real_dmean=0.4954308867454529, fake_dmean=0.18440331518650055\n",
      "第3迭代下第450批次: 判别损失=0.845515251159668，生成损失=1.3812483549118042, real_dmean=0.6034166812896729, fake_dmean=0.24519991874694824\n",
      "第3迭代下第460批次: 判别损失=0.8112422227859497，生成损失=2.406825065612793, real_dmean=0.7950019240379333, fake_dmean=0.4074995219707489\n",
      "第3迭代下第470批次: 判别损失=1.1596344709396362，生成损失=2.916712522506714, real_dmean=0.877687394618988, fake_dmean=0.6008185744285583\n",
      "第3迭代下第480批次: 判别损失=1.052958369255066，生成损失=2.407193183898926, real_dmean=0.8395806550979614, fake_dmean=0.5390335321426392\n",
      "第3迭代下第490批次: 判别损失=0.8314354419708252，生成损失=1.8689179420471191, real_dmean=0.6667451858520508, fake_dmean=0.30205556750297546\n",
      "第3迭代下第500批次: 判别损失=1.0998756885528564，生成损失=1.753405213356018, real_dmean=0.7549582719802856, fake_dmean=0.5110400319099426\n",
      "第3迭代下第510批次: 判别损失=0.9889572858810425，生成损失=1.2892009019851685, real_dmean=0.5748728513717651, fake_dmean=0.29548487067222595\n",
      "第3迭代下第520批次: 判别损失=0.8075694441795349，生成损失=2.1178414821624756, real_dmean=0.7140830755233765, fake_dmean=0.33909404277801514\n",
      "第3迭代下第530批次: 判别损失=0.8827143907546997，生成损失=1.5286576747894287, real_dmean=0.6502104997634888, fake_dmean=0.30655771493911743\n",
      "第3迭代下第540批次: 判别损失=0.9600452184677124，生成损失=2.5225815773010254, real_dmean=0.7075102925300598, fake_dmean=0.417921245098114\n",
      "第3迭代下第550批次: 判别损失=0.9173433184623718，生成损失=1.2359375953674316, real_dmean=0.5408802628517151, fake_dmean=0.2044084221124649\n",
      "第3迭代下第560批次: 判别损失=0.8451557159423828，生成损失=1.2293740510940552, real_dmean=0.5834958553314209, fake_dmean=0.20955777168273926\n",
      "第3迭代下第570批次: 判别损失=0.701627790927887，生成损失=1.8260501623153687, real_dmean=0.6656529307365417, fake_dmean=0.22458353638648987\n",
      "第3迭代下第580批次: 判别损失=0.7242205142974854，生成损失=2.273214817047119, real_dmean=0.7473110556602478, fake_dmean=0.3238576650619507\n",
      "第3迭代下第590批次: 判别损失=0.8984655737876892，生成损失=1.5633833408355713, real_dmean=0.5214958786964417, fake_dmean=0.1597367823123932\n",
      "第3迭代下第600批次: 判别损失=0.8653876185417175，生成损失=1.5611249208450317, real_dmean=0.6061022877693176, fake_dmean=0.2484138458967209\n",
      "第3迭代下第610批次: 判别损失=0.9482150673866272，生成损失=3.113264560699463, real_dmean=0.8893243670463562, fake_dmean=0.5160322785377502\n",
      "第3迭代下第620批次: 判别损失=0.8997237682342529，生成损失=1.1525483131408691, real_dmean=0.5374499559402466, fake_dmean=0.190992534160614\n",
      "第3迭代下第630批次: 判别损失=0.6237181425094604，生成损失=2.1655542850494385, real_dmean=0.8325072526931763, fake_dmean=0.33621278405189514\n",
      "第3迭代下第640批次: 判别损失=1.1944489479064941，生成损失=2.925363063812256, real_dmean=0.8788090944290161, fake_dmean=0.6009315848350525\n",
      "第3迭代下第650批次: 判别损失=0.7000985145568848，生成损失=1.678778886795044, real_dmean=0.6854454874992371, fake_dmean=0.2267419695854187\n",
      "第3迭代下第660批次: 判别损失=1.227490782737732，生成损失=2.2710652351379395, real_dmean=0.7448161840438843, fake_dmean=0.5564212799072266\n",
      "第3迭代下第670批次: 判别损失=0.7506778836250305，生成损失=2.3835716247558594, real_dmean=0.8028377294540405, fake_dmean=0.37277719378471375\n",
      "第3迭代下第680批次: 判别损失=1.6339668035507202，生成损失=4.743674278259277, real_dmean=0.9015018939971924, fake_dmean=0.7325586676597595\n",
      "第3迭代下第690批次: 判别损失=0.8464621901512146，生成损失=1.9734551906585693, real_dmean=0.7302197813987732, fake_dmean=0.37401869893074036\n",
      "第3迭代下第700批次: 判别损失=0.8688323497772217，生成损失=2.0257139205932617, real_dmean=0.8368022441864014, fake_dmean=0.4665737450122833\n",
      "第3迭代下第710批次: 判别损失=0.8410276174545288，生成损失=1.9213964939117432, real_dmean=0.6773366332054138, fake_dmean=0.3221137225627899\n",
      "第3迭代下第720批次: 判别损失=0.8195196986198425，生成损失=2.005815029144287, real_dmean=0.7366480231285095, fake_dmean=0.363756000995636\n",
      "第3迭代下第730批次: 判别损失=0.8052110075950623，生成损失=2.431819438934326, real_dmean=0.8401191234588623, fake_dmean=0.426874041557312\n",
      "第3迭代下第740批次: 判别损失=0.8215849995613098，生成损失=1.9240784645080566, real_dmean=0.8095331788063049, fake_dmean=0.41803374886512756\n",
      "第3迭代下第750批次: 判别损失=0.7568776607513428，生成损失=1.5448545217514038, real_dmean=0.6464848518371582, fake_dmean=0.22100837528705597\n",
      "第3迭代下第760批次: 判别损失=0.7479184865951538，生成损失=1.373643159866333, real_dmean=0.7109599113464355, fake_dmean=0.3031807541847229\n",
      "第3迭代下第770批次: 判别损失=0.8615045547485352，生成损失=1.5451576709747314, real_dmean=0.6896190047264099, fake_dmean=0.3433535695075989\n",
      "第3迭代下第780批次: 判别损失=0.7569586634635925，生成损失=2.124394178390503, real_dmean=0.7253032326698303, fake_dmean=0.3221612274646759\n",
      "第4迭代下第0批次: 判别损失=0.9633815288543701，生成损失=2.065289258956909, real_dmean=0.7446575164794922, fake_dmean=0.43207722902297974\n",
      "第4迭代下第10批次: 判别损失=0.9919608235359192，生成损失=2.5768446922302246, real_dmean=0.7825015783309937, fake_dmean=0.48920294642448425\n",
      "第4迭代下第20批次: 判别损失=0.8379385471343994，生成损失=1.4722836017608643, real_dmean=0.6406641006469727, fake_dmean=0.2813571095466614\n",
      "第4迭代下第30批次: 判别损失=0.9472875595092773，生成损失=2.6730308532714844, real_dmean=0.8563079237937927, fake_dmean=0.5104958415031433\n",
      "第4迭代下第40批次: 判别损失=0.6539444923400879，生成损失=1.866477370262146, real_dmean=0.7499279379844666, fake_dmean=0.27797409892082214\n",
      "第4迭代下第50批次: 判别损失=0.8757471442222595，生成损失=2.9881644248962402, real_dmean=0.8813776969909668, fake_dmean=0.4977821707725525\n",
      "第4迭代下第60批次: 判别损失=0.987738847732544，生成损失=1.1617445945739746, real_dmean=0.6033104658126831, fake_dmean=0.3392380475997925\n",
      "第4迭代下第70批次: 判别损失=0.9010923504829407，生成损失=1.0756112337112427, real_dmean=0.5346049070358276, fake_dmean=0.17965640127658844\n",
      "第4迭代下第80批次: 判别损失=0.6589707136154175，生成损失=2.1835737228393555, real_dmean=0.6959260106086731, fake_dmean=0.22735947370529175\n",
      "第4迭代下第90批次: 判别损失=0.8603898286819458，生成损失=2.068683624267578, real_dmean=0.8240268230438232, fake_dmean=0.4446583390235901\n",
      "第4迭代下第100批次: 判别损失=0.786118745803833，生成损失=2.1004068851470947, real_dmean=0.7442106008529663, fake_dmean=0.35675758123397827\n",
      "第4迭代下第110批次: 判别损失=0.7798200845718384，生成损失=1.7886841297149658, real_dmean=0.6958211660385132, fake_dmean=0.2988721430301666\n",
      "第4迭代下第120批次: 判别损失=0.8804782032966614，生成损失=1.3349709510803223, real_dmean=0.5482792854309082, fake_dmean=0.19582033157348633\n",
      "第4迭代下第130批次: 判别损失=0.8504517078399658，生成损失=1.4093337059020996, real_dmean=0.5457007884979248, fake_dmean=0.16102299094200134\n",
      "第4迭代下第140批次: 判别损失=1.0077611207962036，生成损失=0.9430567026138306, real_dmean=0.4924554228782654, fake_dmean=0.2028511017560959\n",
      "第4迭代下第150批次: 判别损失=0.9474260807037354，生成损失=1.8427581787109375, real_dmean=0.7214558720588684, fake_dmean=0.3988890051841736\n",
      "第4迭代下第160批次: 判别损失=0.8372141122817993，生成损失=1.7276486158370972, real_dmean=0.7006316184997559, fake_dmean=0.3332844376564026\n",
      "第4迭代下第170批次: 判别损失=0.6863535642623901，生成损失=1.995038390159607, real_dmean=0.6793755292892456, fake_dmean=0.2233503758907318\n",
      "第4迭代下第180批次: 判别损失=0.7197436094284058，生成损失=1.488279104232788, real_dmean=0.6256901025772095, fake_dmean=0.1619814783334732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第4迭代下第190批次: 判别损失=0.7573649883270264，生成损失=2.0232551097869873, real_dmean=0.7141498923301697, fake_dmean=0.30415359139442444\n",
      "第4迭代下第200批次: 判别损失=0.8299887776374817，生成损失=1.2211434841156006, real_dmean=0.5922507047653198, fake_dmean=0.2104376256465912\n",
      "第4迭代下第210批次: 判别损失=0.8483108878135681，生成损失=2.9128921031951904, real_dmean=0.8348453044891357, fake_dmean=0.44958049058914185\n",
      "第4迭代下第220批次: 判别损失=1.0201860666275024，生成损失=2.160428762435913, real_dmean=0.7710274457931519, fake_dmean=0.49344027042388916\n",
      "第4迭代下第230批次: 判别损失=0.7923223972320557，生成损失=1.1254520416259766, real_dmean=0.6014729738235474, fake_dmean=0.19534361362457275\n",
      "第4迭代下第240批次: 判别损失=0.7721803784370422，生成损失=1.7113230228424072, real_dmean=0.7172958850860596, fake_dmean=0.29759785532951355\n",
      "第4迭代下第250批次: 判别损失=0.9544878602027893，生成损失=2.605454444885254, real_dmean=0.8075067400932312, fake_dmean=0.4894712567329407\n",
      "第4迭代下第260批次: 判别损失=0.9419422149658203，生成损失=1.3521279096603394, real_dmean=0.643488883972168, fake_dmean=0.357135146856308\n",
      "第4迭代下第270批次: 判别损失=0.8243013024330139，生成损失=2.302624464035034, real_dmean=0.7443985939025879, fake_dmean=0.3766804337501526\n",
      "第4迭代下第280批次: 判别损失=1.0149176120758057，生成损失=1.4933592081069946, real_dmean=0.5755574703216553, fake_dmean=0.2990611791610718\n",
      "第4迭代下第290批次: 判别损失=1.155701994895935，生成损失=0.7835653424263, real_dmean=0.4113646149635315, fake_dmean=0.14500223100185394\n",
      "第4迭代下第300批次: 判别损失=0.7997066974639893，生成损失=1.3152070045471191, real_dmean=0.6251159906387329, fake_dmean=0.23409441113471985\n",
      "第4迭代下第310批次: 判别损失=0.9039074182510376，生成损失=1.3538395166397095, real_dmean=0.5852276086807251, fake_dmean=0.2582259178161621\n",
      "第4迭代下第320批次: 判别损失=0.8775697350502014，生成损失=3.1379151344299316, real_dmean=0.8421577215194702, fake_dmean=0.47295090556144714\n",
      "第4迭代下第330批次: 判别损失=0.7501184940338135，生成损失=1.8698433637619019, real_dmean=0.8070537447929382, fake_dmean=0.38337743282318115\n",
      "第4迭代下第340批次: 判别损失=0.7346897125244141，生成损失=1.9509289264678955, real_dmean=0.6532297134399414, fake_dmean=0.22608590126037598\n",
      "第4迭代下第350批次: 判别损失=0.8514488935470581，生成损失=1.370880365371704, real_dmean=0.6021398305892944, fake_dmean=0.2485860288143158\n",
      "第4迭代下第360批次: 判别损失=1.0098567008972168，生成损失=0.7303279042243958, real_dmean=0.49318668246269226, fake_dmean=0.1998920440673828\n",
      "第4迭代下第370批次: 判别损失=0.7608107924461365，生成损失=1.0769562721252441, real_dmean=0.6173135042190552, fake_dmean=0.1935131549835205\n",
      "第4迭代下第380批次: 判别损失=0.9470169544219971，生成损失=0.9671635031700134, real_dmean=0.5352264046669006, fake_dmean=0.21021048724651337\n",
      "第4迭代下第390批次: 判别损失=1.0651473999023438，生成损失=2.7804954051971436, real_dmean=0.8443136215209961, fake_dmean=0.5467384457588196\n",
      "第4迭代下第400批次: 判别损失=0.8489024639129639，生成损失=2.206573009490967, real_dmean=0.6988829970359802, fake_dmean=0.3428837060928345\n",
      "第4迭代下第410批次: 判别损失=0.7307844161987305，生成损失=1.8663324117660522, real_dmean=0.5912154912948608, fake_dmean=0.1317126750946045\n",
      "第4迭代下第420批次: 判别损失=0.6674953699111938，生成损失=1.5459643602371216, real_dmean=0.6665517091751099, fake_dmean=0.18937130272388458\n",
      "第4迭代下第430批次: 判别损失=1.2284774780273438，生成损失=2.408726453781128, real_dmean=0.7829866409301758, fake_dmean=0.5834120512008667\n",
      "第4迭代下第440批次: 判别损失=0.8367188572883606，生成损失=1.5136799812316895, real_dmean=0.5576565861701965, fake_dmean=0.14864368736743927\n",
      "第4迭代下第450批次: 判别损失=0.7493054270744324，生成损失=1.6223918199539185, real_dmean=0.6932600736618042, fake_dmean=0.2784716784954071\n",
      "第4迭代下第460批次: 判别损失=0.8173221349716187，生成损失=1.431612491607666, real_dmean=0.6351333260536194, fake_dmean=0.2526771128177643\n",
      "第4迭代下第470批次: 判别损失=0.9350124597549438，生成损失=1.4676430225372314, real_dmean=0.5521601438522339, fake_dmean=0.22487911581993103\n",
      "第4迭代下第480批次: 判别损失=0.7895417213439941，生成损失=1.8953778743743896, real_dmean=0.752743124961853, fake_dmean=0.3686518967151642\n",
      "第4迭代下第490批次: 判别损失=0.8275768756866455，生成损失=1.3560799360275269, real_dmean=0.5547111630439758, fake_dmean=0.15943098068237305\n",
      "第4迭代下第500批次: 判别损失=0.8482061624526978，生成损失=1.2557810544967651, real_dmean=0.5414543151855469, fake_dmean=0.15515407919883728\n",
      "第4迭代下第510批次: 判别损失=0.7900093197822571，生成损失=1.56148362159729, real_dmean=0.6175674796104431, fake_dmean=0.2051314413547516\n",
      "第4迭代下第520批次: 判别损失=0.7806981205940247，生成损失=1.3103793859481812, real_dmean=0.6765257716178894, fake_dmean=0.2811588943004608\n",
      "第4迭代下第530批次: 判别损失=0.8735981583595276，生成损失=1.6424052715301514, real_dmean=0.5936382412910461, fake_dmean=0.23953554034233093\n",
      "第4迭代下第540批次: 判别损失=0.7398510575294495，生成损失=1.4575494527816772, real_dmean=0.5910310745239258, fake_dmean=0.1336325854063034\n",
      "第4迭代下第550批次: 判别损失=1.0964394807815552，生成损失=2.758237838745117, real_dmean=0.8653814196586609, fake_dmean=0.561276912689209\n",
      "第4迭代下第560批次: 判别损失=1.1937575340270996，生成损失=0.669877290725708, real_dmean=0.4245966970920563, fake_dmean=0.18167796730995178\n",
      "第4迭代下第570批次: 判别损失=1.0269641876220703，生成损失=3.2510271072387695, real_dmean=0.8903645873069763, fake_dmean=0.5594269037246704\n",
      "第4迭代下第580批次: 判别损失=0.78098464012146，生成损失=2.131051540374756, real_dmean=0.7657051682472229, fake_dmean=0.36649781465530396\n",
      "第4迭代下第590批次: 判别损失=0.7132615447044373，生成损失=2.071424961090088, real_dmean=0.7392858266830444, fake_dmean=0.3031262159347534\n",
      "第4迭代下第600批次: 判别损失=0.8081773519515991，生成损失=2.5453615188598633, real_dmean=0.8124566078186035, fake_dmean=0.40311703085899353\n",
      "第4迭代下第610批次: 判别损失=0.8289295434951782，生成损失=1.3786253929138184, real_dmean=0.5842617154121399, fake_dmean=0.19075384736061096\n",
      "第4迭代下第620批次: 判别损失=0.8231360912322998，生成损失=2.084641456604004, real_dmean=0.779259443283081, fake_dmean=0.40268969535827637\n",
      "第4迭代下第630批次: 判别损失=0.7420173287391663，生成损失=2.122593641281128, real_dmean=0.7914837002754211, fake_dmean=0.36758968234062195\n",
      "第4迭代下第640批次: 判别损失=0.8812709450721741，生成损失=0.9572641253471375, real_dmean=0.5197147727012634, fake_dmean=0.15030591189861298\n",
      "第4迭代下第650批次: 判别损失=0.7466365098953247，生成损失=2.3417718410491943, real_dmean=0.7704753875732422, fake_dmean=0.35075393319129944\n",
      "第4迭代下第660批次: 判别损失=0.8120115995407104，生成损失=1.227526307106018, real_dmean=0.5969177484512329, fake_dmean=0.20180214941501617\n",
      "第4迭代下第670批次: 判别损失=0.901227593421936，生成损失=1.6445269584655762, real_dmean=0.6585358381271362, fake_dmean=0.33802950382232666\n",
      "第4迭代下第680批次: 判别损失=0.65152508020401，生成损失=2.1856331825256348, real_dmean=0.7204552888870239, fake_dmean=0.23951949179172516\n",
      "第4迭代下第690批次: 判别损失=0.7177284359931946，生成损失=1.4532560110092163, real_dmean=0.6287592649459839, fake_dmean=0.17687666416168213\n",
      "第4迭代下第700批次: 判别损失=0.7512116432189941，生成损失=1.8188077211380005, real_dmean=0.7141551375389099, fake_dmean=0.3074936866760254\n",
      "第4迭代下第710批次: 判别损失=0.7595500946044922，生成损失=1.611750841140747, real_dmean=0.7103469371795654, fake_dmean=0.28760793805122375\n",
      "第4迭代下第720批次: 判别损失=0.8428446054458618，生成损失=1.5307881832122803, real_dmean=0.5897500514984131, fake_dmean=0.205253466963768\n",
      "第4迭代下第730批次: 判别损失=0.6095167994499207，生成损失=1.9345118999481201, real_dmean=0.719624400138855, fake_dmean=0.20717737078666687\n",
      "第4迭代下第740批次: 判别损失=1.1336896419525146，生成损失=2.0741684436798096, real_dmean=0.5947403311729431, fake_dmean=0.37129274010658264\n",
      "第4迭代下第750批次: 判别损失=1.0387670993804932，生成损失=2.5766305923461914, real_dmean=0.8816649317741394, fake_dmean=0.5508123636245728\n",
      "第4迭代下第760批次: 判别损失=0.8207688927650452，生成损失=1.4119210243225098, real_dmean=0.5873028635978699, fake_dmean=0.20032942295074463\n",
      "第4迭代下第770批次: 判别损失=0.7776768803596497，生成损失=2.1117935180664062, real_dmean=0.6867290139198303, fake_dmean=0.27496835589408875\n",
      "第4迭代下第780批次: 判别损失=0.8919438719749451，生成损失=1.655316948890686, real_dmean=0.6128255128860474, fake_dmean=0.26491257548332214\n",
      "第5迭代下第0批次: 判别损失=1.0629922151565552，生成损失=3.320507287979126, real_dmean=0.794757604598999, fake_dmean=0.5031309723854065\n",
      "第5迭代下第10批次: 判别损失=0.7655415534973145，生成损失=1.8319894075393677, real_dmean=0.722650408744812, fake_dmean=0.3088914155960083\n",
      "第5迭代下第20批次: 判别损失=0.8970357775688171，生成损失=2.788540840148926, real_dmean=0.8439353704452515, fake_dmean=0.4749915897846222\n",
      "第5迭代下第30批次: 判别损失=1.0093128681182861，生成损失=1.5459847450256348, real_dmean=0.6591150760650635, fake_dmean=0.38223791122436523\n",
      "第5迭代下第40批次: 判别损失=0.652701735496521，生成损失=2.04192852973938, real_dmean=0.7905625700950623, fake_dmean=0.30310723185539246\n",
      "第5迭代下第50批次: 判别损失=0.7560641169548035，生成损失=1.4571359157562256, real_dmean=0.6500864028930664, fake_dmean=0.2273074984550476\n",
      "第5迭代下第60批次: 判别损失=0.6192604899406433，生成损失=2.047013759613037, real_dmean=0.703326940536499, fake_dmean=0.196397066116333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5迭代下第70批次: 判别损失=0.9857097864151001，生成损失=2.712428569793701, real_dmean=0.8271898627281189, fake_dmean=0.5012500882148743\n",
      "第5迭代下第80批次: 判别损失=0.8396402597427368，生成损失=2.6061506271362305, real_dmean=0.8104336261749268, fake_dmean=0.428183376789093\n",
      "第5迭代下第90批次: 判别损失=0.8827073574066162，生成损失=1.921209454536438, real_dmean=0.7514320015907288, fake_dmean=0.408672958612442\n",
      "第5迭代下第100批次: 判别损失=0.9021351337432861，生成损失=1.9258627891540527, real_dmean=0.6601077318191528, fake_dmean=0.33706504106521606\n",
      "第5迭代下第110批次: 判别损失=0.7658358812332153，生成损失=2.8268380165100098, real_dmean=0.8257181644439697, fake_dmean=0.3970542252063751\n",
      "第5迭代下第120批次: 判别损失=1.091932773590088，生成损失=2.561023473739624, real_dmean=0.7255159616470337, fake_dmean=0.4876050353050232\n",
      "第5迭代下第130批次: 判别损失=0.7699039578437805，生成损失=2.427572727203369, real_dmean=0.7888182401657104, fake_dmean=0.3850249648094177\n",
      "第5迭代下第140批次: 判别损失=0.7608299255371094，生成损失=1.6423007249832153, real_dmean=0.6539905667304993, fake_dmean=0.2488734871149063\n",
      "第5迭代下第150批次: 判别损失=0.8529627323150635，生成损失=2.885730743408203, real_dmean=0.8998554944992065, fake_dmean=0.47782158851623535\n",
      "第5迭代下第160批次: 判别损失=0.7171692252159119，生成损失=2.1646482944488525, real_dmean=0.704911470413208, fake_dmean=0.26368996500968933\n",
      "第5迭代下第170批次: 判别损失=1.331882357597351，生成损失=2.9609410762786865, real_dmean=0.8655163049697876, fake_dmean=0.6379148960113525\n",
      "第5迭代下第180批次: 判别损失=0.6530311703681946，生成损失=1.4714380502700806, real_dmean=0.6403342485427856, fake_dmean=0.15113231539726257\n",
      "第5迭代下第190批次: 判别损失=0.8995693922042847，生成损失=1.0837619304656982, real_dmean=0.513939619064331, fake_dmean=0.1344822347164154\n",
      "第5迭代下第200批次: 判别损失=1.0397332906723022，生成损失=1.017311930656433, real_dmean=0.43907856941223145, fake_dmean=0.11789567768573761\n",
      "第5迭代下第210批次: 判别损失=0.9314810037612915，生成损失=2.7124650478363037, real_dmean=0.8741172552108765, fake_dmean=0.5165813565254211\n",
      "第5迭代下第220批次: 判别损失=0.9780478477478027，生成损失=1.2978429794311523, real_dmean=0.6719456911087036, fake_dmean=0.37998417019844055\n",
      "第5迭代下第230批次: 判别损失=0.9823275804519653，生成损失=2.2096452713012695, real_dmean=0.8056920766830444, fake_dmean=0.48328205943107605\n",
      "第5迭代下第240批次: 判别损失=0.6285861730575562，生成损失=2.207275629043579, real_dmean=0.7896743416786194, fake_dmean=0.2940106987953186\n",
      "第5迭代下第250批次: 判别损失=0.5985740423202515，生成损失=2.3202667236328125, real_dmean=0.7545275688171387, fake_dmean=0.2400219440460205\n",
      "第5迭代下第260批次: 判别损失=0.7375215291976929，生成损失=2.565882444381714, real_dmean=0.8655543923377991, fake_dmean=0.41294848918914795\n",
      "第5迭代下第270批次: 判别损失=0.846468448638916，生成损失=1.6044389009475708, real_dmean=0.5717836022377014, fake_dmean=0.20273517072200775\n",
      "第5迭代下第280批次: 判别损失=0.929703950881958，生成损失=3.372654676437378, real_dmean=0.8671881556510925, fake_dmean=0.48862501978874207\n",
      "第5迭代下第290批次: 判别损失=0.8275241255760193，生成损失=2.6698741912841797, real_dmean=0.7973567843437195, fake_dmean=0.41110455989837646\n",
      "第5迭代下第300批次: 判别损失=0.657257616519928，生成损失=2.04990291595459, real_dmean=0.7449413537979126, fake_dmean=0.2746768891811371\n",
      "第5迭代下第310批次: 判别损失=0.6630685329437256，生成损失=2.5909900665283203, real_dmean=0.6729161739349365, fake_dmean=0.18241718411445618\n",
      "第5迭代下第320批次: 判别损失=0.8711358308792114，生成损失=1.3908767700195312, real_dmean=0.633969783782959, fake_dmean=0.2783317565917969\n",
      "第5迭代下第330批次: 判别损失=0.894802451133728，生成损失=2.1747658252716064, real_dmean=0.8006935119628906, fake_dmean=0.4396018087863922\n",
      "第5迭代下第340批次: 判别损失=0.7106011509895325，生成损失=1.9445807933807373, real_dmean=0.7485107183456421, fake_dmean=0.30695247650146484\n",
      "第5迭代下第350批次: 判别损失=0.736865758895874，生成损失=1.7764984369277954, real_dmean=0.6601014137268066, fake_dmean=0.21304821968078613\n",
      "第5迭代下第360批次: 判别损失=0.5630452632904053，生成损失=2.367560386657715, real_dmean=0.766710102558136, fake_dmean=0.22101762890815735\n",
      "第5迭代下第370批次: 判别损失=0.9689627885818481，生成损失=4.111146450042725, real_dmean=0.8991344571113586, fake_dmean=0.5336278080940247\n",
      "第5迭代下第380批次: 判别损失=0.8103613257408142，生成损失=2.2058205604553223, real_dmean=0.7757397890090942, fake_dmean=0.37908899784088135\n",
      "第5迭代下第390批次: 判别损失=0.6495761275291443，生成损失=1.6101378202438354, real_dmean=0.675468921661377, fake_dmean=0.1901002824306488\n",
      "第5迭代下第400批次: 判别损失=1.144221544265747，生成损失=3.289738178253174, real_dmean=0.8532252311706543, fake_dmean=0.5693298578262329\n",
      "第5迭代下第410批次: 判别损失=0.6553988456726074，生成损失=2.2937753200531006, real_dmean=0.7644454836845398, fake_dmean=0.28868210315704346\n",
      "第5迭代下第420批次: 判别损失=0.7241824865341187，生成损失=2.3602898120880127, real_dmean=0.7899606227874756, fake_dmean=0.3443683683872223\n",
      "第5迭代下第430批次: 判别损失=0.9547283053398132，生成损失=2.2327537536621094, real_dmean=0.6818109750747681, fake_dmean=0.37470167875289917\n",
      "第5迭代下第440批次: 判别损失=0.8874405026435852，生成损失=2.7643957138061523, real_dmean=0.8713491559028625, fake_dmean=0.4828726351261139\n",
      "第5迭代下第450批次: 判别损失=0.7800813913345337，生成损失=1.3788772821426392, real_dmean=0.6349424123764038, fake_dmean=0.23326489329338074\n",
      "第5迭代下第460批次: 判别损失=0.8679064512252808，生成损失=1.36360764503479, real_dmean=0.5191992521286011, fake_dmean=0.12568873167037964\n",
      "第5迭代下第470批次: 判别损失=0.683350682258606，生成损失=1.8175538778305054, real_dmean=0.6064229011535645, fake_dmean=0.12882907688617706\n",
      "第5迭代下第480批次: 判别损失=0.6296423673629761，生成损失=1.886770486831665, real_dmean=0.7471560835838318, fake_dmean=0.2579009532928467\n",
      "第5迭代下第490批次: 判别损失=0.9526583552360535，生成损失=2.7128565311431885, real_dmean=0.8502252697944641, fake_dmean=0.5064066648483276\n",
      "第5迭代下第500批次: 判别损失=0.46418994665145874，生成损失=1.9578406810760498, real_dmean=0.8023430705070496, fake_dmean=0.1984563171863556\n",
      "第5迭代下第510批次: 判别损失=0.8622158169746399，生成损失=1.2305982112884521, real_dmean=0.519895613193512, fake_dmean=0.13200794160366058\n",
      "第5迭代下第520批次: 判别损失=0.7703554630279541，生成损失=1.898802399635315, real_dmean=0.6951467990875244, fake_dmean=0.2987760305404663\n",
      "第5迭代下第530批次: 判别损失=0.7075653076171875，生成损失=1.8877878189086914, real_dmean=0.6918900012969971, fake_dmean=0.25086861848831177\n",
      "第5迭代下第540批次: 判别损失=0.6496103405952454，生成损失=1.8501399755477905, real_dmean=0.6850647926330566, fake_dmean=0.1955951750278473\n",
      "第5迭代下第550批次: 判别损失=0.8287947177886963，生成损失=1.384838581085205, real_dmean=0.606983482837677, fake_dmean=0.23614749312400818\n",
      "第5迭代下第560批次: 判别损失=0.8250098824501038，生成损失=1.6064026355743408, real_dmean=0.742196798324585, fake_dmean=0.36932554841041565\n",
      "第5迭代下第570批次: 判别损失=0.682099461555481，生成损失=2.5592527389526367, real_dmean=0.823646605014801, fake_dmean=0.35554856061935425\n",
      "第5迭代下第580批次: 判别损失=0.6876479387283325，生成损失=1.569307565689087, real_dmean=0.6856171488761902, fake_dmean=0.2221803367137909\n",
      "第5迭代下第590批次: 判别损失=0.7697116136550903，生成损失=2.5054588317871094, real_dmean=0.7963992357254028, fake_dmean=0.3810468316078186\n",
      "第5迭代下第600批次: 判别损失=0.7840790748596191，生成损失=1.2087604999542236, real_dmean=0.6084031462669373, fake_dmean=0.20660752058029175\n",
      "第5迭代下第610批次: 判别损失=1.7793562412261963，生成损失=0.8156033158302307, real_dmean=0.24283292889595032, fake_dmean=0.15451771020889282\n",
      "第5迭代下第620批次: 判别损失=0.7062357068061829，生成损失=1.7657347917556763, real_dmean=0.6482006907463074, fake_dmean=0.18772143125534058\n",
      "第5迭代下第630批次: 判别损失=0.6792699098587036，生成损失=1.7613050937652588, real_dmean=0.6451779007911682, fake_dmean=0.16334623098373413\n",
      "第5迭代下第640批次: 判别损失=0.7515815496444702，生成损失=1.6268339157104492, real_dmean=0.6742912530899048, fake_dmean=0.25753167271614075\n",
      "第5迭代下第650批次: 判别损失=0.915054440498352，生成损失=1.2259875535964966, real_dmean=0.5156905055046082, fake_dmean=0.11887045204639435\n",
      "第5迭代下第660批次: 判别损失=0.7744821906089783，生成损失=1.460172176361084, real_dmean=0.5690553188323975, fake_dmean=0.1334531307220459\n",
      "第5迭代下第670批次: 判别损失=0.8502904176712036，生成损失=1.1136082410812378, real_dmean=0.5228885412216187, fake_dmean=0.12976379692554474\n",
      "第5迭代下第680批次: 判别损失=1.0071507692337036，生成损失=3.071932792663574, real_dmean=0.8193531036376953, fake_dmean=0.5014224648475647\n",
      "第5迭代下第690批次: 判别损失=0.7813866138458252，生成损失=2.135871410369873, real_dmean=0.7463891506195068, fake_dmean=0.3403293192386627\n",
      "第5迭代下第700批次: 判别损失=0.7131714820861816，生成损失=1.8682130575180054, real_dmean=0.667374849319458, fake_dmean=0.22228175401687622\n",
      "第5迭代下第710批次: 判别损失=0.9280847907066345，生成损失=1.2914706468582153, real_dmean=0.5734838843345642, fake_dmean=0.2335277497768402\n",
      "第5迭代下第720批次: 判别损失=0.76451575756073，生成损失=2.9406888484954834, real_dmean=0.9288493394851685, fake_dmean=0.46605992317199707\n",
      "第5迭代下第730批次: 判别损失=0.9312886595726013，生成损失=1.446428894996643, real_dmean=0.5347075462341309, fake_dmean=0.1905166506767273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5迭代下第740批次: 判别损失=0.9955960512161255，生成损失=2.6610565185546875, real_dmean=0.8122183084487915, fake_dmean=0.4928717315196991\n",
      "第5迭代下第750批次: 判别损失=0.7245989441871643，生成损失=1.7725002765655518, real_dmean=0.7384385466575623, fake_dmean=0.3000933527946472\n",
      "第5迭代下第760批次: 判别损失=0.9296326637268066，生成损失=1.8041081428527832, real_dmean=0.7109522819519043, fake_dmean=0.4042365849018097\n",
      "第5迭代下第770批次: 判别损失=0.6887548565864563，生成损失=1.6662681102752686, real_dmean=0.6960586309432983, fake_dmean=0.24181602895259857\n",
      "第5迭代下第780批次: 判别损失=0.7468101978302002，生成损失=1.8018503189086914, real_dmean=0.7360919117927551, fake_dmean=0.3131471872329712\n",
      "第6迭代下第0批次: 判别损失=0.8481423854827881，生成损失=1.3526113033294678, real_dmean=0.608686625957489, fake_dmean=0.24914707243442535\n",
      "第6迭代下第10批次: 判别损失=0.6999359726905823，生成损失=2.5864973068237305, real_dmean=0.830008327960968, fake_dmean=0.3724403977394104\n",
      "第6迭代下第20批次: 判别损失=0.7390673756599426，生成损失=2.0376269817352295, real_dmean=0.7663382291793823, fake_dmean=0.32783281803131104\n",
      "第6迭代下第30批次: 判别损失=0.7587523460388184，生成损失=1.8520516157150269, real_dmean=0.7717175483703613, fake_dmean=0.3429502844810486\n",
      "第6迭代下第40批次: 判别损失=0.497161865234375，生成损失=2.0137104988098145, real_dmean=0.7581399083137512, fake_dmean=0.16996490955352783\n",
      "第6迭代下第50批次: 判别损失=0.6396280527114868，生成损失=1.6310374736785889, real_dmean=0.6595606207847595, fake_dmean=0.16106952726840973\n",
      "第6迭代下第60批次: 判别损失=1.1090856790542603，生成损失=0.6512385606765747, real_dmean=0.4299740493297577, fake_dmean=0.12995433807373047\n",
      "第6迭代下第70批次: 判别损失=0.752823531627655，生成损失=2.0570456981658936, real_dmean=0.8164105415344238, fake_dmean=0.3828118145465851\n",
      "第6迭代下第80批次: 判别损失=0.578317403793335，生成损失=2.5758774280548096, real_dmean=0.737371027469635, fake_dmean=0.2102065235376358\n",
      "第6迭代下第90批次: 判别损失=0.6760942935943604，生成损失=1.7764086723327637, real_dmean=0.7027618885040283, fake_dmean=0.2320164144039154\n",
      "第6迭代下第100批次: 判别损失=1.0280641317367554，生成损失=3.2383999824523926, real_dmean=0.8839557766914368, fake_dmean=0.5471967458724976\n",
      "第6迭代下第110批次: 判别损失=0.6483153104782104，生成损失=1.8514736890792847, real_dmean=0.7082710266113281, fake_dmean=0.2195657342672348\n",
      "第6迭代下第120批次: 判别损失=1.1798292398452759，生成损失=0.6964156031608582, real_dmean=0.41163989901542664, fake_dmean=0.13458286225795746\n",
      "第6迭代下第130批次: 判别损失=0.7108603715896606，生成损失=1.9223779439926147, real_dmean=0.7411185503005981, fake_dmean=0.29943031072616577\n",
      "第6迭代下第140批次: 判别损失=0.5841172337532043，生成损失=1.267918586730957, real_dmean=0.7572252750396729, fake_dmean=0.23989693820476532\n",
      "第6迭代下第150批次: 判别损失=0.6527413725852966，生成损失=1.5635048151016235, real_dmean=0.663750946521759, fake_dmean=0.17255322635173798\n",
      "第6迭代下第160批次: 判别损失=0.7297390699386597，生成损失=1.962742805480957, real_dmean=0.5892729759216309, fake_dmean=0.11712799966335297\n",
      "第6迭代下第170批次: 判别损失=0.7403536438941956，生成损失=1.956014633178711, real_dmean=0.687667191028595, fake_dmean=0.25991135835647583\n",
      "第6迭代下第180批次: 判别损失=1.1682535409927368，生成损失=0.719684362411499, real_dmean=0.37699633836746216, fake_dmean=0.0916963741183281\n",
      "第6迭代下第190批次: 判别损失=0.6497372388839722，生成损失=1.8079535961151123, real_dmean=0.7330209612846375, fake_dmean=0.2528323531150818\n",
      "第6迭代下第200批次: 判别损失=0.6306350231170654，生成损失=1.4937033653259277, real_dmean=0.6695640683174133, fake_dmean=0.17004510760307312\n",
      "第6迭代下第210批次: 判别损失=0.723738431930542，生成损失=1.9408799409866333, real_dmean=0.722334086894989, fake_dmean=0.2947787046432495\n",
      "第6迭代下第220批次: 判别损失=0.7488288283348083，生成损失=1.177473545074463, real_dmean=0.6188817620277405, fake_dmean=0.19141888618469238\n",
      "第6迭代下第230批次: 判别损失=0.7697648406028748，生成损失=1.4372504949569702, real_dmean=0.5949311256408691, fake_dmean=0.1698623150587082\n",
      "第6迭代下第240批次: 判别损失=0.6724700927734375，生成损失=1.7520617246627808, real_dmean=0.7267793416976929, fake_dmean=0.2514022886753082\n",
      "第6迭代下第250批次: 判别损失=0.6593871116638184，生成损失=2.8181605339050293, real_dmean=0.9022889137268066, fake_dmean=0.39663878083229065\n",
      "第6迭代下第260批次: 判别损失=0.68201744556427，生成损失=1.8842912912368774, real_dmean=0.735895037651062, fake_dmean=0.2863733172416687\n",
      "第6迭代下第270批次: 判别损失=0.8714806437492371，生成损失=2.4684884548187256, real_dmean=0.7446795105934143, fake_dmean=0.3814225494861603\n",
      "第6迭代下第280批次: 判别损失=0.9234986901283264，生成损失=1.859228491783142, real_dmean=0.4674939811229706, fake_dmean=0.05276728421449661\n",
      "第6迭代下第290批次: 判别损失=0.8838508725166321，生成损失=1.4154860973358154, real_dmean=0.5172455906867981, fake_dmean=0.12245900183916092\n",
      "第6迭代下第300批次: 判别损失=1.19251549243927，生成损失=3.5430147647857666, real_dmean=0.9068116545677185, fake_dmean=0.6015003323554993\n",
      "第6迭代下第310批次: 判别损失=0.9675576090812683，生成损失=1.9876796007156372, real_dmean=0.7032978534698486, fake_dmean=0.4178534746170044\n",
      "第6迭代下第320批次: 判别损失=0.9064329266548157，生成损失=1.3863028287887573, real_dmean=0.5122746229171753, fake_dmean=0.11394968628883362\n",
      "第6迭代下第330批次: 判别损失=0.9496863484382629，生成损失=2.2553341388702393, real_dmean=0.7825449109077454, fake_dmean=0.45019298791885376\n",
      "第6迭代下第340批次: 判别损失=0.7054879665374756，生成损失=2.21799635887146, real_dmean=0.7948081493377686, fake_dmean=0.3398805558681488\n",
      "第6迭代下第350批次: 判别损失=0.766907811164856，生成损失=1.444400429725647, real_dmean=0.6205599308013916, fake_dmean=0.19122569262981415\n",
      "第6迭代下第360批次: 判别损失=0.73769211769104，生成损失=1.066612720489502, real_dmean=0.6145268678665161, fake_dmean=0.1576530933380127\n",
      "第6迭代下第370批次: 判别损失=0.8433826565742493，生成损失=1.072835922241211, real_dmean=0.6047280430793762, fake_dmean=0.2317558228969574\n",
      "第6迭代下第380批次: 判别损失=0.6679117679595947，生成损失=1.678817868232727, real_dmean=0.7002772092819214, fake_dmean=0.23252509534358978\n",
      "第6迭代下第390批次: 判别损失=0.9344526529312134，生成损失=2.5545947551727295, real_dmean=0.8399369120597839, fake_dmean=0.49190637469291687\n",
      "第6迭代下第400批次: 判别损失=0.9305241107940674，生成损失=2.6881346702575684, real_dmean=0.8146435022354126, fake_dmean=0.4805681109428406\n",
      "第6迭代下第410批次: 判别损失=0.8651731014251709，生成损失=1.590463638305664, real_dmean=0.6317089200019836, fake_dmean=0.28154775500297546\n",
      "第6迭代下第420批次: 判别损失=0.9233385324478149，生成损失=1.207557201385498, real_dmean=0.5577107071876526, fake_dmean=0.21500907838344574\n",
      "第6迭代下第430批次: 判别损失=0.8812841773033142，生成损失=1.0242919921875, real_dmean=0.5437083840370178, fake_dmean=0.1727122664451599\n",
      "第6迭代下第440批次: 判别损失=0.7505111694335938，生成损失=1.6988681554794312, real_dmean=0.6556118726730347, fake_dmean=0.23417800664901733\n",
      "第6迭代下第450批次: 判别损失=0.7088972926139832，生成损失=2.0916008949279785, real_dmean=0.8033416867256165, fake_dmean=0.35536903142929077\n",
      "第6迭代下第460批次: 判别损失=0.6607189178466797，生成损失=2.4601755142211914, real_dmean=0.7967442870140076, fake_dmean=0.3198712468147278\n",
      "第6迭代下第470批次: 判别损失=0.7551690340042114，生成损失=1.953884482383728, real_dmean=0.7900395393371582, fake_dmean=0.375803142786026\n",
      "第6迭代下第480批次: 判别损失=1.0076335668563843，生成损失=2.2481229305267334, real_dmean=0.7769330143928528, fake_dmean=0.47543951869010925\n",
      "第6迭代下第490批次: 判别损失=0.7978674173355103，生成损失=1.382086992263794, real_dmean=0.6305516958236694, fake_dmean=0.21519343554973602\n",
      "第6迭代下第500批次: 判别损失=0.6931401491165161，生成损失=1.7477120161056519, real_dmean=0.6370888948440552, fake_dmean=0.15291710197925568\n",
      "第6迭代下第510批次: 判别损失=0.7676537036895752，生成损失=1.6705691814422607, real_dmean=0.6359745264053345, fake_dmean=0.21364881098270416\n",
      "第6迭代下第520批次: 判别损失=0.7591072916984558，生成损失=1.3940191268920898, real_dmean=0.5840562582015991, fake_dmean=0.14632585644721985\n",
      "第6迭代下第530批次: 判别损失=0.721736490726471，生成损失=2.4953927993774414, real_dmean=0.7937307357788086, fake_dmean=0.33447185158729553\n",
      "第6迭代下第540批次: 判别损失=0.6727176904678345，生成损失=2.087982416152954, real_dmean=0.749424934387207, fake_dmean=0.27520570158958435\n",
      "第6迭代下第550批次: 判别损失=0.743807315826416，生成损失=2.163079261779785, real_dmean=0.7726161479949951, fake_dmean=0.34584271907806396\n",
      "第6迭代下第560批次: 判别损失=0.8707363605499268，生成损失=1.1612334251403809, real_dmean=0.6333277821540833, fake_dmean=0.2836468517780304\n",
      "第6迭代下第570批次: 判别损失=0.7486048340797424，生成损失=1.9033852815628052, real_dmean=0.6877123117446899, fake_dmean=0.26373931765556335\n",
      "第6迭代下第580批次: 判别损失=0.6882890462875366，生成损失=2.0299875736236572, real_dmean=0.7971571087837219, fake_dmean=0.3262506127357483\n",
      "第6迭代下第590批次: 判别损失=1.1395390033721924，生成损失=3.3328113555908203, real_dmean=0.8150992393493652, fake_dmean=0.5417331457138062\n",
      "第6迭代下第600批次: 判别损失=0.73485267162323，生成损失=2.660362720489502, real_dmean=0.8275977373123169, fake_dmean=0.37449726462364197\n",
      "第6迭代下第610批次: 判别损失=0.819263219833374，生成损失=1.3368033170700073, real_dmean=0.6329730153083801, fake_dmean=0.23234744369983673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第6迭代下第620批次: 判别损失=1.4768041372299194，生成损失=3.2617077827453613, real_dmean=0.8743359446525574, fake_dmean=0.6763903498649597\n",
      "第6迭代下第630批次: 判别损失=0.9987660646438599，生成损失=2.3940279483795166, real_dmean=0.7356470227241516, fake_dmean=0.4378250241279602\n",
      "第6迭代下第640批次: 判别损失=0.71767258644104，生成损失=1.6390541791915894, real_dmean=0.6536399722099304, fake_dmean=0.19398638606071472\n",
      "第6迭代下第650批次: 判别损失=0.8647552728652954，生成损失=2.0424728393554688, real_dmean=0.6800578236579895, fake_dmean=0.33025333285331726\n",
      "第6迭代下第660批次: 判别损失=1.0030118227005005，生成损失=2.958522319793701, real_dmean=0.8556140661239624, fake_dmean=0.5190215110778809\n",
      "第6迭代下第670批次: 判别损失=0.6475604772567749，生成损失=1.9910986423492432, real_dmean=0.7440415024757385, fake_dmean=0.260722279548645\n",
      "第6迭代下第680批次: 判别损失=1.0505645275115967，生成损失=0.9159897565841675, real_dmean=0.4614335894584656, fake_dmean=0.16588355600833893\n",
      "第6迭代下第690批次: 判别损失=0.7386100888252258，生成损失=1.7084934711456299, real_dmean=0.6332888603210449, fake_dmean=0.18348267674446106\n",
      "第6迭代下第700批次: 判别损失=0.6402077078819275，生成损失=2.1337640285491943, real_dmean=0.7344843149185181, fake_dmean=0.24344585835933685\n",
      "第6迭代下第710批次: 判别损失=0.8840251564979553，生成损失=2.1419308185577393, real_dmean=0.7632651329040527, fake_dmean=0.40584707260131836\n",
      "第6迭代下第720批次: 判别损失=0.9093090891838074，生成损失=1.1905862092971802, real_dmean=0.5346457958221436, fake_dmean=0.1645580381155014\n",
      "第6迭代下第730批次: 判别损失=0.5976705551147461，生成损失=2.679666757583618, real_dmean=0.7936320304870605, fake_dmean=0.26731154322624207\n",
      "第6迭代下第740批次: 判别损失=0.8676312565803528，生成损失=1.8050181865692139, real_dmean=0.5886942148208618, fake_dmean=0.2239566147327423\n",
      "第6迭代下第750批次: 判别损失=1.0262235403060913，生成损失=1.3458712100982666, real_dmean=0.4411010444164276, fake_dmean=0.07102704048156738\n",
      "第6迭代下第760批次: 判别损失=0.773681640625，生成损失=1.1844743490219116, real_dmean=0.6330580711364746, fake_dmean=0.21274830400943756\n",
      "第6迭代下第770批次: 判别损失=0.6065664887428284，生成损失=1.6353883743286133, real_dmean=0.6748188138008118, fake_dmean=0.15006941556930542\n",
      "第6迭代下第780批次: 判别损失=1.0820924043655396，生成损失=0.9066627025604248, real_dmean=0.4355548918247223, fake_dmean=0.1161322370171547\n",
      "第7迭代下第0批次: 判别损失=0.7518149614334106，生成损失=1.4457521438598633, real_dmean=0.5808848142623901, fake_dmean=0.1361086219549179\n",
      "第7迭代下第10批次: 判别损失=0.6555023193359375，生成损失=2.164349317550659, real_dmean=0.7641397714614868, fake_dmean=0.27970364689826965\n",
      "第7迭代下第20批次: 判别损失=0.9871707558631897，生成损失=1.9539519548416138, real_dmean=0.6884331107139587, fake_dmean=0.39068126678466797\n",
      "第7迭代下第30批次: 判别损失=0.6143471598625183，生成损失=2.8197920322418213, real_dmean=0.8046111464500427, fake_dmean=0.2971192002296448\n",
      "第7迭代下第40批次: 判别损失=0.9106950759887695，生成损失=0.9868775606155396, real_dmean=0.4977067708969116, fake_dmean=0.11758768558502197\n",
      "第7迭代下第50批次: 判别损失=0.7535401582717896，生成损失=1.8877700567245483, real_dmean=0.58915776014328, fake_dmean=0.13638891279697418\n",
      "第7迭代下第60批次: 判别损失=0.4962093234062195，生成损失=2.4762885570526123, real_dmean=0.7755271196365356, fake_dmean=0.19223639369010925\n",
      "第7迭代下第70批次: 判别损失=1.3637789487838745，生成损失=0.9511575102806091, real_dmean=0.32465648651123047, fake_dmean=0.042622022330760956\n",
      "第7迭代下第80批次: 判别损失=0.8312612771987915，生成损失=1.321537971496582, real_dmean=0.600616455078125, fake_dmean=0.20995669066905975\n",
      "第7迭代下第90批次: 判别损失=0.9552783966064453，生成损失=1.3257373571395874, real_dmean=0.5507548451423645, fake_dmean=0.21438176929950714\n",
      "第7迭代下第100批次: 判别损失=0.8049646019935608，生成损失=1.4225194454193115, real_dmean=0.6637909412384033, fake_dmean=0.2849824130535126\n",
      "第7迭代下第110批次: 判别损失=0.7847194671630859，生成损失=1.7827212810516357, real_dmean=0.669692873954773, fake_dmean=0.2717097997665405\n",
      "第7迭代下第120批次: 判别损失=1.135799765586853，生成损失=2.6422300338745117, real_dmean=0.8411417603492737, fake_dmean=0.5547909140586853\n",
      "第7迭代下第130批次: 判别损失=0.8287177085876465，生成损失=1.110553503036499, real_dmean=0.6337761878967285, fake_dmean=0.2617913484573364\n",
      "第7迭代下第140批次: 判别损失=0.8971701860427856，生成损失=2.6532609462738037, real_dmean=0.8449251651763916, fake_dmean=0.44761067628860474\n",
      "第7迭代下第150批次: 判别损失=0.9800673723220825，生成损失=1.3956449031829834, real_dmean=0.4926377832889557, fake_dmean=0.14366799592971802\n",
      "第7迭代下第160批次: 判别损失=1.254974126815796，生成损失=0.9219092130661011, real_dmean=0.40223491191864014, fake_dmean=0.1903030127286911\n",
      "第7迭代下第170批次: 判别损失=0.8362318277359009，生成损失=1.7751981019973755, real_dmean=0.5989812612533569, fake_dmean=0.19656391441822052\n",
      "第7迭代下第180批次: 判别损失=0.7519007325172424，生成损失=1.9232019186019897, real_dmean=0.7407501339912415, fake_dmean=0.3237789571285248\n",
      "第7迭代下第190批次: 判别损失=0.7887530326843262，生成损失=1.3244843482971191, real_dmean=0.7375171780586243, fake_dmean=0.3488706350326538\n",
      "第7迭代下第200批次: 判别损失=0.8285139799118042，生成损失=1.7866722345352173, real_dmean=0.5451417565345764, fake_dmean=0.14117886126041412\n",
      "第7迭代下第210批次: 判别损失=0.708338737487793，生成损失=2.4319028854370117, real_dmean=0.8036738634109497, fake_dmean=0.34964287281036377\n",
      "第7迭代下第220批次: 判别损失=0.9614624977111816，生成损失=1.1257857084274292, real_dmean=0.4915409982204437, fake_dmean=0.13929304480552673\n",
      "第7迭代下第230批次: 判别损失=0.839506208896637，生成损失=1.7236623764038086, real_dmean=0.637382984161377, fake_dmean=0.26954495906829834\n",
      "第7迭代下第240批次: 判别损失=0.873982310295105，生成损失=2.7232556343078613, real_dmean=0.8159206509590149, fake_dmean=0.44520360231399536\n",
      "第7迭代下第250批次: 判别损失=0.7618639469146729，生成损失=1.7682995796203613, real_dmean=0.6264967918395996, fake_dmean=0.19625088572502136\n",
      "第7迭代下第260批次: 判别损失=0.7004258632659912，生成损失=2.097949981689453, real_dmean=0.7015053033828735, fake_dmean=0.2538348138332367\n",
      "第7迭代下第270批次: 判别损失=0.8518259525299072，生成损失=1.4901059865951538, real_dmean=0.5895587205886841, fake_dmean=0.2034025639295578\n",
      "第7迭代下第280批次: 判别损失=1.06156325340271，生成损失=1.3158023357391357, real_dmean=0.42002642154693604, fake_dmean=0.08611102402210236\n",
      "第7迭代下第290批次: 判别损失=0.6865204572677612，生成损失=2.48852801322937, real_dmean=0.7970356941223145, fake_dmean=0.3342694640159607\n",
      "第7迭代下第300批次: 判别损失=0.8230650424957275，生成损失=2.1363048553466797, real_dmean=0.6615772247314453, fake_dmean=0.2969793975353241\n",
      "第7迭代下第310批次: 判别损失=0.8468340635299683，生成损失=2.6958682537078857, real_dmean=0.8833304643630981, fake_dmean=0.46972543001174927\n",
      "第7迭代下第320批次: 判别损失=0.6772459149360657，生成损失=2.414205551147461, real_dmean=0.8217297792434692, fake_dmean=0.3542144298553467\n",
      "第7迭代下第330批次: 判别损失=0.9081873297691345，生成损失=2.400681495666504, real_dmean=0.8246777057647705, fake_dmean=0.4696064591407776\n",
      "第7迭代下第340批次: 判别损失=1.0023843050003052，生成损失=2.538769483566284, real_dmean=0.742601752281189, fake_dmean=0.45071446895599365\n",
      "第7迭代下第350批次: 判别损失=0.6770553588867188，生成损失=2.166727066040039, real_dmean=0.7590051889419556, fake_dmean=0.29993101954460144\n",
      "第7迭代下第360批次: 判别损失=0.7448902130126953，生成损失=2.4905831813812256, real_dmean=0.8137313723564148, fake_dmean=0.368989497423172\n",
      "第7迭代下第370批次: 判别损失=0.9246050119400024，生成损失=1.2227953672409058, real_dmean=0.5924522876739502, fake_dmean=0.2667873203754425\n",
      "第7迭代下第380批次: 判别损失=0.9960106015205383，生成损失=1.6563069820404053, real_dmean=0.6389074325561523, fake_dmean=0.3632262349128723\n",
      "第7迭代下第390批次: 判别损失=0.9509057402610779，生成损失=2.6075220108032227, real_dmean=0.8338133096694946, fake_dmean=0.4915180206298828\n",
      "第7迭代下第400批次: 判别损失=0.7548918128013611，生成损失=1.7595274448394775, real_dmean=0.7328587770462036, fake_dmean=0.32351383566856384\n",
      "第7迭代下第410批次: 判别损失=0.7814956903457642，生成损失=3.016401529312134, real_dmean=0.8943980932235718, fake_dmean=0.4557316303253174\n",
      "第7迭代下第420批次: 判别损失=0.7194191217422485，生成损失=1.441062092781067, real_dmean=0.6280007362365723, fake_dmean=0.17282210290431976\n",
      "第7迭代下第430批次: 判别损失=0.6880542635917664，生成损失=2.144166946411133, real_dmean=0.7471015453338623, fake_dmean=0.27504613995552063\n",
      "第7迭代下第440批次: 判别损失=0.6954597234725952，生成损失=1.9886314868927002, real_dmean=0.6614452004432678, fake_dmean=0.19364187121391296\n",
      "第7迭代下第450批次: 判别损失=0.4327183663845062，生成损失=2.1716346740722656, real_dmean=0.8151196241378784, fake_dmean=0.184625506401062\n",
      "第7迭代下第460批次: 判别损失=0.9493045806884766，生成损失=2.864719867706299, real_dmean=0.8495755195617676, fake_dmean=0.5088049173355103\n",
      "第7迭代下第470批次: 判别损失=0.6357088088989258，生成损失=2.1747334003448486, real_dmean=0.8049744367599487, fake_dmean=0.31057798862457275\n",
      "第7迭代下第480批次: 判别损失=0.9254763722419739，生成损失=1.7877368927001953, real_dmean=0.6483317613601685, fake_dmean=0.32122892141342163\n",
      "第7迭代下第490批次: 判别损失=0.8211629986763，生成损失=2.419311761856079, real_dmean=0.7437515258789062, fake_dmean=0.363869309425354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第7迭代下第500批次: 判别损失=0.7817825078964233，生成损失=2.8433761596679688, real_dmean=0.8380255103111267, fake_dmean=0.41652852296829224\n",
      "第7迭代下第510批次: 判别损失=0.9722101092338562，生成损失=1.0388075113296509, real_dmean=0.47801464796066284, fake_dmean=0.10886398702859879\n",
      "第7迭代下第520批次: 判别损失=0.7662486433982849，生成损失=1.6652510166168213, real_dmean=0.762107253074646, fake_dmean=0.3544312119483948\n",
      "第7迭代下第530批次: 判别损失=1.0571739673614502，生成损失=1.440993070602417, real_dmean=0.5721375942230225, fake_dmean=0.32436734437942505\n",
      "第7迭代下第540批次: 判别损失=0.6562495827674866，生成损失=2.3398561477661133, real_dmean=0.8207430839538574, fake_dmean=0.32841747999191284\n",
      "第7迭代下第550批次: 判别损失=0.6464498043060303，生成损失=2.286519765853882, real_dmean=0.6749511957168579, fake_dmean=0.17576389014720917\n",
      "第7迭代下第560批次: 判别损失=1.107511043548584，生成损失=0.8494018316268921, real_dmean=0.45080992579460144, fake_dmean=0.18012800812721252\n",
      "第7迭代下第570批次: 判别损失=0.621394157409668，生成损失=2.0253419876098633, real_dmean=0.6930158138275146, fake_dmean=0.17843103408813477\n",
      "第7迭代下第580批次: 判别损失=1.0142039060592651，生成损失=3.4013354778289795, real_dmean=0.8275147676467896, fake_dmean=0.4805282652378082\n",
      "第7迭代下第590批次: 判别损失=0.8117083311080933，生成损失=2.1253859996795654, real_dmean=0.6719563007354736, fake_dmean=0.28614407777786255\n",
      "第7迭代下第600批次: 判别损失=0.778035044670105，生成损失=1.862734317779541, real_dmean=0.8013196587562561, fake_dmean=0.3971908390522003\n",
      "第7迭代下第610批次: 判别损失=0.6455472707748413，生成损失=1.970474123954773, real_dmean=0.8133912086486816, fake_dmean=0.3244856894016266\n",
      "第7迭代下第620批次: 判别损失=0.8499829173088074，生成损失=2.3087785243988037, real_dmean=0.7210674285888672, fake_dmean=0.3614215552806854\n",
      "第7迭代下第630批次: 判别损失=1.0190849304199219，生成损失=1.6556193828582764, real_dmean=0.47117379307746887, fake_dmean=0.12818311154842377\n",
      "第7迭代下第640批次: 判别损失=0.7116674184799194，生成损失=1.3431692123413086, real_dmean=0.7083155512809753, fake_dmean=0.2649867534637451\n",
      "第7迭代下第650批次: 判别损失=0.7356970906257629，生成损失=2.1885502338409424, real_dmean=0.727626621723175, fake_dmean=0.28861719369888306\n",
      "第7迭代下第660批次: 判别损失=0.9178677201271057，生成损失=1.7650563716888428, real_dmean=0.7212822437286377, fake_dmean=0.39767685532569885\n",
      "第7迭代下第670批次: 判别损失=0.5643778443336487，生成损失=2.6031455993652344, real_dmean=0.8002511858940125, fake_dmean=0.2606079578399658\n",
      "第7迭代下第680批次: 判别损失=0.7109693288803101，生成损失=2.3501007556915283, real_dmean=0.8080065250396729, fake_dmean=0.34907716512680054\n",
      "第7迭代下第690批次: 判别损失=0.7824753522872925，生成损失=2.5742740631103516, real_dmean=0.7272937297821045, fake_dmean=0.30446797609329224\n",
      "第7迭代下第700批次: 判别损失=0.7958776354789734，生成损失=2.3579020500183105, real_dmean=0.7583401799201965, fake_dmean=0.3528706431388855\n",
      "第7迭代下第710批次: 判别损失=0.931013286113739，生成损失=1.5493985414505005, real_dmean=0.5016412138938904, fake_dmean=0.11886131018400192\n",
      "第7迭代下第720批次: 判别损失=0.6887505650520325，生成损失=1.5714417695999146, real_dmean=0.622191309928894, fake_dmean=0.14330419898033142\n",
      "第7迭代下第730批次: 判别损失=0.6530930995941162，生成损失=2.13948392868042, real_dmean=0.6973943114280701, fake_dmean=0.20523402094841003\n",
      "第7迭代下第740批次: 判别损失=0.7220560908317566，生成损失=1.5005772113800049, real_dmean=0.5898652076721191, fake_dmean=0.11648674309253693\n",
      "第7迭代下第750批次: 判别损失=0.834708571434021，生成损失=2.568971872329712, real_dmean=0.8331003189086914, fake_dmean=0.4268771708011627\n",
      "第7迭代下第760批次: 判别损失=0.7274565100669861，生成损失=1.5776185989379883, real_dmean=0.7014410495758057, fake_dmean=0.2641332149505615\n",
      "第7迭代下第770批次: 判别损失=0.7644741535186768，生成损失=1.9324181079864502, real_dmean=0.8177156448364258, fake_dmean=0.39055943489074707\n",
      "第7迭代下第780批次: 判别损失=0.8037518262863159，生成损失=1.6867709159851074, real_dmean=0.5994338989257812, fake_dmean=0.18051749467849731\n",
      "第8迭代下第0批次: 判别损失=0.9074729681015015，生成损失=2.765535831451416, real_dmean=0.8455958366394043, fake_dmean=0.48498642444610596\n",
      "第8迭代下第10批次: 判别损失=0.9075024724006653，生成损失=1.60739004611969, real_dmean=0.5159091353416443, fake_dmean=0.12469368427991867\n",
      "第8迭代下第20批次: 判别损失=0.7106703519821167，生成损失=2.430652618408203, real_dmean=0.7836266756057739, fake_dmean=0.3365511894226074\n",
      "第8迭代下第30批次: 判别损失=0.7304857969284058，生成损失=1.9507068395614624, real_dmean=0.8154699206352234, fake_dmean=0.374586820602417\n",
      "第8迭代下第40批次: 判别损失=0.730330228805542，生成损失=2.4256465435028076, real_dmean=0.8358963131904602, fake_dmean=0.38330143690109253\n",
      "第8迭代下第50批次: 判别损失=0.888470470905304，生成损失=1.1995370388031006, real_dmean=0.5034595131874084, fake_dmean=0.11681094020605087\n",
      "第8迭代下第60批次: 判别损失=0.9236016869544983，生成损失=1.2328218221664429, real_dmean=0.5764962434768677, fake_dmean=0.24642595648765564\n",
      "第8迭代下第70批次: 判别损失=1.0392533540725708，生成损失=1.144866943359375, real_dmean=0.4334649443626404, fake_dmean=0.06542150676250458\n",
      "第8迭代下第80批次: 判别损失=0.7145708203315735，生成损失=2.6806116104125977, real_dmean=0.8579444885253906, fake_dmean=0.3925153911113739\n",
      "第8迭代下第90批次: 判别损失=1.1847668886184692，生成损失=0.8257995843887329, real_dmean=0.38389700651168823, fake_dmean=0.10992256551980972\n",
      "第8迭代下第100批次: 判别损失=0.7698478698730469，生成损失=1.9386038780212402, real_dmean=0.7458589673042297, fake_dmean=0.34174221754074097\n",
      "第8迭代下第110批次: 判别损失=0.7027051448822021，生成损失=2.4700775146484375, real_dmean=0.8393886089324951, fake_dmean=0.37612688541412354\n",
      "第8迭代下第120批次: 判别损失=0.5306050777435303，生成损失=2.206019639968872, real_dmean=0.8273149728775024, fake_dmean=0.2610607445240021\n",
      "第8迭代下第130批次: 判别损失=0.749729573726654，生成损失=1.5618176460266113, real_dmean=0.6244511604309082, fake_dmean=0.19541020691394806\n",
      "第8迭代下第140批次: 判别损失=0.7715373635292053，生成损失=1.7662488222122192, real_dmean=0.6936168670654297, fake_dmean=0.29200059175491333\n",
      "第8迭代下第150批次: 判别损失=0.9818576574325562，生成损失=0.8187990784645081, real_dmean=0.5638680458068848, fake_dmean=0.26451918482780457\n",
      "第8迭代下第160批次: 判别损失=0.9630013704299927，生成损失=1.9204635620117188, real_dmean=0.6261292099952698, fake_dmean=0.3190869092941284\n",
      "第8迭代下第170批次: 判别损失=0.9245218634605408，生成损失=2.6009609699249268, real_dmean=0.7808871269226074, fake_dmean=0.42467761039733887\n",
      "第8迭代下第180批次: 判别损失=0.6551614999771118，生成损失=2.740405797958374, real_dmean=0.8150917291641235, fake_dmean=0.3298422694206238\n",
      "第8迭代下第190批次: 判别损失=0.7100939750671387，生成损失=1.667179822921753, real_dmean=0.774369478225708, fake_dmean=0.3348580300807953\n",
      "第8迭代下第200批次: 判别损失=0.8760319948196411，生成损失=2.4969067573547363, real_dmean=0.8708482980728149, fake_dmean=0.48739928007125854\n",
      "第8迭代下第210批次: 判别损失=0.8562597632408142，生成损失=1.2380638122558594, real_dmean=0.5858838558197021, fake_dmean=0.22395797073841095\n",
      "第8迭代下第220批次: 判别损失=0.7830560803413391，生成损失=1.9926567077636719, real_dmean=0.8284285664558411, fake_dmean=0.3983517587184906\n",
      "第8迭代下第230批次: 判别损失=0.7254769802093506，生成损失=1.6516607999801636, real_dmean=0.6818771958351135, fake_dmean=0.26054590940475464\n",
      "第8迭代下第240批次: 判别损失=0.9589832425117493，生成损失=1.0281729698181152, real_dmean=0.5171010494232178, fake_dmean=0.20412617921829224\n",
      "第8迭代下第250批次: 判别损失=0.7491951584815979，生成损失=1.4030951261520386, real_dmean=0.7005497217178345, fake_dmean=0.2816790044307709\n",
      "第8迭代下第260批次: 判别损失=1.091976523399353，生成损失=2.8498852252960205, real_dmean=0.7431448698043823, fake_dmean=0.48803985118865967\n",
      "第8迭代下第270批次: 判别损失=0.8551731109619141，生成损失=1.2398854494094849, real_dmean=0.6164126992225647, fake_dmean=0.23317575454711914\n",
      "第8迭代下第280批次: 判别损失=0.6112836599349976，生成损失=2.3110435009002686, real_dmean=0.7842724323272705, fake_dmean=0.2770406901836395\n",
      "第8迭代下第290批次: 判别损失=0.8524108529090881，生成损失=2.404106616973877, real_dmean=0.7815428376197815, fake_dmean=0.40918150544166565\n",
      "第8迭代下第300批次: 判别损失=0.8813327550888062，生成损失=1.2394074201583862, real_dmean=0.5994762182235718, fake_dmean=0.2453887015581131\n",
      "第8迭代下第310批次: 判别损失=0.7985795140266418，生成损失=1.7567652463912964, real_dmean=0.7073808908462524, fake_dmean=0.32827022671699524\n",
      "第8迭代下第320批次: 判别损失=0.9693125486373901，生成损失=1.370337963104248, real_dmean=0.5166674256324768, fake_dmean=0.1690220832824707\n",
      "第8迭代下第330批次: 判别损失=0.9052160978317261，生成损失=2.415344715118408, real_dmean=0.7731468677520752, fake_dmean=0.4204021990299225\n",
      "第8迭代下第340批次: 判别损失=0.9562212228775024，生成损失=1.8440263271331787, real_dmean=0.4538861811161041, fake_dmean=0.0717897042632103\n",
      "第8迭代下第350批次: 判别损失=1.0705411434173584，生成损失=1.9236953258514404, real_dmean=0.7299940586090088, fake_dmean=0.4697487950325012\n",
      "第8迭代下第360批次: 判别损失=0.8481228351593018，生成损失=2.038067579269409, real_dmean=0.7133331894874573, fake_dmean=0.3589044213294983\n",
      "第8迭代下第370批次: 判别损失=0.7484402656555176，生成损失=1.6295273303985596, real_dmean=0.6653309464454651, fake_dmean=0.2360425889492035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第8迭代下第380批次: 判别损失=0.8518284559249878，生成损失=2.1590003967285156, real_dmean=0.8497174978256226, fake_dmean=0.44357213377952576\n",
      "第8迭代下第390批次: 判别损失=0.8110255002975464，生成损失=1.422577977180481, real_dmean=0.571183443069458, fake_dmean=0.14598867297172546\n",
      "第8迭代下第400批次: 判别损失=1.3782764673233032，生成损失=1.1884292364120483, real_dmean=0.3302604556083679, fake_dmean=0.09796693176031113\n",
      "第8迭代下第410批次: 判别损失=0.8884243369102478，生成损失=1.0407238006591797, real_dmean=0.5958401560783386, fake_dmean=0.23801198601722717\n",
      "第8迭代下第420批次: 判别损失=1.0260205268859863，生成损失=2.5945188999176025, real_dmean=0.7106691598892212, fake_dmean=0.42864322662353516\n",
      "第8迭代下第430批次: 判别损失=0.624243974685669，生成损失=1.5938911437988281, real_dmean=0.7080392241477966, fake_dmean=0.20443816483020782\n",
      "第8迭代下第440批次: 判别损失=0.7538996338844299，生成损失=1.6433192491531372, real_dmean=0.6869240999221802, fake_dmean=0.2510300874710083\n",
      "第8迭代下第450批次: 判别损失=0.773456871509552，生成损失=1.9498331546783447, real_dmean=0.7210897207260132, fake_dmean=0.31284499168395996\n",
      "第8迭代下第460批次: 判别损失=0.8104184865951538，生成损失=2.2376410961151123, real_dmean=0.7182560563087463, fake_dmean=0.3421616852283478\n",
      "第8迭代下第470批次: 判别损失=0.5671097040176392，生成损失=1.8826602697372437, real_dmean=0.8107598423957825, fake_dmean=0.27557677030563354\n",
      "第8迭代下第480批次: 判别损失=0.9229207038879395，生成损失=1.981630563735962, real_dmean=0.6910541653633118, fake_dmean=0.38815438747406006\n",
      "第8迭代下第490批次: 判别损失=0.8491654992103577，生成损失=1.5724555253982544, real_dmean=0.5134507417678833, fake_dmean=0.10463545471429825\n",
      "第8迭代下第500批次: 判别损失=0.764958381652832，生成损失=1.6080520153045654, real_dmean=0.6707180738449097, fake_dmean=0.25960877537727356\n",
      "第8迭代下第510批次: 判别损失=0.5606763958930969，生成损失=2.4801437854766846, real_dmean=0.7785454392433167, fake_dmean=0.23107829689979553\n",
      "第8迭代下第520批次: 判别损失=0.8177401423454285，生成损失=1.9805139303207397, real_dmean=0.6403086185455322, fake_dmean=0.22927618026733398\n",
      "第8迭代下第530批次: 判别损失=0.8909234404563904，生成损失=1.5586192607879639, real_dmean=0.6969093084335327, fake_dmean=0.3547837734222412\n",
      "第8迭代下第540批次: 判别损失=0.6821538209915161，生成损失=2.2964720726013184, real_dmean=0.7500091791152954, fake_dmean=0.2838405966758728\n",
      "第8迭代下第550批次: 判别损失=0.8755480647087097，生成损失=2.2349507808685303, real_dmean=0.6696832180023193, fake_dmean=0.3326677680015564\n",
      "第8迭代下第560批次: 判别损失=0.7096395492553711，生成损失=1.5385502576828003, real_dmean=0.6483902335166931, fake_dmean=0.192469984292984\n",
      "第8迭代下第570批次: 判别损失=0.9906352758407593，生成损失=2.313215494155884, real_dmean=0.6489577293395996, fake_dmean=0.3666583001613617\n",
      "第8迭代下第580批次: 判别损失=0.706813633441925，生成损失=1.5781517028808594, real_dmean=0.6671902537345886, fake_dmean=0.20545949041843414\n",
      "第8迭代下第590批次: 判别损失=0.806086540222168，生成损失=1.533759355545044, real_dmean=0.6060731410980225, fake_dmean=0.2012557089328766\n",
      "第8迭代下第600批次: 判别损失=0.76869797706604，生成损失=1.9806631803512573, real_dmean=0.7215678691864014, fake_dmean=0.3144310712814331\n",
      "第8迭代下第610批次: 判别损失=0.8445101976394653，生成损失=1.9460978507995605, real_dmean=0.5820684432983398, fake_dmean=0.20390434563159943\n",
      "第8迭代下第620批次: 判别损失=0.9016091227531433，生成损失=2.2074813842773438, real_dmean=0.7258265018463135, fake_dmean=0.38794243335723877\n",
      "第8迭代下第630批次: 判别损失=0.9490610361099243，生成损失=1.5524696111679077, real_dmean=0.575742781162262, fake_dmean=0.24583174288272858\n",
      "第8迭代下第640批次: 判别损失=0.7689306735992432，生成损失=2.076345443725586, real_dmean=0.6674556732177734, fake_dmean=0.2423688769340515\n",
      "第8迭代下第650批次: 判别损失=1.0471593141555786，生成损失=2.826317310333252, real_dmean=0.7905775308609009, fake_dmean=0.49740278720855713\n",
      "第8迭代下第660批次: 判别损失=1.0024360418319702，生成损失=1.2995119094848633, real_dmean=0.5187437534332275, fake_dmean=0.17307528853416443\n",
      "第8迭代下第670批次: 判别损失=0.7655227780342102，生成损失=1.9590091705322266, real_dmean=0.7492586374282837, fake_dmean=0.34125402569770813\n",
      "第8迭代下第680批次: 判别损失=0.720927357673645，生成损失=2.6996676921844482, real_dmean=0.766309916973114, fake_dmean=0.3103100061416626\n",
      "第8迭代下第690批次: 判别损失=0.8985267281532288，生成损失=2.4918606281280518, real_dmean=0.7972805500030518, fake_dmean=0.43690603971481323\n",
      "第8迭代下第700批次: 判别损失=0.7119731903076172，生成损失=1.6773850917816162, real_dmean=0.6606502532958984, fake_dmean=0.20274029672145844\n",
      "第8迭代下第710批次: 判别损失=0.9591782093048096，生成损失=2.7607977390289307, real_dmean=0.7612835764884949, fake_dmean=0.44579851627349854\n",
      "第8迭代下第720批次: 判别损失=1.146691083908081，生成损失=1.281919002532959, real_dmean=0.5699827671051025, fake_dmean=0.3517187535762787\n",
      "第8迭代下第730批次: 判别损失=0.8366302847862244，生成损失=1.9176322221755981, real_dmean=0.6723276972770691, fake_dmean=0.30457764863967896\n",
      "第8迭代下第740批次: 判别损失=0.7693947553634644，生成损失=1.4178965091705322, real_dmean=0.6375619173049927, fake_dmean=0.22005361318588257\n",
      "第8迭代下第750批次: 判别损失=0.7025401592254639，生成损失=2.03113055229187, real_dmean=0.5759928822517395, fake_dmean=0.08938722312450409\n",
      "第8迭代下第760批次: 判别损失=0.7923777103424072，生成损失=2.9573307037353516, real_dmean=0.7406456470489502, fake_dmean=0.3497764468193054\n",
      "第8迭代下第770批次: 判别损失=0.7519406080245972，生成损失=2.442131996154785, real_dmean=0.7616922855377197, fake_dmean=0.3476217985153198\n",
      "第8迭代下第780批次: 判别损失=0.7828165888786316，生成损失=2.576748847961426, real_dmean=0.8986388444900513, fake_dmean=0.4648229777812958\n",
      "第9迭代下第0批次: 判别损失=0.8226260542869568，生成损失=1.725183367729187, real_dmean=0.737206757068634, fake_dmean=0.3662833273410797\n",
      "第9迭代下第10批次: 判别损失=0.6735207438468933，生成损失=2.434800148010254, real_dmean=0.8223258852958679, fake_dmean=0.3524063229560852\n",
      "第9迭代下第20批次: 判别损失=1.0114529132843018，生成损失=1.385108470916748, real_dmean=0.4349384903907776, fake_dmean=0.08136250823736191\n",
      "第9迭代下第30批次: 判别损失=0.912251353263855，生成损失=2.164350986480713, real_dmean=0.8437082767486572, fake_dmean=0.48631995916366577\n",
      "第9迭代下第40批次: 判别损失=0.7581082582473755，生成损失=1.339775562286377, real_dmean=0.638404369354248, fake_dmean=0.21341444551944733\n",
      "第9迭代下第50批次: 判别损失=0.7134996056556702，生成损失=2.470621347427368, real_dmean=0.7590941786766052, fake_dmean=0.3199514150619507\n",
      "第9迭代下第60批次: 判别损失=0.9757987856864929，生成损失=2.2890706062316895, real_dmean=0.810355544090271, fake_dmean=0.491237610578537\n",
      "第9迭代下第70批次: 判别损失=0.8885072469711304，生成损失=1.793078064918518, real_dmean=0.6111897230148315, fake_dmean=0.27180778980255127\n",
      "第9迭代下第80批次: 判别损失=0.8581790924072266，生成损失=1.1687214374542236, real_dmean=0.5554229617118835, fake_dmean=0.18139971792697906\n",
      "第9迭代下第90批次: 判别损失=0.7997645735740662，生成损失=1.1924848556518555, real_dmean=0.6281115412712097, fake_dmean=0.230913907289505\n",
      "第9迭代下第100批次: 判别损失=0.9264235496520996，生成损失=2.7933568954467773, real_dmean=0.8459532856941223, fake_dmean=0.4929926097393036\n",
      "第9迭代下第110批次: 判别损失=0.8016241788864136，生成损失=1.4910434484481812, real_dmean=0.723506510257721, fake_dmean=0.3321038782596588\n",
      "第9迭代下第120批次: 判别损失=0.8315870761871338，生成损失=1.3899035453796387, real_dmean=0.5920114517211914, fake_dmean=0.2033143788576126\n",
      "第9迭代下第130批次: 判别损失=0.8106358647346497，生成损失=1.6325968503952026, real_dmean=0.6101652383804321, fake_dmean=0.23436790704727173\n",
      "第9迭代下第140批次: 判别损失=0.8232853412628174，生成损失=2.3735642433166504, real_dmean=0.7994237542152405, fake_dmean=0.4075126349925995\n",
      "第9迭代下第150批次: 判别损失=0.7668451070785522，生成损失=2.162625789642334, real_dmean=0.7489205598831177, fake_dmean=0.3504719138145447\n",
      "第9迭代下第160批次: 判别损失=1.167183518409729，生成损失=1.4647425413131714, real_dmean=0.37914228439331055, fake_dmean=0.09164012968540192\n",
      "第9迭代下第170批次: 判别损失=0.7371940612792969，生成损失=2.0324981212615967, real_dmean=0.727510392665863, fake_dmean=0.3064258396625519\n",
      "第9迭代下第180批次: 判别损失=0.7978732585906982，生成损失=1.934271216392517, real_dmean=0.6996699571609497, fake_dmean=0.31129950284957886\n",
      "第9迭代下第190批次: 判别损失=1.0789366960525513，生成损失=3.0198240280151367, real_dmean=0.9030889272689819, fake_dmean=0.5583579540252686\n",
      "第9迭代下第200批次: 判别损失=1.139146089553833，生成损失=1.4259636402130127, real_dmean=0.40643519163131714, fake_dmean=0.0804210677742958\n",
      "第9迭代下第210批次: 判别损失=0.9702167510986328，生成损失=2.338047981262207, real_dmean=0.7464374303817749, fake_dmean=0.4475773274898529\n",
      "第9迭代下第220批次: 判别损失=1.0766644477844238，生成损失=1.592401385307312, real_dmean=0.4091072380542755, fake_dmean=0.07538993656635284\n",
      "第9迭代下第230批次: 判别损失=0.7286673784255981，生成损失=2.3711183071136475, real_dmean=0.8095040321350098, fake_dmean=0.3635956346988678\n",
      "第9迭代下第240批次: 判别损失=0.6609163880348206，生成损失=2.212512493133545, real_dmean=0.7996634244918823, fake_dmean=0.3184245824813843\n",
      "第9迭代下第250批次: 判别损失=0.9048903584480286，生成损失=1.3575167655944824, real_dmean=0.6903282403945923, fake_dmean=0.35858020186424255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第9迭代下第260批次: 判别损失=0.7306243181228638，生成损失=1.661392092704773, real_dmean=0.6388769149780273, fake_dmean=0.20002338290214539\n",
      "第9迭代下第270批次: 判别损失=0.7049425840377808，生成损失=2.03511905670166, real_dmean=0.7529082298278809, fake_dmean=0.3069228231906891\n",
      "第9迭代下第280批次: 判别损失=1.1079535484313965，生成损失=1.1558510065078735, real_dmean=0.4830162525177002, fake_dmean=0.20679128170013428\n",
      "第9迭代下第290批次: 判别损失=0.905644416809082，生成损失=1.4211890697479248, real_dmean=0.5158320665359497, fake_dmean=0.15067633986473083\n",
      "第9迭代下第300批次: 判别损失=0.7936159372329712，生成损失=1.4075424671173096, real_dmean=0.6391701698303223, fake_dmean=0.23706990480422974\n",
      "第9迭代下第310批次: 判别损失=0.7821336388587952，生成损失=1.7640748023986816, real_dmean=0.645266056060791, fake_dmean=0.23207689821720123\n",
      "第9迭代下第320批次: 判别损失=0.9953293800354004，生成损失=2.560338020324707, real_dmean=0.8643552660942078, fake_dmean=0.5323917865753174\n",
      "第9迭代下第330批次: 判别损失=0.6586422324180603，生成损失=1.9843354225158691, real_dmean=0.7260493636131287, fake_dmean=0.2507269084453583\n",
      "第9迭代下第340批次: 判别损失=1.2366554737091064，生成损失=0.9985905885696411, real_dmean=0.37691986560821533, fake_dmean=0.10041052848100662\n",
      "第9迭代下第350批次: 判别损失=0.9335637092590332，生成损失=1.076489806175232, real_dmean=0.5141116380691528, fake_dmean=0.15776817500591278\n",
      "第9迭代下第360批次: 判别损失=0.8449729084968567，生成损失=1.2789781093597412, real_dmean=0.5974688529968262, fake_dmean=0.19674015045166016\n",
      "第9迭代下第370批次: 判别损失=0.9364750385284424，生成损失=1.8522229194641113, real_dmean=0.7468551397323608, fake_dmean=0.4302303194999695\n",
      "第9迭代下第380批次: 判别损失=0.8496527075767517，生成损失=1.8270177841186523, real_dmean=0.6837700605392456, fake_dmean=0.3265818953514099\n",
      "第9迭代下第390批次: 判别损失=0.7724326848983765，生成损失=2.5332610607147217, real_dmean=0.7687968015670776, fake_dmean=0.35769760608673096\n",
      "第9迭代下第400批次: 判别损失=0.8716623783111572，生成损失=1.977453351020813, real_dmean=0.8012709617614746, fake_dmean=0.43900442123413086\n",
      "第9迭代下第410批次: 判别损失=0.7435185313224792，生成损失=2.215304374694824, real_dmean=0.6057925820350647, fake_dmean=0.16214564442634583\n",
      "第9迭代下第420批次: 判别损失=0.9674365520477295，生成损失=2.356708288192749, real_dmean=0.8334020376205444, fake_dmean=0.5046722292900085\n",
      "第9迭代下第430批次: 判别损失=0.7451663017272949，生成损失=1.4928475618362427, real_dmean=0.6739470958709717, fake_dmean=0.2525404393672943\n",
      "第9迭代下第440批次: 判别损失=0.8762439489364624，生成损失=1.9243886470794678, real_dmean=0.6867043972015381, fake_dmean=0.34268373250961304\n",
      "第9迭代下第450批次: 判别损失=0.8247473835945129，生成损失=1.8480710983276367, real_dmean=0.5414000749588013, fake_dmean=0.09304707497358322\n",
      "第9迭代下第460批次: 判别损失=0.8201051950454712，生成损失=1.644562005996704, real_dmean=0.7072902917861938, fake_dmean=0.3314144015312195\n",
      "第9迭代下第470批次: 判别损失=1.0189396142959595，生成损失=1.1916476488113403, real_dmean=0.443015992641449, fake_dmean=0.09093712270259857\n",
      "第9迭代下第480批次: 判别损失=0.9852555990219116，生成损失=2.3427343368530273, real_dmean=0.880179226398468, fake_dmean=0.534835934638977\n",
      "第9迭代下第490批次: 判别损失=0.8727670311927795，生成损失=1.912962794303894, real_dmean=0.5435841679573059, fake_dmean=0.14883966743946075\n",
      "第9迭代下第500批次: 判别损失=0.8943907022476196，生成损失=1.136202096939087, real_dmean=0.6175931096076965, fake_dmean=0.26803433895111084\n",
      "第9迭代下第510批次: 判别损失=0.7728461027145386，生成损失=1.760854721069336, real_dmean=0.7517632842063904, fake_dmean=0.3492409586906433\n",
      "第9迭代下第520批次: 判别损失=0.9025352001190186，生成损失=2.3245720863342285, real_dmean=0.775025486946106, fake_dmean=0.4329519271850586\n",
      "第9迭代下第530批次: 判别损失=0.6437798738479614，生成损失=2.380436897277832, real_dmean=0.843926727771759, fake_dmean=0.34198203682899475\n",
      "第9迭代下第540批次: 判别损失=0.6758846640586853，生成损失=2.3086137771606445, real_dmean=0.8905603885650635, fake_dmean=0.3950178623199463\n",
      "第9迭代下第550批次: 判别损失=0.6505399942398071，生成损失=2.2600560188293457, real_dmean=0.7654123306274414, fake_dmean=0.27842551469802856\n",
      "第9迭代下第560批次: 判别损失=1.2849602699279785，生成损失=1.0070151090621948, real_dmean=0.37281256914138794, fake_dmean=0.12779122591018677\n",
      "第9迭代下第570批次: 判别损失=0.9131869673728943，生成损失=2.0830976963043213, real_dmean=0.7589510679244995, fake_dmean=0.40678343176841736\n",
      "第9迭代下第580批次: 判别损失=0.7698959708213806，生成损失=2.2079763412475586, real_dmean=0.7845966815948486, fake_dmean=0.3653436303138733\n",
      "第9迭代下第590批次: 判别损失=0.909765362739563，生成损失=3.1634416580200195, real_dmean=0.8565750122070312, fake_dmean=0.48092034459114075\n",
      "第9迭代下第600批次: 判别损失=0.8612171411514282，生成损失=1.165298581123352, real_dmean=0.5505892634391785, fake_dmean=0.15223586559295654\n",
      "第9迭代下第610批次: 判别损失=0.9046067595481873，生成损失=1.3457343578338623, real_dmean=0.543269693851471, fake_dmean=0.1892639547586441\n",
      "第9迭代下第620批次: 判别损失=0.6825319528579712，生成损失=1.7762963771820068, real_dmean=0.7515076398849487, fake_dmean=0.2964577376842499\n",
      "第9迭代下第630批次: 判别损失=0.78700852394104，生成损失=1.6565802097320557, real_dmean=0.6001455783843994, fake_dmean=0.18103504180908203\n",
      "第9迭代下第640批次: 判别损失=1.0960465669631958，生成损失=1.1113481521606445, real_dmean=0.4849889278411865, fake_dmean=0.2320309430360794\n",
      "第9迭代下第650批次: 判别损失=1.017423391342163，生成损失=2.4405689239501953, real_dmean=0.8522129058837891, fake_dmean=0.518925130367279\n",
      "第9迭代下第660批次: 判别损失=0.8288624882698059，生成损失=1.0790808200836182, real_dmean=0.589745044708252, fake_dmean=0.19270861148834229\n",
      "第9迭代下第670批次: 判别损失=0.899724006652832，生成损失=1.2971793413162231, real_dmean=0.5401326417922974, fake_dmean=0.17288154363632202\n",
      "第9迭代下第680批次: 判别损失=0.7891038060188293，生成损失=1.528486967086792, real_dmean=0.6983298063278198, fake_dmean=0.3061077892780304\n",
      "第9迭代下第690批次: 判别损失=0.9749530553817749，生成损失=1.3093175888061523, real_dmean=0.6486247777938843, fake_dmean=0.35923483967781067\n",
      "第9迭代下第700批次: 判别损失=0.7796492576599121，生成损失=2.009549617767334, real_dmean=0.7182949185371399, fake_dmean=0.30764228105545044\n",
      "第9迭代下第710批次: 判别损失=0.8813340067863464，生成损失=1.8987634181976318, real_dmean=0.6133084297180176, fake_dmean=0.25442901253700256\n",
      "第9迭代下第720批次: 判别损失=0.7413477897644043，生成损失=1.7255388498306274, real_dmean=0.6929059624671936, fake_dmean=0.26768186688423157\n",
      "第9迭代下第730批次: 判别损失=0.9324972629547119，生成损失=1.6655625104904175, real_dmean=0.6735610961914062, fake_dmean=0.3606276512145996\n",
      "第9迭代下第740批次: 判别损失=0.7968605756759644，生成损失=1.654052734375, real_dmean=0.5886977910995483, fake_dmean=0.1732683628797531\n",
      "第9迭代下第750批次: 判别损失=0.9460666179656982，生成损失=1.3553688526153564, real_dmean=0.5146138668060303, fake_dmean=0.1391030251979828\n",
      "第9迭代下第760批次: 判别损失=0.5533206462860107，生成损失=2.191068649291992, real_dmean=0.7725096344947815, fake_dmean=0.2255767583847046\n",
      "第9迭代下第770批次: 判别损失=0.9894225597381592，生成损失=1.6594924926757812, real_dmean=0.5291900038719177, fake_dmean=0.2087785303592682\n",
      "第9迭代下第780批次: 判别损失=0.7083799839019775，生成损失=1.847747802734375, real_dmean=0.7326517701148987, fake_dmean=0.28373444080352783\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "goptimizer = torch.optim.Adam(gnet.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "doptimizer = torch.optim.Adam(dnet.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        # 无监督训练\n",
    "        real_images, _ = data\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # 真实数据\n",
    "        real_labels = torch.ones(batch_size)\n",
    "        real_preds = dnet(real_images).reshape(-1)\n",
    "        real_dloss = criterion(real_preds, real_labels)\n",
    "        real_dmean = real_preds.sigmoid().mean()\n",
    "        \n",
    "        # 生成数据\n",
    "        noise_input = torch.randn(batch_size, 64, 1, 1)\n",
    "        fake_images = gnet(noise_input)\n",
    "        fake_labels_ = torch.zeros(batch_size)\n",
    "        fake_images_ = fake_images.detach()\n",
    "        fake_preds_ = dnet(fake_images_).view(-1)\n",
    "        fake_dloss_ = criterion(fake_preds_, fake_labels_)\n",
    "        fake_dmean = fake_preds_.sigmoid().mean()\n",
    "        \n",
    "        # 训练判别器：同时优化真实数据和生成数据\n",
    "        dloss = real_dloss + fake_dloss_\n",
    "        doptimizer.zero_grad()\n",
    "        dloss.backward()\n",
    "        doptimizer.step()\n",
    "        \n",
    "        # 训练生成器：优化生成数据\n",
    "        fake_labels = torch.ones(batch_size)\n",
    "        fake_preds = dnet(fake_images).view(-1)\n",
    "        gloss = criterion(fake_preds, fake_labels)\n",
    "        goptimizer.zero_grad()\n",
    "        gloss.backward()\n",
    "        goptimizer.step()\n",
    "        \n",
    "        if batch_idx%10==0:\n",
    "            print('第{}迭代下第{}批次: 判别损失={}，生成损失={}, real_dmean={}, fake_dmean={}'.\n",
    "              format(epoch, batch_idx, dloss, gloss, real_dmean, fake_dmean))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成新样本，看看\n",
    "noise_input = torch.randn(batch_size, 64, 1, 1)\n",
    "fake_images = gnet(noise_input)\n",
    "fake_labels_ = torch.zeros(batch_size)\n",
    "fake_images_ = fake_images.detach()\n",
    "for i, fake_image_ in enumerate(fake_images_):\n",
    "    # print(fake_image_.shape)\n",
    "    save_image(fake_image_, './data/fake_images/{}.png'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

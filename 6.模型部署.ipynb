{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型导出，c++/python高性能推理（可以认为只具有前向推理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.onnx及其onnxruntime（微软）\n",
    "# 只要平台或终端支持onnxruntime就可以执行onnx模型\n",
    "# 无论通过何种方式导出ONNX模型，最终的目的都是将模型部署到目标平台并进行推理。\n",
    "# 目前为止，很多推理框架都直接或者间接的支持ONNX模型推理，如ONNXRuntime（ORT）、TensorRT和TVM\n",
    "# （TensorRT和TVM将在后面的文章中进行介绍与分析）可以直接部署ONNX模型，Torch、Tensorflow和mxnet等可以间接的\n",
    "# 通过官方提供的工具对模型进行转换实现ONN模型的部署。\n",
    "# onnx底层采用谷歌的protobuffer定义\n",
    "# onnx与pytorch交互本质是调用torch.jit.trace\n",
    "\n",
    "pip install onnx\n",
    "pip install onnxruntime # use cpu\n",
    "pip install onnxruntime-gpu # use gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T05:19:30.319562900Z",
     "start_time": "2023-08-15T05:19:30.225821700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.00858306884765625\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from time import time\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "model = torch.load('models/LSTM_MLP_AE_[64,32],[32,64]_32_epoch=997_valloss=234.79.pt')\n",
    "\n",
    "# 必须为推理模式\n",
    "model.eval()\n",
    "# dummy_input就是一个输入的实例，仅提供输入shape、type等信息 \n",
    "batch_size = 10 # 随机的取值，当设置dynamic_axes后影响不大\n",
    "dummy_input = torch.randn(batch_size, 30, 3, requires_grad=True).to(device)\n",
    "t1 = time()\n",
    "output = model(dummy_input)\n",
    "print('time:', time()-t1)\n",
    "\n",
    "# 导出模型，实现从pytorch模型到onnx转换，每个pytorch操作转换onnx算子\n",
    "onnx_file_name = 'models/LSTM_MLP_AE.onnx'\n",
    "torch.onnx.export(model,        # 模型的名称\n",
    "                  dummy_input,   # 一组实例化输入\n",
    "                  onnx_file_name,   # 文件保存路径/名称\n",
    "                  export_params=True,        #  如果指定为True或默认, 参数也会被导出. 如果你要导出一个没训练过的就设为 False.\n",
    "                  opset_version=10,          # ONNX 算子集的版本，当前已更新到15\n",
    "                  do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "                  input_names = ['input'],   # 输入模型的张量的名称，需要用netron查看onnx文件\n",
    "                  output_names = ['output'], # 输出模型的张量的名称，需要用netron查看onnx文件\n",
    "                  # dynamic_axes将batch_size的维度指定为动态，\n",
    "                  # 后续进行推理的数据可以与导出的dummy_input的batch_size不同\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "# 实际上，导出需要注意很多问题，模型里一些算子转化为onnx并不友好，需要修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "# 我们可以使用异常处理的方法进行检验\n",
    "try:\n",
    "    # 当我们的模型不可用时，将会报出异常\n",
    "    onnx.checker.check_model(onnx_file_name)\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(\"The model is invalid: %s\"%e)\n",
    "else:\n",
    "    # 模型可用时，将不会报出异常，并会输出“The model is valid!”\n",
    "    print(\"The model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用Netron可视化ONNX格式的模型\n",
    "# https://github.com/lutzroeder/netron/releases/tag/v7.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.0011768341064453125\n",
      "input: (10, 30, 3)\n",
      "output: (10, 30, 3)\n",
      "[[[3.23216617e-02 3.31142545e-03 1.52625173e-01]\n",
      "  [1.56924307e-01 2.24587321e-03 1.58904791e-01]\n",
      "  [1.63386464e-01 3.64223123e-03 1.45755202e-01]\n",
      "  [2.97241092e-01 7.05817640e-02 1.43262357e-01]\n",
      "  [3.34667712e-01 7.13166296e-02 1.37585998e-01]\n",
      "  [3.64846259e-01 1.54044390e-01 1.37276560e-01]\n",
      "  [4.27440286e-01 2.05454558e-01 1.51976436e-01]\n",
      "  [4.19373035e-01 2.71701992e-01 1.46220148e-01]\n",
      "  [5.05093336e-01 2.58284658e-01 1.64969146e-01]\n",
      "  [4.57483113e-01 2.53103524e-01 1.48771316e-01]\n",
      "  [5.32694817e-01 2.10138977e-01 1.44022912e-01]\n",
      "  [5.63353300e-01 2.24701196e-01 1.55759186e-01]\n",
      "  [5.74124515e-01 8.48690569e-02 1.57262921e-01]\n",
      "  [5.78734219e-01 2.47707069e-02 1.54802412e-01]\n",
      "  [5.81529021e-01 1.28314793e-02 1.61350995e-01]\n",
      "  [6.16788208e-01 1.08636320e-02 1.69775695e-01]\n",
      "  [5.82189441e-01 7.64288604e-02 1.67744070e-01]\n",
      "  [5.11988461e-01 2.44493246e-01 1.44173056e-01]\n",
      "  [4.59290028e-01 4.27703440e-01 1.46017939e-01]\n",
      "  [3.06495130e-01 3.29292297e-01 1.63621306e-01]\n",
      "  [1.19320840e-01 3.30627918e-01 1.49052352e-01]\n",
      "  [6.91787004e-02 3.20626974e-01 1.45542175e-01]\n",
      "  [4.54498231e-02 3.27678680e-01 1.46017879e-01]\n",
      "  [6.42840862e-02 1.26496226e-01 1.48595631e-01]\n",
      "  [1.21279925e-01 8.13822150e-02 1.63673252e-01]\n",
      "  [3.43977869e-01 4.14092839e-02 1.61546618e-01]\n",
      "  [4.43970859e-01 9.85710323e-02 1.63333297e-01]\n",
      "  [5.41165352e-01 6.79941773e-02 1.52486414e-01]\n",
      "  [5.64812422e-01 1.49371177e-01 1.72412008e-01]\n",
      "  [6.33575797e-01 1.83936268e-01 1.84269398e-01]]\n",
      "\n",
      " [[6.53963447e-01 6.20198190e-01 7.72116005e-01]\n",
      "  [9.69660699e-01 9.00563240e-01 6.60253763e-01]\n",
      "  [9.48343515e-01 9.93251622e-01 8.05676043e-01]\n",
      "  [9.33221221e-01 9.64585781e-01 4.70292717e-01]\n",
      "  [8.56621027e-01 8.97858620e-01 2.45371878e-01]\n",
      "  [8.24006855e-01 7.53706574e-01 2.57437587e-01]\n",
      "  [8.06309581e-01 5.98247349e-01 2.68094987e-01]\n",
      "  [7.83468127e-01 3.98205042e-01 1.15722537e-01]\n",
      "  [5.84321856e-01 6.16778970e-01 2.13782698e-01]\n",
      "  [6.61186814e-01 4.88730401e-01 5.32962978e-02]\n",
      "  [4.84537691e-01 4.08350766e-01 1.55742317e-01]\n",
      "  [5.59278429e-01 1.52221560e-01 2.39713490e-02]\n",
      "  [1.79617703e-01 1.84269547e-02 6.66728616e-03]\n",
      "  [3.34259450e-01 3.45835090e-03 2.48128176e-03]\n",
      "  [3.06560814e-01 8.29337835e-02 3.81812453e-03]\n",
      "  [7.63603449e-02 2.17860937e-03 2.38519907e-03]\n",
      "  [1.98976129e-01 2.26613879e-03 2.69129872e-03]\n",
      "  [2.36479878e-01 1.14792585e-03 3.10960412e-03]\n",
      "  [2.10283458e-01 1.50075555e-03 4.85959649e-03]\n",
      "  [2.77730942e-01 1.15490556e-02 5.98394871e-03]\n",
      "  [3.82823497e-01 6.56956434e-03 7.40396976e-03]\n",
      "  [4.46267486e-01 5.64247370e-03 1.08263791e-02]\n",
      "  [5.79269290e-01 6.64505363e-03 1.49970651e-02]\n",
      "  [5.07087767e-01 1.19024515e-03 1.23815536e-02]\n",
      "  [5.29037416e-01 2.57739425e-03 1.54258013e-02]\n",
      "  [5.30165911e-01 1.75559521e-03 1.45839453e-02]\n",
      "  [5.45517743e-01 1.06289089e-02 1.48641467e-02]\n",
      "  [4.06096548e-01 8.91155899e-02 9.65532660e-03]\n",
      "  [4.07968760e-01 2.88865924e-01 1.33047998e-02]\n",
      "  [2.69992471e-01 5.88152528e-01 4.89444137e-02]]\n",
      "\n",
      " [[9.91468728e-02 2.74437666e-03 1.49220586e-01]\n",
      "  [1.02166474e-01 2.62710452e-03 1.93913221e-01]\n",
      "  [2.25205272e-01 9.74655151e-04 2.80154228e-01]\n",
      "  [2.45648474e-01 1.09225512e-03 1.60974473e-01]\n",
      "  [1.47433668e-01 9.43243504e-04 1.61774069e-01]\n",
      "  [1.80552483e-01 1.88449025e-03 1.49142593e-01]\n",
      "  [6.73551261e-02 7.34448433e-04 1.16901129e-01]\n",
      "  [6.55653477e-02 1.58480704e-02 1.31420404e-01]\n",
      "  [1.01253092e-02 3.71316671e-02 1.26955330e-01]\n",
      "  [1.59819126e-02 5.72304130e-02 1.13324225e-01]\n",
      "  [1.03829801e-02 3.50048542e-02 9.89429653e-02]\n",
      "  [6.03434443e-03 1.99946433e-01 1.06139868e-01]\n",
      "  [6.54157996e-03 2.10827053e-01 9.72374380e-02]\n",
      "  [7.24098086e-03 2.17213422e-01 9.05212462e-02]\n",
      "  [6.96375966e-03 2.58326828e-01 8.02312195e-02]\n",
      "  [4.59668040e-03 3.39348406e-01 7.28094280e-02]\n",
      "  [4.35283780e-03 3.68678600e-01 3.14987898e-02]\n",
      "  [2.17026472e-03 1.17599875e-01 3.60474885e-02]\n",
      "  [3.94845009e-03 1.43628001e-01 2.65108049e-02]\n",
      "  [6.50048256e-03 2.97327340e-02 2.12161839e-02]\n",
      "  [3.02180648e-03 4.97490168e-03 2.07959712e-02]\n",
      "  [2.62427330e-03 2.08330154e-03 2.62021720e-02]\n",
      "  [4.97549772e-03 1.19338632e-02 3.16140056e-02]\n",
      "  [3.67501378e-03 1.12122595e-02 2.31645405e-02]\n",
      "  [6.20928407e-03 2.45350063e-01 2.13786364e-02]\n",
      "  [6.30295277e-03 5.12858748e-01 1.34074390e-02]\n",
      "  [7.38355517e-03 7.62559474e-01 1.63511038e-02]\n",
      "  [1.30772591e-02 9.02104139e-01 1.51954293e-02]\n",
      "  [9.94700193e-03 9.28049147e-01 1.52745843e-02]\n",
      "  [9.89135504e-02 8.39135945e-01 3.46392691e-02]]\n",
      "\n",
      " [[1.16657108e-01 1.63175672e-01 2.43144333e-02]\n",
      "  [1.15092844e-01 6.50667846e-02 2.65445411e-02]\n",
      "  [1.26854092e-01 1.36983991e-02 2.78230011e-02]\n",
      "  [1.29537433e-01 1.73109770e-03 3.05172205e-02]\n",
      "  [2.12900728e-01 8.28415155e-04 3.42617035e-02]\n",
      "  [2.22419143e-01 1.59341097e-03 3.68627608e-02]\n",
      "  [1.71505243e-01 1.32474303e-03 3.59537601e-02]\n",
      "  [1.80751026e-01 3.21120024e-03 3.98458242e-02]\n",
      "  [8.82716477e-02 2.40468681e-02 3.96562219e-02]\n",
      "  [1.08329266e-01 4.37575877e-02 3.45019698e-02]\n",
      "  [9.10854340e-02 1.11594290e-01 4.11992967e-02]\n",
      "  [9.91349816e-02 2.16135144e-01 4.11978662e-02]\n",
      "  [8.96895528e-02 2.23862886e-01 4.80312705e-02]\n",
      "  [7.01052248e-02 2.17498094e-01 4.72497940e-02]\n",
      "  [1.84181333e-01 2.21056193e-01 5.06166816e-02]\n",
      "  [2.59131134e-01 1.22510314e-01 5.07867038e-02]\n",
      "  [2.09635288e-01 1.62444115e-02 4.15814221e-02]\n",
      "  [1.46335065e-01 2.12597847e-03 4.40836847e-02]\n",
      "  [1.44148350e-01 8.72820616e-04 4.84644771e-02]\n",
      "  [1.79379672e-01 2.06023455e-03 5.26849627e-02]\n",
      "  [5.49919605e-02 9.64879990e-04 4.67689633e-02]\n",
      "  [3.94898653e-02 2.44846940e-03 5.25946319e-02]\n",
      "  [4.47213948e-02 3.39943171e-03 5.56739271e-02]\n",
      "  [2.16919184e-02 1.57111883e-03 6.03108406e-02]\n",
      "  [2.22716928e-02 3.71503830e-03 6.14443123e-02]\n",
      "  [2.66304016e-02 9.87643003e-03 5.90887070e-02]\n",
      "  [5.11018932e-02 6.80626035e-02 6.38726652e-02]\n",
      "  [8.05256069e-02 7.46627450e-02 5.70316017e-02]\n",
      "  [5.42769730e-02 3.01748812e-02 5.99318743e-02]\n",
      "  [8.77417326e-02 2.47737467e-02 6.09205663e-02]]\n",
      "\n",
      " [[3.38900089e-03 2.60955334e-01 1.18759573e-01]\n",
      "  [2.44200230e-03 1.55014217e-01 1.20651126e-01]\n",
      "  [1.06468797e-03 1.95678413e-01 1.06606901e-01]\n",
      "  [2.33602524e-03 1.02088481e-01 1.05857968e-01]\n",
      "  [2.08699703e-03 4.40598428e-02 1.02585018e-01]\n",
      "  [1.14372373e-03 2.05148757e-02 9.67494845e-02]\n",
      "  [2.36311555e-03 3.03761959e-02 1.01357251e-01]\n",
      "  [1.21110678e-03 3.38685811e-02 9.56958234e-02]\n",
      "  [7.87168741e-04 2.98371613e-02 9.90236700e-02]\n",
      "  [9.46104527e-04 4.26607430e-02 8.56707692e-02]\n",
      "  [1.16014481e-03 5.46580851e-02 8.67687762e-02]\n",
      "  [1.19075179e-03 5.01306057e-02 8.90734196e-02]\n",
      "  [2.70226598e-03 6.22301102e-02 8.70938003e-02]\n",
      "  [3.86318564e-03 5.32726347e-02 8.00052583e-02]\n",
      "  [1.51129663e-02 4.36872840e-02 8.94931555e-02]\n",
      "  [3.05529237e-02 4.51740623e-03 7.70729780e-02]\n",
      "  [1.13383025e-01 1.14476681e-03 6.67110682e-02]\n",
      "  [1.57369882e-01 1.08405948e-03 6.81521893e-02]\n",
      "  [1.57369107e-01 1.02853775e-03 6.25551045e-02]\n",
      "  [1.75829917e-01 1.62667036e-03 6.11893237e-02]\n",
      "  [1.10181093e-01 1.03780627e-03 5.62554002e-02]\n",
      "  [9.88318622e-02 1.20961666e-03 5.95041215e-02]\n",
      "  [6.88137710e-02 1.47211552e-03 6.10992014e-02]\n",
      "  [9.23982859e-02 1.96945667e-03 6.47386312e-02]\n",
      "  [7.16508627e-02 2.43815780e-03 5.97773790e-02]\n",
      "  [9.12222564e-02 2.22417712e-03 5.61943054e-02]\n",
      "  [9.60785151e-02 4.84766662e-02 5.55293858e-02]\n",
      "  [1.21022254e-01 8.87233317e-02 5.11432886e-02]\n",
      "  [6.63873553e-02 1.78849965e-01 5.42117059e-02]\n",
      "  [6.82137012e-02 3.49938631e-01 8.79308879e-02]]\n",
      "\n",
      " [[6.53449595e-01 7.89890647e-01 4.36018407e-01]\n",
      "  [8.28816175e-01 8.86139393e-01 5.24954319e-01]\n",
      "  [5.75327814e-01 4.75497216e-01 7.85811186e-01]\n",
      "  [6.06941223e-01 5.51324487e-01 7.72162437e-01]\n",
      "  [6.18255615e-01 6.03483796e-01 9.20716882e-01]\n",
      "  [7.29398608e-01 5.66084385e-01 8.82820845e-01]\n",
      "  [5.52957714e-01 5.78552902e-01 9.32002306e-01]\n",
      "  [6.71493769e-01 6.52285695e-01 8.91886711e-01]\n",
      "  [7.08384275e-01 5.23491204e-01 9.32984650e-01]\n",
      "  [7.40435123e-01 6.39934063e-01 8.47255707e-01]\n",
      "  [7.96262801e-01 7.54965901e-01 8.36288810e-01]\n",
      "  [7.35408425e-01 5.04522622e-01 8.93278599e-01]\n",
      "  [4.37710732e-01 3.98811638e-01 8.90828967e-01]\n",
      "  [4.73543882e-01 3.64666104e-01 8.76097679e-01]\n",
      "  [4.48611230e-01 3.64332080e-01 7.96158552e-01]\n",
      "  [4.16832149e-01 4.05889601e-01 8.78239870e-01]\n",
      "  [4.01021183e-01 6.39073133e-01 7.90974319e-01]\n",
      "  [3.48460734e-01 7.64842391e-01 7.11401522e-01]\n",
      "  [3.65211368e-01 8.34543586e-01 8.75955105e-01]\n",
      "  [3.84836614e-01 9.11075592e-01 8.09371471e-01]\n",
      "  [4.73323882e-01 9.60818708e-01 8.86128306e-01]\n",
      "  [4.68837082e-01 9.66114402e-01 8.21824312e-01]\n",
      "  [4.31318671e-01 9.04231548e-01 9.02416170e-01]\n",
      "  [4.94178951e-01 9.61618662e-01 8.76014650e-01]\n",
      "  [4.23076212e-01 7.44141698e-01 9.18012023e-01]\n",
      "  [4.08978581e-01 5.15612781e-01 9.22725916e-01]\n",
      "  [3.79093647e-01 4.69484329e-01 8.97134066e-01]\n",
      "  [3.89424562e-01 5.32535136e-01 8.61123681e-01]\n",
      "  [3.84424448e-01 5.60228467e-01 8.84833813e-01]\n",
      "  [3.88168603e-01 3.63254488e-01 8.24242234e-01]]\n",
      "\n",
      " [[9.15232301e-03 2.65429318e-01 1.39529109e-02]\n",
      "  [9.17300582e-03 2.30714470e-01 1.64485276e-02]\n",
      "  [2.16684937e-02 2.98312902e-01 3.14542949e-02]\n",
      "  [2.36844718e-02 3.48047733e-01 3.82024050e-02]\n",
      "  [2.03190148e-02 4.02437836e-01 3.90429795e-02]\n",
      "  [5.23548424e-02 4.26386595e-01 4.42779660e-02]\n",
      "  [7.34876394e-02 4.13970053e-01 4.73887622e-02]\n",
      "  [7.08900988e-02 4.32457447e-01 4.89062369e-02]\n",
      "  [1.23624027e-01 2.85648316e-01 5.02754748e-02]\n",
      "  [1.94402307e-01 1.79894924e-01 5.15012145e-02]\n",
      "  [2.93143272e-01 6.55854642e-02 5.24420738e-02]\n",
      "  [3.37125003e-01 4.68658209e-02 5.32618463e-02]\n",
      "  [3.69531900e-01 2.32670009e-02 5.66666424e-02]\n",
      "  [3.27200770e-01 4.70153689e-02 5.82005680e-02]\n",
      "  [4.21109140e-01 1.22108430e-01 5.68704009e-02]\n",
      "  [4.63853747e-01 1.59401417e-01 5.22050858e-02]\n",
      "  [4.56242085e-01 2.10047513e-01 5.14853597e-02]\n",
      "  [3.65032941e-01 1.87934041e-01 5.56358099e-02]\n",
      "  [3.81942391e-01 1.88825130e-01 5.57908714e-02]\n",
      "  [3.16334963e-01 1.62516862e-01 5.88791370e-02]\n",
      "  [2.43827313e-01 1.18528575e-01 5.77230453e-02]\n",
      "  [1.02839470e-01 6.10951483e-02 6.81102872e-02]\n",
      "  [5.63539565e-02 5.24811745e-02 7.34677613e-02]\n",
      "  [2.56984532e-02 3.06704044e-02 7.27661252e-02]\n",
      "  [5.73062897e-03 3.99830341e-02 7.16020465e-02]\n",
      "  [4.72921133e-03 7.00144172e-02 7.38261044e-02]\n",
      "  [5.00991940e-03 8.08509290e-02 7.30301440e-02]\n",
      "  [2.86504626e-03 6.84137642e-02 7.19075501e-02]\n",
      "  [3.80316377e-03 2.60654390e-02 7.18048811e-02]\n",
      "  [2.64865160e-03 8.73169303e-03 7.27463961e-02]]\n",
      "\n",
      " [[5.47447801e-03 7.68251896e-01 1.34772539e-01]\n",
      "  [5.85754514e-02 4.50217187e-01 1.41800642e-01]\n",
      "  [1.15645766e-01 4.89856362e-01 2.22480267e-01]\n",
      "  [1.64815784e-01 3.27072322e-01 1.46885842e-01]\n",
      "  [3.62975597e-01 1.35482669e-01 1.48649454e-01]\n",
      "  [4.57146019e-01 6.13108277e-02 1.48623466e-01]\n",
      "  [5.07811606e-01 8.30656886e-02 1.40477300e-01]\n",
      "  [5.47344744e-01 3.70171070e-02 1.33150190e-01]\n",
      "  [5.34016490e-01 4.48901057e-02 1.43882602e-01]\n",
      "  [4.98844057e-01 4.87328470e-02 1.29187465e-01]\n",
      "  [3.72973084e-01 9.73252952e-02 1.39073163e-01]\n",
      "  [2.91870892e-01 2.04874545e-01 1.26745224e-01]\n",
      "  [2.05717713e-01 1.58991665e-01 1.41267449e-01]\n",
      "  [1.08067185e-01 1.55737191e-01 1.32821113e-01]\n",
      "  [6.99060857e-02 1.91774487e-01 1.23890728e-01]\n",
      "  [7.16805756e-02 2.15090185e-01 1.27029032e-01]\n",
      "  [2.71383822e-02 7.31665492e-02 8.28992724e-02]\n",
      "  [2.81703174e-02 3.80390584e-02 1.08819127e-01]\n",
      "  [2.27989852e-02 1.47618055e-02 9.51314569e-02]\n",
      "  [3.99855375e-02 5.05180955e-02 9.82122421e-02]\n",
      "  [2.24514902e-02 4.93278205e-02 8.69136453e-02]\n",
      "  [3.12292874e-02 4.99233305e-02 9.57900882e-02]\n",
      "  [2.10722983e-02 1.18348897e-02 9.19076800e-02]\n",
      "  [3.02065909e-02 1.32462978e-02 8.40632319e-02]\n",
      "  [1.75340772e-02 1.39567554e-02 8.09856057e-02]\n",
      "  [3.08248997e-02 2.94649303e-02 8.60853195e-02]\n",
      "  [1.75268054e-02 1.42726898e-02 7.89960325e-02]\n",
      "  [1.59520507e-02 1.02464855e-02 8.16752613e-02]\n",
      "  [5.30940294e-03 2.09772587e-03 7.25180805e-02]\n",
      "  [3.06868553e-03 1.54915452e-03 7.18819797e-02]]\n",
      "\n",
      " [[6.31939530e-01 4.07535821e-01 4.85255420e-02]\n",
      "  [4.55258101e-01 4.28870916e-02 4.93215919e-02]\n",
      "  [4.79902893e-01 3.70565057e-03 1.42485797e-02]\n",
      "  [1.82942331e-01 5.86092472e-04 5.60113788e-03]\n",
      "  [6.06999993e-02 4.62657213e-03 7.21260905e-03]\n",
      "  [2.70224214e-02 6.10893965e-03 5.71414828e-03]\n",
      "  [1.42581463e-02 1.03222430e-02 5.97515702e-03]\n",
      "  [9.13611054e-03 4.60296869e-03 5.26577234e-03]\n",
      "  [5.86700439e-03 1.49112940e-03 5.10558486e-03]\n",
      "  [3.57511640e-03 1.34539604e-03 7.62712955e-03]\n",
      "  [5.28845191e-03 1.89289451e-03 7.20515847e-03]\n",
      "  [3.61990929e-03 2.84096599e-03 7.36355782e-03]\n",
      "  [2.76535749e-03 4.31355834e-03 5.75718284e-03]\n",
      "  [3.57815623e-03 1.10380352e-02 8.11520219e-03]\n",
      "  [4.77007031e-03 1.05197430e-02 8.11547041e-03]\n",
      "  [2.93183327e-03 1.03715062e-03 6.45908713e-03]\n",
      "  [6.56902790e-03 8.38220119e-04 1.08834505e-02]\n",
      "  [1.95753574e-02 7.48723745e-04 1.14614367e-02]\n",
      "  [2.31897235e-02 1.37025118e-03 1.09793842e-02]\n",
      "  [7.67157078e-02 2.02488899e-03 9.93138552e-03]\n",
      "  [1.13542855e-01 1.58694386e-03 1.28035843e-02]\n",
      "  [1.78182542e-01 1.77511573e-03 1.72595084e-02]\n",
      "  [3.02408665e-01 2.24667788e-03 2.02631354e-02]\n",
      "  [3.16909045e-01 2.27546692e-03 1.80650055e-02]\n",
      "  [3.34544688e-01 2.05673575e-02 1.76578462e-02]\n",
      "  [3.48576367e-01 4.32415307e-02 1.52418315e-02]\n",
      "  [3.18227172e-01 5.05571365e-02 1.27796233e-02]\n",
      "  [2.48494536e-01 4.14898992e-02 1.18078887e-02]\n",
      "  [1.77221000e-01 4.93525565e-02 1.45214200e-02]\n",
      "  [1.92080081e-01 7.15009868e-02 2.53968835e-02]]\n",
      "\n",
      " [[2.40794510e-01 1.86331779e-01 8.12742114e-03]\n",
      "  [1.65152431e-01 1.55966341e-01 4.79054451e-03]\n",
      "  [1.71678305e-01 2.29126066e-01 3.90082598e-03]\n",
      "  [1.36989564e-01 2.60981768e-01 3.94952297e-03]\n",
      "  [8.34187567e-02 3.69603902e-01 3.57836485e-03]\n",
      "  [4.95095253e-02 3.19938600e-01 3.86619568e-03]\n",
      "  [2.39254534e-02 3.38746011e-01 5.56981564e-03]\n",
      "  [1.21692419e-02 3.20308745e-01 7.76877999e-03]\n",
      "  [5.17034531e-03 2.90471435e-01 1.46942437e-02]\n",
      "  [2.38603354e-03 1.92128360e-01 1.84839666e-02]\n",
      "  [3.16140056e-03 1.01454496e-01 2.27539837e-02]\n",
      "  [3.28209996e-03 2.39954889e-02 2.25702524e-02]\n",
      "  [1.05185509e-02 3.53297591e-03 4.01886702e-02]\n",
      "  [7.84429908e-03 1.34488940e-03 4.18538749e-02]\n",
      "  [9.04955864e-02 2.04536319e-03 5.60312569e-02]\n",
      "  [1.38716072e-01 2.18784809e-03 5.39299250e-02]\n",
      "  [1.21143907e-01 1.33314729e-03 5.06132245e-02]\n",
      "  [1.12016201e-01 1.43996179e-02 5.30863404e-02]\n",
      "  [7.94869661e-02 3.72244120e-02 5.55351675e-02]\n",
      "  [6.28884137e-02 9.53821540e-02 5.39380312e-02]\n",
      "  [1.19816065e-02 2.44841248e-01 5.46921492e-02]\n",
      "  [2.73007154e-03 1.78406864e-01 5.74433506e-02]\n",
      "  [1.25083327e-03 3.38369548e-01 5.38904071e-02]\n",
      "  [8.63760710e-04 3.51613522e-01 5.58285117e-02]\n",
      "  [6.89417124e-04 2.23229527e-01 5.82050979e-02]\n",
      "  [1.40303373e-03 1.30177319e-01 5.91697097e-02]\n",
      "  [1.60604715e-03 5.37351370e-02 5.71528077e-02]\n",
      "  [3.90443206e-03 3.82116437e-02 6.06280267e-02]\n",
      "  [3.07583809e-03 1.06851459e-02 6.14244342e-02]\n",
      "  [1.12420917e-02 7.56910443e-03 6.50025308e-02]]]\n"
     ]
    }
   ],
   "source": [
    "# 采用onnx runtime推理引擎对onnx模型进行推理（微软研制）\n",
    "import onnxruntime\n",
    "# 需要进行推理的onnx模型文件名称\n",
    "\n",
    "# onnxruntime.InferenceSession用于获取一个 ONNX Runtime 推理器\n",
    "ort_session = onnxruntime.InferenceSession(onnx_file_name)  \n",
    "\n",
    "# 构建字典的输入数据，字典的key需要与我们构建onnx模型时的input_names相同\n",
    "# 输入也需要改变为ndarray格式\n",
    "ort_inputs = {'input': dummy_input.detach().cpu().numpy()}\n",
    "# 我们更建议使用下面这种方法,因为避免了手动输入key\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name:input_img}\n",
    "\n",
    "# pytorch动态建模，故需要执行一遍\n",
    "# run是进行模型的推理，第一个参数为输出张量名的列表，一般情况可以设置为None\n",
    "# 第二个参数为构建的输入值的字典\n",
    "# 由于返回的结果被列表嵌套，因此我们需要进行[0]的索引\n",
    "t1 = time()\n",
    "ort_output = ort_session.run(None,ort_inputs)[0]\n",
    "print('time:', time()-t1)\n",
    "# output = {ort_session.get_outputs()[0].name}\n",
    "# ort_output = ort_session.run([output], ort_inputs)[0]\n",
    "\n",
    "print('input:', dummy_input.detach().cpu().numpy().shape)\n",
    "print('output:', ort_output.shape)\n",
    "print(ort_output)\n",
    "\n",
    "# onnx比 pytorch model推理速度快数倍，这里是10倍\n",
    "# ONNX 表示更容易部署的静态图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx模型量化(三行代码)\n",
    "# 模型大小减小近乎一半\n",
    "# pip install onnxconverter_common\n",
    "\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "model_ = onnx.load('models/LSTM_MLP_AE.onnx') # 409 kb\n",
    "model__ = float16.convert_float_to_float16(model_)\n",
    "onnx.save(model__, 'models/LSTM_MLP_AE_.onnx') # 210 kb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = \"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"\n",
      "  _1 = \"input must have {} dimensions, got {}\"\n",
      "  _2 = \"input.size(-1) must be equal to input_size. Expected {}, got {}\"\n",
      "  _3 = \"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"\n",
      "  _4 = \"input must have {} dimensions, got {}\"\n",
      "  _5 = \"input.size(-1) must be equal to input_size. Expected {}, got {}\"\n",
      "  decoder = self.decoder\n",
      "  encoder = self.encoder\n",
      "  input_layer = encoder.input_layer\n",
      "  seq_len = encoder.seq_len\n",
      "  input_dim = encoder.input_dim\n",
      "  _6 = torch.reshape(x, [-1, seq_len, input_dim])\n",
      "  _00 = getattr(input_layer, \"0\")\n",
      "  weight = _00.weight\n",
      "  bias = _00.bias\n",
      "  input = torch.linear(_6, weight, bias)\n",
      "  x0 = torch.tanh(input)\n",
      "  lstms = encoder.lstms\n",
      "  _01 = getattr(lstms, \"0\")\n",
      "  _7 = torch.dim(x0)\n",
      "  if torch.__contains__([2, 3], _7):\n",
      "    pass\n",
      "  else:\n",
      "    _8 = torch.add(\"AssertionError: \", torch.format(_0, torch.dim(x0)))\n",
      "    ops.prim.RaiseException(_8)\n",
      "  is_batched = torch.eq(torch.dim(x0), 3)\n",
      "  if torch.__not__(is_batched):\n",
      "    input0 = torch.unsqueeze(x0, 0)\n",
      "  else:\n",
      "    input0 = x0\n",
      "  max_batch_size = torch.size(input0, 0)\n",
      "  _9 = ops.prim.dtype(input0)\n",
      "  _10 = ops.prim.device(input0)\n",
      "  h_zeros = torch.zeros([1, max_batch_size, 32], dtype=_9, layout=None, device=_10)\n",
      "  _11 = ops.prim.dtype(input0)\n",
      "  _12 = ops.prim.device(input0)\n",
      "  c_zeros = torch.zeros([1, max_batch_size, 32], dtype=_11, layout=None, device=_12)\n",
      "  hx = (h_zeros, c_zeros)\n",
      "  if torch.ne(torch.dim(input0), 3):\n",
      "    _13 = torch.format(_1, 3, torch.dim(input0))\n",
      "    ops.prim.RaiseException(_13, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  if torch.ne(64, torch.size(input0, -1)):\n",
      "    _14 = torch.format(_2, 64, torch.size(input0, -1))\n",
      "    ops.prim.RaiseException(_14, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _15 = (hx)[0]\n",
      "  mini_batch = torch.size(input0, 0)\n",
      "  expected_hidden_size = (1, mini_batch, 32)\n",
      "  _16 = torch.size(_15)\n",
      "  _17, _18, _19, = expected_hidden_size\n",
      "  if torch.ne(_16, [_17, _18, _19]):\n",
      "    _20 = torch.format(\"Expected hidden[0] size {}, got {}\", expected_hidden_size, torch.list(torch.size(_15)))\n",
      "    ops.prim.RaiseException(_20, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _21 = (hx)[1]\n",
      "  mini_batch0 = torch.size(input0, 0)\n",
      "  expected_hidden_size0 = (1, mini_batch0, 32)\n",
      "  _22 = torch.size(_21)\n",
      "  _23, _24, _25, = expected_hidden_size0\n",
      "  if torch.ne(_22, [_23, _24, _25]):\n",
      "    _26 = torch.format(\"Expected hidden[1] size {}, got {}\", expected_hidden_size0, torch.list(torch.size(_21)))\n",
      "    ops.prim.RaiseException(_26, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _flat_weights = _01._flat_weights\n",
      "  training = _01.training\n",
      "  _27, _28, = hx\n",
      "  _29, _30, _31 = torch.lstm(input0, [_27, _28], _flat_weights, True, 1, 0., training, False, True)\n",
      "  hidden = (_30, _31)\n",
      "  if torch.__not__(is_batched):\n",
      "    output0 = torch.squeeze(_29, 0)\n",
      "    hidden1 = (torch.squeeze(_30, 1), torch.squeeze(_31, 1))\n",
      "    hidden0, output = hidden1, output0\n",
      "  else:\n",
      "    hidden0, output = hidden, _29\n",
      "  x1, _32, = (output, hidden0)\n",
      "  output_layer = encoder.output_layer\n",
      "  seq_len0 = encoder.seq_len\n",
      "  encoder_dims = encoder.encoder_dims\n",
      "  _33 = [-1, torch.mul(seq_len0, encoder_dims[-1])]\n",
      "  _34 = torch.reshape(x1, _33)\n",
      "  _02 = getattr(output_layer, \"0\")\n",
      "  weight0 = _02.weight\n",
      "  bias0 = _02.bias\n",
      "  input1 = torch.linear(_34, weight0, bias0)\n",
      "  input2 = torch.tanh(input1)\n",
      "  input_layer0 = decoder.input_layer\n",
      "  _03 = getattr(input_layer0, \"0\")\n",
      "  weight1 = _03.weight\n",
      "  bias1 = _03.bias\n",
      "  input3 = torch.linear(input2, weight1, bias1)\n",
      "  x2 = torch.tanh(input3)\n",
      "  seq_len1 = decoder.seq_len\n",
      "  decoder_dims = decoder.decoder_dims\n",
      "  x3 = torch.reshape(x2, [-1, seq_len1, decoder_dims[0]])\n",
      "  lstms0 = decoder.lstms\n",
      "  _04 = getattr(lstms0, \"0\")\n",
      "  _35 = torch.dim(x3)\n",
      "  if torch.__contains__([2, 3], _35):\n",
      "    pass\n",
      "  else:\n",
      "    _36 = torch.add(\"AssertionError: \", torch.format(_3, torch.dim(x3)))\n",
      "    ops.prim.RaiseException(_36)\n",
      "  is_batched0 = torch.eq(torch.dim(x3), 3)\n",
      "  if torch.__not__(is_batched0):\n",
      "    input4 = torch.unsqueeze(x3, 0)\n",
      "  else:\n",
      "    input4 = x3\n",
      "  max_batch_size0 = torch.size(input4, 0)\n",
      "  _37 = ops.prim.dtype(input4)\n",
      "  _38 = ops.prim.device(input4)\n",
      "  h_zeros0 = torch.zeros([1, max_batch_size0, 64], dtype=_37, layout=None, device=_38)\n",
      "  _39 = ops.prim.dtype(input4)\n",
      "  _40 = ops.prim.device(input4)\n",
      "  c_zeros0 = torch.zeros([1, max_batch_size0, 64], dtype=_39, layout=None, device=_40)\n",
      "  hx0 = (h_zeros0, c_zeros0)\n",
      "  if torch.ne(torch.dim(input4), 3):\n",
      "    _41 = torch.format(_4, 3, torch.dim(input4))\n",
      "    ops.prim.RaiseException(_41, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  if torch.ne(32, torch.size(input4, -1)):\n",
      "    _42 = torch.format(_5, 32, torch.size(input4, -1))\n",
      "    ops.prim.RaiseException(_42, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _43 = (hx0)[0]\n",
      "  mini_batch1 = torch.size(input4, 0)\n",
      "  expected_hidden_size1 = (1, mini_batch1, 64)\n",
      "  _44 = torch.size(_43)\n",
      "  _45, _46, _47, = expected_hidden_size1\n",
      "  if torch.ne(_44, [_45, _46, _47]):\n",
      "    _48 = torch.format(\"Expected hidden[0] size {}, got {}\", expected_hidden_size1, torch.list(torch.size(_43)))\n",
      "    ops.prim.RaiseException(_48, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _49 = (hx0)[1]\n",
      "  mini_batch2 = torch.size(input4, 0)\n",
      "  expected_hidden_size2 = (1, mini_batch2, 64)\n",
      "  _50 = torch.size(_49)\n",
      "  _51, _52, _53, = expected_hidden_size2\n",
      "  if torch.ne(_50, [_51, _52, _53]):\n",
      "    _54 = torch.format(\"Expected hidden[1] size {}, got {}\", expected_hidden_size2, torch.list(torch.size(_49)))\n",
      "    ops.prim.RaiseException(_54, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _flat_weights0 = _04._flat_weights\n",
      "  training0 = _04.training\n",
      "  _55, _56, = hx0\n",
      "  _57, _58, _59 = torch.lstm(input4, [_55, _56], _flat_weights0, True, 1, 0., training0, False, True)\n",
      "  hidden2 = (_58, _59)\n",
      "  if torch.__not__(is_batched0):\n",
      "    output2 = torch.squeeze(_57, 0)\n",
      "    hidden4 = (torch.squeeze(_58, 1), torch.squeeze(_59, 1))\n",
      "    hidden3, output1 = hidden4, output2\n",
      "  else:\n",
      "    hidden3, output1 = hidden2, _57\n",
      "  x4, _60, = (output1, hidden3)\n",
      "  output_layer0 = decoder.output_layer\n",
      "  _05 = getattr(output_layer0, \"0\")\n",
      "  weight2 = _05.weight\n",
      "  bias2 = _05.bias\n",
      "  input5 = torch.linear(x4, weight2, bias2)\n",
      "  return torch.sigmoid(input5)\n",
      "\n",
      "2 graph(%self : __torch__.models.LSTM_MLP_AE.LSTM_MLP_AE,\n",
      "      %x.1 : Tensor):\n",
      "  %decoder : __torch__.models.LSTM_MLP_AE.Decoder = prim::GetAttr[name=\"decoder\"](%self)\n",
      "  %encoder : __torch__.models.LSTM_MLP_AE.Encoder = prim::GetAttr[name=\"encoder\"](%self)\n",
      "  %16 : bool = prim::Constant[value=0]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:813:59\n",
      "  %17 : float = prim::Constant[value=0.]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:813:30\n",
      "  %18 : str = prim::Constant[value=\"builtins.RuntimeError\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:798:30\n",
      "  %19 : bool = prim::Constant[value=1]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:795:24\n",
      "  %20 : int = prim::Constant[value=32]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:784:73\n",
      "  %21 : str = prim::Constant[value=\"AssertionError: \"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "  %22 : str = prim::Constant[value=\"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:44\n",
      "  %batch_sizes.4 : NoneType = prim::Constant() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:772:26\n",
      "  %24 : int = prim::Constant[value=2]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:36\n",
      "  %25 : int = prim::Constant[value=3]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:39\n",
      "  %batch_dim.1 : int = prim::Constant[value=0]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:775:24\n",
      "  %27 : int = prim::Constant[value=1]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:783:58\n",
      "  %28 : str = prim::Constant[value=\"input.size(-1) must be equal to input_size. Expected {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:219:16\n",
      "  %29 : int = prim::Constant[value=64]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:11\n",
      "  %30 : str = prim::Constant[value=\"input must have {} dimensions, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:215:16\n",
      "  %31 : str = prim::Constant[value=\"Expected hidden[0] size {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:732:31\n",
      "  %32 : str = prim::Constant[value=\"Expected hidden[1] size {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:734:31\n",
      "  %33 : int = prim::Constant[value=-1]() # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:17:40\n",
      "  %input_layer.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"input_layer\"](%encoder)\n",
      "  %seq_len.1 : int = prim::GetAttr[name=\"seq_len\"](%encoder)\n",
      "  %input_dim : int = prim::GetAttr[name=\"input_dim\"](%encoder)\n",
      "  %37 : int[] = prim::ListConstruct(%33, %seq_len.1, %input_dim)\n",
      "  %38 : Tensor = aten::reshape(%x.1, %37) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:17:29\n",
      "  %_0.4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"0\"](%input_layer.1)\n",
      "  %weight.2 : Tensor = prim::GetAttr[name=\"weight\"](%_0.4)\n",
      "  %bias.2 : Tensor = prim::GetAttr[name=\"bias\"](%_0.4)\n",
      "  %input.7 : Tensor = aten::linear(%38, %weight.2, %bias.2) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:15\n",
      "  %x.6 : Tensor = aten::tanh(%input.7) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/activation.py:359:15\n",
      "  %lstms.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"lstms\"](%encoder)\n",
      "  %_0.6 : __torch__.torch.nn.modules.rnn.LSTM = prim::GetAttr[name=\"0\"](%lstms.1)\n",
      "  %46 : int = aten::dim(%x.6) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:20\n",
      "  %47 : int[] = prim::ListConstruct(%24, %25)\n",
      "  %48 : bool = aten::__contains__(%47, %46) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:20\n",
      "   = prim::If(%48) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "    block0():\n",
      "      -> ()\n",
      "    block1():\n",
      "      %49 : int = aten::dim(%x.6) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:98\n",
      "      %50 : str = aten::format(%22, %49) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:44\n",
      "      %51 : str = aten::add(%21, %50) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "       = prim::RaiseException(%51, %batch_sizes.4) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "      -> ()\n",
      "  %52 : int = aten::dim(%x.6) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774:25\n",
      "  %is_batched.2 : bool = aten::eq(%52, %25) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774:25\n",
      "  %54 : bool = aten::__not__(%is_batched.2) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:776:15\n",
      "  %input.10 : Tensor = prim::If(%54) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:776:12\n",
      "    block0():\n",
      "      %input.14 : Tensor = aten::unsqueeze(%x.6, %batch_dim.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:777:24\n",
      "      -> (%input.14)\n",
      "    block1():\n",
      "      -> (%x.6)\n",
      "  %max_batch_size.2 : int = aten::size(%input.10, %batch_dim.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:778:29\n",
      "  %58 : int = prim::dtype(%input.10)\n",
      "  %59 : Device = prim::device(%input.10)\n",
      "  %60 : int[] = prim::ListConstruct(%27, %max_batch_size.2, %20)\n",
      "  %h_zeros.2 : Tensor = aten::zeros(%60, %58, %batch_sizes.4, %59, %batch_sizes.4) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:785:22\n",
      "  %62 : int = prim::dtype(%input.10)\n",
      "  %63 : Device = prim::device(%input.10)\n",
      "  %64 : int[] = prim::ListConstruct(%27, %max_batch_size.2, %20)\n",
      "  %c_zeros.2 : Tensor = aten::zeros(%64, %62, %batch_sizes.4, %63, %batch_sizes.4) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:788:22\n",
      "  %hx.6 : (Tensor, Tensor) = prim::TupleConstruct(%h_zeros.2, %c_zeros.2)\n",
      "  %67 : int = aten::dim(%input.10) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:11\n",
      "  %68 : bool = aten::ne(%67, %25) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:11\n",
      "   = prim::If(%68) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:8\n",
      "    block0():\n",
      "      %69 : int = aten::dim(%input.10) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:216:40\n",
      "      %70 : str = aten::format(%30, %25, %69) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:215:16\n",
      "       = prim::RaiseException(%70, %18) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:214:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %71 : int = aten::size(%input.10, %33) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:30\n",
      "  %72 : bool = aten::ne(%29, %71) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:11\n",
      "   = prim::If(%72) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:8\n",
      "    block0():\n",
      "      %73 : int = aten::size(%input.10, %33) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:220:37\n",
      "      %74 : str = aten::format(%28, %29, %73) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:219:16\n",
      "       = prim::RaiseException(%74, %18) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:218:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %75 : Tensor = prim::TupleIndex(%hx.6, %batch_dim.1)\n",
      "  %mini_batch.7 : int = aten::size(%input.10, %batch_dim.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:226:25\n",
      "  %expected_hidden_size.4 : (int, int, int) = prim::TupleConstruct(%27, %mini_batch.7, %20)\n",
      "  %78 : int[] = aten::size(%75) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "  %79 : int, %80 : int, %81 : int = prim::TupleUnpack(%expected_hidden_size.4)\n",
      "  %82 : int[] = prim::ListConstruct(%79, %80, %81)\n",
      "  %83 : bool = aten::ne(%78, %82) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "   = prim::If(%83) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:8\n",
      "    block0():\n",
      "      %84 : int[] = aten::size(%75) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:69\n",
      "      %85 : int[] = aten::list(%84) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:64\n",
      "      %86 : str = aten::format(%31, %expected_hidden_size.4, %85) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:31\n",
      "       = prim::RaiseException(%86, %18) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %87 : Tensor = prim::TupleIndex(%hx.6, %27)\n",
      "  %mini_batch.9 : int = aten::size(%input.10, %batch_dim.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:717:25\n",
      "  %expected_hidden_size.6 : (int, int, int) = prim::TupleConstruct(%27, %mini_batch.9, %20)\n",
      "  %90 : int[] = aten::size(%87) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "  %91 : int, %92 : int, %93 : int = prim::TupleUnpack(%expected_hidden_size.6)\n",
      "  %94 : int[] = prim::ListConstruct(%91, %92, %93)\n",
      "  %95 : bool = aten::ne(%90, %94) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "   = prim::If(%95) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:8\n",
      "    block0():\n",
      "      %96 : int[] = aten::size(%87) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:69\n",
      "      %97 : int[] = aten::list(%96) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:64\n",
      "      %98 : str = aten::format(%32, %expected_hidden_size.6, %97) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:31\n",
      "       = prim::RaiseException(%98, %18) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %_flat_weights.1 : Tensor[] = prim::GetAttr[name=\"_flat_weights\"](%_0.6)\n",
      "  %training.1 : bool = prim::GetAttr[name=\"training\"](%_0.6)\n",
      "  %101 : Tensor, %102 : Tensor = prim::TupleUnpack(%hx.6)\n",
      "  %103 : Tensor[] = prim::ListConstruct(%101, %102)\n",
      "  %104 : Tensor, %105 : Tensor, %106 : Tensor = aten::lstm(%input.10, %103, %_flat_weights.1, %19, %27, %17, %training.1, %16, %19) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812:21\n",
      "  %hidden.2 : (Tensor, Tensor) = prim::TupleConstruct(%105, %106)\n",
      "  %108 : bool = aten::__not__(%is_batched.2) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:824:15\n",
      "  %hidden.4 : (Tensor, Tensor), %output.1 : Tensor = prim::If(%108) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:824:12\n",
      "    block0():\n",
      "      %output.6 : Tensor = aten::squeeze(%104, %batch_dim.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:825:25\n",
      "      %112 : Tensor = aten::squeeze(%105, %27) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:826:26\n",
      "      %113 : Tensor = aten::squeeze(%106, %27) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:826:48\n",
      "      %hidden.8 : (Tensor, Tensor) = prim::TupleConstruct(%112, %113)\n",
      "      -> (%hidden.8, %output.6)\n",
      "    block1():\n",
      "      -> (%hidden.2, %104)\n",
      "  %115 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output.1, %hidden.4)\n",
      "  %x.10 : Tensor, %117 : (Tensor, Tensor) = prim::TupleUnpack(%115)\n",
      "  %output_layer.1 : __torch__.torch.nn.modules.container.___torch_mangle_1.Sequential = prim::GetAttr[name=\"output_layer\"](%encoder)\n",
      "  %seq_len.2 : int = prim::GetAttr[name=\"seq_len\"](%encoder)\n",
      "  %encoder_dims : int[] = prim::GetAttr[name=\"encoder_dims\"](%encoder)\n",
      "  %121 : int = aten::__getitem__(%encoder_dims, %33) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:23:63\n",
      "  %122 : int = aten::mul(%seq_len.2, %121) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:23:48\n",
      "  %123 : int[] = prim::ListConstruct(%33, %122)\n",
      "  %124 : Tensor = aten::reshape(%x.10, %123) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:23:33\n",
      "  %_0.8 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Linear = prim::GetAttr[name=\"0\"](%output_layer.1)\n",
      "  %weight.4 : Tensor = prim::GetAttr[name=\"weight\"](%_0.8)\n",
      "  %bias.4 : Tensor = prim::GetAttr[name=\"bias\"](%_0.8)\n",
      "  %input.16 : Tensor = aten::linear(%124, %weight.4, %bias.4) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:15\n",
      "  %input.18 : Tensor = aten::tanh(%input.16) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/activation.py:359:15\n",
      "  %130 : bool = prim::Constant[value=0]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:813:59\n",
      "  %131 : float = prim::Constant[value=0.]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:813:30\n",
      "  %132 : str = prim::Constant[value=\"builtins.RuntimeError\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:798:30\n",
      "  %133 : bool = prim::Constant[value=1]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:795:24\n",
      "  %134 : int = prim::Constant[value=64]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:784:73\n",
      "  %135 : str = prim::Constant[value=\"AssertionError: \"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "  %136 : str = prim::Constant[value=\"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:44\n",
      "  %batch_sizes.3 : NoneType = prim::Constant() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:772:26\n",
      "  %138 : int = prim::Constant[value=2]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:36\n",
      "  %139 : int = prim::Constant[value=3]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:39\n",
      "  %140 : int = prim::Constant[value=1]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:783:58\n",
      "  %141 : str = prim::Constant[value=\"input.size(-1) must be equal to input_size. Expected {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:219:16\n",
      "  %142 : int = prim::Constant[value=32]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:11\n",
      "  %143 : str = prim::Constant[value=\"input must have {} dimensions, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:215:16\n",
      "  %144 : str = prim::Constant[value=\"Expected hidden[0] size {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:732:31\n",
      "  %145 : str = prim::Constant[value=\"Expected hidden[1] size {}, got {}\"]() # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:734:31\n",
      "  %i : int = prim::Constant[value=0]() # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:39:59\n",
      "  %147 : int = prim::Constant[value=-1]() # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:39:23\n",
      "  %input_layer : __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential = prim::GetAttr[name=\"input_layer\"](%decoder)\n",
      "  %_0.3 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=\"0\"](%input_layer)\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%_0.3)\n",
      "  %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%_0.3)\n",
      "  %input.6 : Tensor = aten::linear(%input.18, %weight.1, %bias.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:15\n",
      "  %x.5 : Tensor = aten::tanh(%input.6) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/activation.py:359:15\n",
      "  %seq_len : int = prim::GetAttr[name=\"seq_len\"](%decoder)\n",
      "  %decoder_dims : int[] = prim::GetAttr[name=\"decoder_dims\"](%decoder)\n",
      "  %156 : int = aten::__getitem__(%decoder_dims, %i) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:39:41\n",
      "  %157 : int[] = prim::ListConstruct(%147, %seq_len, %156)\n",
      "  %x.9 : Tensor = aten::reshape(%x.5, %157) # /Users/fubin/Downloads/pytorch/models/LSTM_MLP_AE.py:39:12\n",
      "  %lstms : __torch__.torch.nn.modules.container.___torch_mangle_5.ModuleList = prim::GetAttr[name=\"lstms\"](%decoder)\n",
      "  %_0.1 : __torch__.torch.nn.modules.rnn.___torch_mangle_4.LSTM = prim::GetAttr[name=\"0\"](%lstms)\n",
      "  %161 : int = aten::dim(%x.9) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:20\n",
      "  %162 : int[] = prim::ListConstruct(%138, %139)\n",
      "  %163 : bool = aten::__contains__(%162, %161) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:20\n",
      "   = prim::If(%163) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "    block0():\n",
      "      -> ()\n",
      "    block1():\n",
      "      %164 : int = aten::dim(%x.9) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:98\n",
      "      %165 : str = aten::format(%136, %164) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:44\n",
      "      %166 : str = aten::add(%135, %165) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "       = prim::RaiseException(%166, %batch_sizes.3) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:773:12\n",
      "      -> ()\n",
      "  %167 : int = aten::dim(%x.9) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774:25\n",
      "  %is_batched.1 : bool = aten::eq(%167, %139) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774:25\n",
      "  %169 : bool = aten::__not__(%is_batched.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:776:15\n",
      "  %input : Tensor = prim::If(%169) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:776:12\n",
      "    block0():\n",
      "      %input.13 : Tensor = aten::unsqueeze(%x.9, %i) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:777:24\n",
      "      -> (%input.13)\n",
      "    block1():\n",
      "      -> (%x.9)\n",
      "  %max_batch_size.1 : int = aten::size(%input, %i) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:778:29\n",
      "  %173 : int = prim::dtype(%input)\n",
      "  %174 : Device = prim::device(%input)\n",
      "  %175 : int[] = prim::ListConstruct(%140, %max_batch_size.1, %134)\n",
      "  %h_zeros.1 : Tensor = aten::zeros(%175, %173, %batch_sizes.3, %174, %batch_sizes.3) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:785:22\n",
      "  %177 : int = prim::dtype(%input)\n",
      "  %178 : Device = prim::device(%input)\n",
      "  %179 : int[] = prim::ListConstruct(%140, %max_batch_size.1, %134)\n",
      "  %c_zeros.1 : Tensor = aten::zeros(%179, %177, %batch_sizes.3, %178, %batch_sizes.3) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:788:22\n",
      "  %hx.5 : (Tensor, Tensor) = prim::TupleConstruct(%h_zeros.1, %c_zeros.1)\n",
      "  %182 : int = aten::dim(%input) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:11\n",
      "  %183 : bool = aten::ne(%182, %139) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:11\n",
      "   = prim::If(%183) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:213:8\n",
      "    block0():\n",
      "      %184 : int = aten::dim(%input) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:216:40\n",
      "      %185 : str = aten::format(%143, %139, %184) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:215:16\n",
      "       = prim::RaiseException(%185, %132) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:214:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %186 : int = aten::size(%input, %147) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:30\n",
      "  %187 : bool = aten::ne(%142, %186) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:11\n",
      "   = prim::If(%187) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:217:8\n",
      "    block0():\n",
      "      %188 : int = aten::size(%input, %147) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:220:37\n",
      "      %189 : str = aten::format(%141, %142, %188) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:219:16\n",
      "       = prim::RaiseException(%189, %132) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:218:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %190 : Tensor = prim::TupleIndex(%hx.5, %i)\n",
      "  %mini_batch.6 : int = aten::size(%input, %i) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:226:25\n",
      "  %expected_hidden_size.3 : (int, int, int) = prim::TupleConstruct(%140, %mini_batch.6, %134)\n",
      "  %193 : int[] = aten::size(%190) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "  %194 : int, %195 : int, %196 : int = prim::TupleUnpack(%expected_hidden_size.3)\n",
      "  %197 : int[] = prim::ListConstruct(%194, %195, %196)\n",
      "  %198 : bool = aten::ne(%193, %197) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "   = prim::If(%198) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:8\n",
      "    block0():\n",
      "      %199 : int[] = aten::size(%190) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:69\n",
      "      %200 : int[] = aten::list(%199) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:64\n",
      "      %201 : str = aten::format(%144, %expected_hidden_size.3, %200) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:31\n",
      "       = prim::RaiseException(%201, %132) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %202 : Tensor = prim::TupleIndex(%hx.5, %140)\n",
      "  %mini_batch.3 : int = aten::size(%input, %i) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:717:25\n",
      "  %expected_hidden_size.1 : (int, int, int) = prim::TupleConstruct(%140, %mini_batch.3, %134)\n",
      "  %205 : int[] = aten::size(%202) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "  %206 : int, %207 : int, %208 : int = prim::TupleUnpack(%expected_hidden_size.1)\n",
      "  %209 : int[] = prim::ListConstruct(%206, %207, %208)\n",
      "  %210 : bool = aten::ne(%205, %209) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:11\n",
      "   = prim::If(%210) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:238:8\n",
      "    block0():\n",
      "      %211 : int[] = aten::size(%202) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:69\n",
      "      %212 : int[] = aten::list(%211) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:64\n",
      "      %213 : str = aten::format(%145, %expected_hidden_size.1, %212) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:31\n",
      "       = prim::RaiseException(%213, %132) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:239:12\n",
      "      -> ()\n",
      "    block1():\n",
      "      -> ()\n",
      "  %_flat_weights : Tensor[] = prim::GetAttr[name=\"_flat_weights\"](%_0.1)\n",
      "  %training : bool = prim::GetAttr[name=\"training\"](%_0.1)\n",
      "  %216 : Tensor, %217 : Tensor = prim::TupleUnpack(%hx.5)\n",
      "  %218 : Tensor[] = prim::ListConstruct(%216, %217)\n",
      "  %219 : Tensor, %220 : Tensor, %221 : Tensor = aten::lstm(%input, %218, %_flat_weights, %133, %140, %131, %training, %130, %133) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:812:21\n",
      "  %hidden.1 : (Tensor, Tensor) = prim::TupleConstruct(%220, %221)\n",
      "  %223 : bool = aten::__not__(%is_batched.1) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:824:15\n",
      "  %hidden : (Tensor, Tensor), %output : Tensor = prim::If(%223) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:824:12\n",
      "    block0():\n",
      "      %output.5 : Tensor = aten::squeeze(%219, %i) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:825:25\n",
      "      %227 : Tensor = aten::squeeze(%220, %140) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:826:26\n",
      "      %228 : Tensor = aten::squeeze(%221, %140) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:826:48\n",
      "      %hidden.7 : (Tensor, Tensor) = prim::TupleConstruct(%227, %228)\n",
      "      -> (%hidden.7, %output.5)\n",
      "    block1():\n",
      "      -> (%hidden.1, %219)\n",
      "  %230 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output, %hidden)\n",
      "  %x.13 : Tensor, %232 : (Tensor, Tensor) = prim::TupleUnpack(%230)\n",
      "  %output_layer : __torch__.torch.nn.modules.container.___torch_mangle_7.Sequential = prim::GetAttr[name=\"output_layer\"](%decoder)\n",
      "  %_0 : __torch__.torch.nn.modules.linear.___torch_mangle_6.Linear = prim::GetAttr[name=\"0\"](%output_layer)\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%_0)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%_0)\n",
      "  %input.5 : Tensor = aten::linear(%x.13, %weight, %bias) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:15\n",
      "  %input.9 : Tensor = aten::sigmoid(%input.5) # /Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/activation.py:295:15\n",
      "  return (%input.9)\n",
      "\n",
      "3 def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  _0 = \"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"\n",
      "  _1 = \"input must have {} dimensions, got {}\"\n",
      "  _2 = \"input.size(-1) must be equal to input_size. Expected {}, got {}\"\n",
      "  _3 = \"LSTM: Expected input to be 2-D or 3-D but received {}-D tensor\"\n",
      "  _4 = \"input must have {} dimensions, got {}\"\n",
      "  _5 = \"input.size(-1) must be equal to input_size. Expected {}, got {}\"\n",
      "  decoder = self.decoder\n",
      "  encoder = self.encoder\n",
      "  input_layer = encoder.input_layer\n",
      "  seq_len = encoder.seq_len\n",
      "  input_dim = encoder.input_dim\n",
      "  _6 = torch.reshape(x, [-1, seq_len, input_dim])\n",
      "  _00 = getattr(input_layer, \"0\")\n",
      "  weight = _00.weight\n",
      "  bias = _00.bias\n",
      "  input = torch.linear(_6, weight, bias)\n",
      "  x0 = torch.tanh(input)\n",
      "  lstms = encoder.lstms\n",
      "  _01 = getattr(lstms, \"0\")\n",
      "  _7 = torch.dim(x0)\n",
      "  if torch.__contains__([2, 3], _7):\n",
      "    pass\n",
      "  else:\n",
      "    _8 = torch.add(\"AssertionError: \", torch.format(_0, torch.dim(x0)))\n",
      "    ops.prim.RaiseException(_8)\n",
      "  is_batched = torch.eq(torch.dim(x0), 3)\n",
      "  if torch.__not__(is_batched):\n",
      "    input0 = torch.unsqueeze(x0, 0)\n",
      "  else:\n",
      "    input0 = x0\n",
      "  max_batch_size = torch.size(input0, 0)\n",
      "  _9 = ops.prim.dtype(input0)\n",
      "  _10 = ops.prim.device(input0)\n",
      "  h_zeros = torch.zeros([1, max_batch_size, 32], dtype=_9, layout=None, device=_10)\n",
      "  _11 = ops.prim.dtype(input0)\n",
      "  _12 = ops.prim.device(input0)\n",
      "  c_zeros = torch.zeros([1, max_batch_size, 32], dtype=_11, layout=None, device=_12)\n",
      "  hx = (h_zeros, c_zeros)\n",
      "  if torch.ne(torch.dim(input0), 3):\n",
      "    _13 = torch.format(_1, 3, torch.dim(input0))\n",
      "    ops.prim.RaiseException(_13, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  if torch.ne(64, torch.size(input0, -1)):\n",
      "    _14 = torch.format(_2, 64, torch.size(input0, -1))\n",
      "    ops.prim.RaiseException(_14, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _15 = (hx)[0]\n",
      "  mini_batch = torch.size(input0, 0)\n",
      "  expected_hidden_size = (1, mini_batch, 32)\n",
      "  _16 = torch.size(_15)\n",
      "  _17, _18, _19, = expected_hidden_size\n",
      "  if torch.ne(_16, [_17, _18, _19]):\n",
      "    _20 = torch.format(\"Expected hidden[0] size {}, got {}\", expected_hidden_size, torch.list(torch.size(_15)))\n",
      "    ops.prim.RaiseException(_20, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _21 = (hx)[1]\n",
      "  mini_batch0 = torch.size(input0, 0)\n",
      "  expected_hidden_size0 = (1, mini_batch0, 32)\n",
      "  _22 = torch.size(_21)\n",
      "  _23, _24, _25, = expected_hidden_size0\n",
      "  if torch.ne(_22, [_23, _24, _25]):\n",
      "    _26 = torch.format(\"Expected hidden[1] size {}, got {}\", expected_hidden_size0, torch.list(torch.size(_21)))\n",
      "    ops.prim.RaiseException(_26, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _flat_weights = _01._flat_weights\n",
      "  training = _01.training\n",
      "  _27, _28, = hx\n",
      "  _29, _30, _31 = torch.lstm(input0, [_27, _28], _flat_weights, True, 1, 0., training, False, True)\n",
      "  hidden = (_30, _31)\n",
      "  if torch.__not__(is_batched):\n",
      "    output0 = torch.squeeze(_29, 0)\n",
      "    hidden1 = (torch.squeeze(_30, 1), torch.squeeze(_31, 1))\n",
      "    hidden0, output = hidden1, output0\n",
      "  else:\n",
      "    hidden0, output = hidden, _29\n",
      "  x1, _32, = (output, hidden0)\n",
      "  output_layer = encoder.output_layer\n",
      "  seq_len0 = encoder.seq_len\n",
      "  encoder_dims = encoder.encoder_dims\n",
      "  _33 = [-1, torch.mul(seq_len0, encoder_dims[-1])]\n",
      "  _34 = torch.reshape(x1, _33)\n",
      "  _02 = getattr(output_layer, \"0\")\n",
      "  weight0 = _02.weight\n",
      "  bias0 = _02.bias\n",
      "  input1 = torch.linear(_34, weight0, bias0)\n",
      "  input2 = torch.tanh(input1)\n",
      "  input_layer0 = decoder.input_layer\n",
      "  _03 = getattr(input_layer0, \"0\")\n",
      "  weight1 = _03.weight\n",
      "  bias1 = _03.bias\n",
      "  input3 = torch.linear(input2, weight1, bias1)\n",
      "  x2 = torch.tanh(input3)\n",
      "  seq_len1 = decoder.seq_len\n",
      "  decoder_dims = decoder.decoder_dims\n",
      "  x3 = torch.reshape(x2, [-1, seq_len1, decoder_dims[0]])\n",
      "  lstms0 = decoder.lstms\n",
      "  _04 = getattr(lstms0, \"0\")\n",
      "  _35 = torch.dim(x3)\n",
      "  if torch.__contains__([2, 3], _35):\n",
      "    pass\n",
      "  else:\n",
      "    _36 = torch.add(\"AssertionError: \", torch.format(_3, torch.dim(x3)))\n",
      "    ops.prim.RaiseException(_36)\n",
      "  is_batched0 = torch.eq(torch.dim(x3), 3)\n",
      "  if torch.__not__(is_batched0):\n",
      "    input4 = torch.unsqueeze(x3, 0)\n",
      "  else:\n",
      "    input4 = x3\n",
      "  max_batch_size0 = torch.size(input4, 0)\n",
      "  _37 = ops.prim.dtype(input4)\n",
      "  _38 = ops.prim.device(input4)\n",
      "  h_zeros0 = torch.zeros([1, max_batch_size0, 64], dtype=_37, layout=None, device=_38)\n",
      "  _39 = ops.prim.dtype(input4)\n",
      "  _40 = ops.prim.device(input4)\n",
      "  c_zeros0 = torch.zeros([1, max_batch_size0, 64], dtype=_39, layout=None, device=_40)\n",
      "  hx0 = (h_zeros0, c_zeros0)\n",
      "  if torch.ne(torch.dim(input4), 3):\n",
      "    _41 = torch.format(_4, 3, torch.dim(input4))\n",
      "    ops.prim.RaiseException(_41, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  if torch.ne(32, torch.size(input4, -1)):\n",
      "    _42 = torch.format(_5, 32, torch.size(input4, -1))\n",
      "    ops.prim.RaiseException(_42, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _43 = (hx0)[0]\n",
      "  mini_batch1 = torch.size(input4, 0)\n",
      "  expected_hidden_size1 = (1, mini_batch1, 64)\n",
      "  _44 = torch.size(_43)\n",
      "  _45, _46, _47, = expected_hidden_size1\n",
      "  if torch.ne(_44, [_45, _46, _47]):\n",
      "    _48 = torch.format(\"Expected hidden[0] size {}, got {}\", expected_hidden_size1, torch.list(torch.size(_43)))\n",
      "    ops.prim.RaiseException(_48, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _49 = (hx0)[1]\n",
      "  mini_batch2 = torch.size(input4, 0)\n",
      "  expected_hidden_size2 = (1, mini_batch2, 64)\n",
      "  _50 = torch.size(_49)\n",
      "  _51, _52, _53, = expected_hidden_size2\n",
      "  if torch.ne(_50, [_51, _52, _53]):\n",
      "    _54 = torch.format(\"Expected hidden[1] size {}, got {}\", expected_hidden_size2, torch.list(torch.size(_49)))\n",
      "    ops.prim.RaiseException(_54, \"builtins.RuntimeError\")\n",
      "  else:\n",
      "    pass\n",
      "  _flat_weights0 = _04._flat_weights\n",
      "  training0 = _04.training\n",
      "  _55, _56, = hx0\n",
      "  _57, _58, _59 = torch.lstm(input4, [_55, _56], _flat_weights0, True, 1, 0., training0, False, True)\n",
      "  hidden2 = (_58, _59)\n",
      "  if torch.__not__(is_batched0):\n",
      "    output2 = torch.squeeze(_57, 0)\n",
      "    hidden4 = (torch.squeeze(_58, 1), torch.squeeze(_59, 1))\n",
      "    hidden3, output1 = hidden4, output2\n",
      "  else:\n",
      "    hidden3, output1 = hidden2, _57\n",
      "  x4, _60, = (output1, hidden3)\n",
      "  output_layer0 = decoder.output_layer\n",
      "  _05 = getattr(output_layer0, \"0\")\n",
      "  weight2 = _05.weight\n",
      "  bias2 = _05.bias\n",
      "  input5 = torch.linear(x4, weight2, bias2)\n",
      "  return torch.sigmoid(input5)\n",
      "\n",
      "time: 0.0030870437622070312\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  decoder = self.decoder\n",
      "  encoder = self.encoder\n",
      "  _0 = (decoder).forward((encoder).forward(x, ), )\n",
      "  return _0\n",
      "\n",
      "time: 0.0023758411407470703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fubin/opt/anaconda3/lib/python3.9/site-packages/torch/jit/_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:491.)\n",
      "  if a.grad is not None:\n"
     ]
    }
   ],
   "source": [
    "# 2.torchscript（pytorch自己的-python版本部署）:  script(pytorch model) or trace(pytorch model, input)，pytorch自己的静态存储，仅用于推理\n",
    "# 采用无输入的torch.jit.script,源码转换\n",
    "# 支持if-else等控制流，支持非tensor的数据类型，需要对部分数据进行类型标注（：）\n",
    "model_1 = torch.jit.script(model)\n",
    "print(1,model_1.code)\n",
    "print(2,model_1.graph)\n",
    "# 完全确定子模块输出，所有子模块内联\n",
    "torch._C._jit_pass_inline(model_1.graph)\n",
    "print(3,model_1.code)\n",
    "t1 = time()\n",
    "output = model_1(dummy_input)\n",
    "print('time:', time()-t1)\n",
    "torch.jit.save(model_1, 'models/LSTM_MLP_AE_jittest.pt')\n",
    "# torch.jit.load('models/LSTM_MLP_AE_jittest.pt') # 暂时不支持mps，RuntimeError: supported devices include CPU, CUDA and HPU, however got MPS\n",
    "\n",
    "# 采用有输入的torch.jit.trace\n",
    "# 不支持if-else控制流，不支持tensor以外的数据类型\n",
    "model_2 = torch.jit.trace(model, dummy_input)\n",
    "print(model_2.code)\n",
    "t1 = time()\n",
    "output = model_1(dummy_input)\n",
    "print('time:', time()-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间对比\n",
    "# pytorch model: 0.00858306884765625\n",
    "# onnxruntime: 0.0011768341064453125\n",
    "# torch.jit.script: 0.0030870437622070312\n",
    "# torch.jit.trace: 0.0023758411407470703\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.libtorch（pytorch自己的-c++版本）: c++里的pytorch，实现c++环境下的部署\n",
    "# 这里省略，需要在c++中安装相应包，并执行c++环境，如pytorch中的操作torch.einsum对应libtorch中的torch::einsum\n",
    "# 1.可以直接用libtorch来实现模型\n",
    "# 2.可以直接加载ONNX或者pt模型文件\n",
    "\n",
    "# 以下为c++代码，其实风格同pytorch类似:\n",
    "#include <torch/torch.h>\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int main(int argc, const char ** argv){\n",
    "    torch::Tensor x = torch::randn((2,3));\n",
    "    torch::nn::Linear f(3,6);\n",
    "    # torch::Tensor y = f(x);\n",
    "    torch::Tensor y = f->forward(x);\n",
    "    cout << y << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.TensorRT 3（NVIDIA自家GPU优化）：基于ONNX提供c++/python api，工业级推理方案\n",
    "# nvidia发布dnn推理引擎，针对nvidia硬件进行优化加速，实现最大化利用gpu资源，提升推理性能\n",
    "# 是业内nvidia系列产品部署落地时的最佳选择，基于libnvonxparser.so（ONNXParser）\n",
    "# 高性能后续需要考虑，高吞吐、低延迟、低内存设备占用，异步进行、消除没用的操作\n",
    "# onnx模型 -> TRT模型\n",
    "# 执行过程：onnx文件  ->  trt api  ->  trt builder  ->  trt engine\n",
    "# 比cpu快40倍\n",
    "\n",
    "# c++：\n",
    "TRT::compile(\n",
    "    TRT::Mode::FP32, # 使用FP32模型编译\n",
    "    3, # max batch size\n",
    "    \"plugin.onnx\", // onnx文件\n",
    "    \"plugin.fp32.trtmodel\", // 保存文件路径\n",
    "    {}\n",
    ")\n",
    "\n",
    "# python：\n",
    "# pip install trtpy\n",
    "import trtpy\n",
    "model = models.resnet18(True).eval()\n",
    "trtpy.from_torch(\n",
    "    model,\n",
    "    max_batch_size=16,\n",
    "    onnx_save_file='LSTM_MLP_AE.onnx',\n",
    "    engine_save_file='LSTM_MLP_AE.trtmodel'\n",
    ")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.基于flask web部署\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
